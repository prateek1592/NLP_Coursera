{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find duplicate questions on StackOverflow by their embeddings\n",
    "\n",
    "In this assignment you will learn how to calculate a similarity for pieces of text. Using this approach you will know how to find duplicate questions from [StackOverflow](https://stackoverflow.com)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "In this task you will you will need the following libraries:\n",
    "- [StarSpace](https://github.com/facebookresearch/StarSpace) — a general-purpose model for efficient learning of entity embeddings from Facebook\n",
    "- [Gensim](https://radimrehurek.com/gensim/) — a tool for solving various NLP-related tasks (topic modeling, text representation, ...)\n",
    "- [Numpy](http://www.numpy.org) — a package for scientific computing.\n",
    "- [scikit-learn](http://scikit-learn.org/stable/index.html) — a tool for data mining and data analysis.\n",
    "- [Nltk](http://www.nltk.org) — a platform to work with human language data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data\n",
    "\n",
    "The following cell will download all data required for this assignment into the folder `week3/data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File data/train.tsv is already downloaded.\n",
      "File data/validation.tsv is already downloaded.\n",
      "File data/test.tsv is already downloaded.\n",
      "File data/test_embeddings.tsv is already downloaded.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "from common.download_utils import download_week3_resources\n",
    "\n",
    "download_week3_resources()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grading\n",
    "We will create a grader instace below and use it to collect your answers. Note that these outputs will be stored locally inside grader and will be uploaded to platform only after running submiting function in the last part of this assignment. If you want to make partial submission, you can run that cell any time you want."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from grader import Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "grader = Grader()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word embedding\n",
    "\n",
    "To solve the problem, you will use two different models of embeddings:\n",
    "\n",
    " - [Pre-trained word vectors](https://code.google.com/archive/p/word2vec/) from Google which were trained on a part of Google News dataset (about 100 billion words). The model contains 300-dimensional vectors for 3 million words and phrases. You need to download it by following this [link](https://drive.google.com/file/d/0B7XkCwpI5KDYNlNUTTlSS21pQmM/edit?usp=sharing).\n",
    " - Representations using StarSpace on StackOverflow data sample. You will need to train them from scratch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's always easier to start with pre-trained embeddings. Unpack the pre-trained Goggle's vectors and upload them using the function [KeyedVectors.load_word2vec_format](https://radimrehurek.com/gensim/models/keyedvectors.html) from gensim library with the parameter *binary=True*. If the size of the embeddings is larger than the avaliable memory, you could load only a part of the embeddings by defining the parameter *limit* (recommended: 500000)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import KeyedVectors\n",
    "wv_embeddings = KeyedVectors.load_word2vec_format('data/GoogleNews-vectors-negative300.bin', binary=True, limit=500000)\n",
    "######### YOUR CODE HERE #############"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to work with Google's word2vec embeddings?\n",
    "\n",
    "Once you have loaded the representations, make sure you can access them. First, you can check if the loaded embeddings contain a word:\n",
    "    \n",
    "    'word' in wv_embeddings\n",
    "    \n",
    "Second, to get the corresponding embedding you can use the square brackets:\n",
    "\n",
    "    wv_embeddings['word']\n",
    " \n",
    "### Checking that the embeddings are correct \n",
    " \n",
    "To prevent any errors during the first stage, we can check that the loaded embeddings are correct. You can call the function *check_embeddings*, implemented below, which runs 3 tests:\n",
    "1. Find the most similar word for provided \"positive\" and \"negative\" words.\n",
    "2. Find which word from the given list doesn’t go with the others.\n",
    "3. Find the most similar word for the provided one.\n",
    "\n",
    "In the right case the function will return the string *These embeddings look good*. Othervise, you need to validate the previous steps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def check_embeddings(embeddings):\n",
    "    error_text = \"Something wrong with your embeddings ('%s test isn't correct).\"\n",
    "    most_similar = embeddings.most_similar(positive=['woman', 'king'], negative=['man'])\n",
    "    if len(most_similar) < 1 or most_similar[0][0] != 'queen':\n",
    "        return error_text % \"Most similar\"\n",
    "\n",
    "    doesnt_match = embeddings.doesnt_match(['breakfast', 'cereal', 'dinner', 'lunch'])\n",
    "    if doesnt_match != 'cereal':\n",
    "        return error_text % \"Doesn't match\"\n",
    "    \n",
    "    most_similar_to_given = embeddings.most_similar_to_given('music', ['water', 'sound', 'backpack', 'mouse'])\n",
    "    if most_similar_to_given != 'sound':\n",
    "        return error_text % \"Most similar to given\"\n",
    "    \n",
    "    return \"These embeddings look good.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(check_embeddings(wv_embeddings))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## From word to text embeddings\n",
    "\n",
    "**Task 1 (Question2Vec).** Usually, we have word-based embeddings, but for the task we need to create a representation for the whole question. It could be done in different ways. In our case we will use a **mean** of all word vectors in the question. Now you need to implement the function *question_to_vec*, which calculates the question representation described above. This function should work with the input text as is without any preprocessing.\n",
    "\n",
    "Note that there could be words without the corresponding embeddings. In this case, you can just skip these words and don't take them into account during calculating the result. If the question doesn't contain any known word with embedding, the function should return a zero vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec(question, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        embeddings: dict where the key is a word and a value is its' embedding\n",
    "        dim: size of the representation\n",
    "\n",
    "        result: vector representation for the question\n",
    "    \"\"\"\n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    \n",
    "    output = np.zeros(dim)\n",
    "    strings = question.split()\n",
    "    emb_count = 0.0\n",
    "    \n",
    "    for string in strings:\n",
    "        if string in embeddings:\n",
    "            emb = embeddings[string]\n",
    "            output += emb\n",
    "            emb_count += 1\n",
    "    \n",
    "    if emb_count > 0:\n",
    "        return output/emb_count\n",
    "    else:\n",
    "        return output    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To check the basic correctness of your implementation, run the function *question_to_vec_tests*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def question_to_vec_tests():\n",
    "    if (np.zeros(300) != question_to_vec('', wv_embeddings)).any():\n",
    "        return \"You need to return zero vector for empty question.\"\n",
    "    if (np.zeros(300) != question_to_vec('thereisnosuchword', wv_embeddings)).any():\n",
    "        return \"You need to return zero vector for the question, which consists only unknown words.\"\n",
    "    if (wv_embeddings['word'] != question_to_vec('word', wv_embeddings)).any():\n",
    "        return \"You need to check the corectness of your function.\"\n",
    "    if ((wv_embeddings['I'] + wv_embeddings['am']) / 2 != question_to_vec('I am', wv_embeddings)).any():\n",
    "        return \"Your function should calculate a mean of word vectors.\"\n",
    "    if (wv_embeddings['word'] != question_to_vec('thereisnosuchword word', wv_embeddings)).any():\n",
    "        return \"You should not consider words which embeddings are unknown.\"\n",
    "    return \"Basic tests are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "print(question_to_vec_tests())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can submit embeddings for the questions from the file *test_embeddings.tsv* to earn the points. In this task you don't need to transform the text of a question somehow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from util import array_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task Question2Vec is: 0.019293891059\n",
      "-0.0287272135417\n",
      "0.0460561116536\n",
      "0.0852593315972\n",
      "0.0243055555556\n",
      "-0.0729031032986\n",
      "0.0...\n"
     ]
    }
   ],
   "source": [
    "question2vec_result = []\n",
    "for question in open('data/test_embeddings.tsv'):\n",
    "    question = question.strip()\n",
    "    answer = question_to_vec(question, wv_embeddings)\n",
    "    question2vec_result = np.append(question2vec_result, answer)\n",
    "\n",
    "grader.submit_tag('Question2Vec', array_to_string(question2vec_result))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we have a method to create a representation of any sentence and we are ready for the first evaluation. So, let's check how well our solution (Google's vectors + *question_to_vec*) will work.\n",
    "\n",
    "## Evaluation of text similarity\n",
    "\n",
    "We can imagine that if we use good embeddings, the cosine similarity between the duplicate sentences should be less than for the random ones. Overall, for each pair of duplicate sentences we can generate *R* random negative examples and find out the position of the correct duplicate.  \n",
    "\n",
    "For example, we have the question *\"Exceptions What really happens\"* and we are sure that another question *\"How does the catch keyword determine the type of exception that was thrown\"* is a duplicate. But our model doesn't know it and tries to find out the best option also among questions like *\"How Can I Make These Links Rotate in PHP\"*, *\"NSLog array description not memory address\"* and *\"PECL_HTTP not recognised php ubuntu\"*. The goal of the model is to rank all these 4 questions (1 *positive* and *R* = 3 *negative*) in the way that the correct one is in the first place.\n",
    "\n",
    "However, it is unnatural to count on that the best candidate will be always in the first place. So let us consider the place of the best candidate in the sorted list of candidates and formulate a metric based on it. We can fix some *K* — a reasonalble number of top-ranked elements and *N* — a number of queries (size of the sample).\n",
    "\n",
    "### Hits@K\n",
    "\n",
    "The first simple metric will be a number of correct hits for some *K*:\n",
    "$$ \\text{Hits@K} = \\frac{1}{N}\\sum_{i=1}^N \\, [dup_i \\in topK(q_i)]$$\n",
    "\n",
    "where $q_i$ is the i-th query, $dup_i$ is its duplicate, $topK(q_i)$ is the top K elements of the ranked sentences provided by our model and the operation $[dup_i \\in topK(q_i)]$ equals 1 if the condition is true and 0 otherwise (more details about this operation could be found [here](https://en.wikipedia.org/wiki/Iverson_bracket)).\n",
    "\n",
    "\n",
    "### DCG@K\n",
    "The second one is a simplified [DCG metric](https://en.wikipedia.org/wiki/Discounted_cumulative_gain):\n",
    "\n",
    "$$ \\text{DCG@K} = \\frac{1}{N} \\sum_{i=1}^N\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le K] $$\n",
    "\n",
    "where $rank_{dup_i}$ is a position of the duplicate in the sorted list of the nearest sentences for the query $q_i$. According to this metric, the model gets a higher reward for a higher position of the correct answer. If the answer does not appear in topK at all, the reward is zero. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation examples\n",
    "\n",
    "Let's calculate the described metrics for the toy example introduced above. In this case $N$ = 1 and the correct candidate for $q_1$ is *\"How does the catch keyword determine the type of exception that was thrown\"*. Consider the following ranking of the candidates:\n",
    "1. *\"How Can I Make These Links Rotate in PHP\"*\n",
    "2. *\"How does the catch keyword determine the type of exception that was thrown\"*\n",
    "3. *\"NSLog array description not memory address\"*\n",
    "4. *\"PECL_HTTP not recognised php ubuntu\"*\n",
    "\n",
    "Using the ranking above, calculate *Hits@K* metric for *K = 1, 2, 4*: \n",
    " \n",
    "- [K = 1] $\\text{Hits@1} = \\frac{1}{1}\\sum_{i=1}^1 \\, [dup_i \\in top1(q_i)] = [dup_1 \\in top1(q_1)] = 0$ because the correct answer doesn't appear in the *top1* list.\n",
    "- [K = 2] $\\text{Hits@2} = \\frac{1}{1}\\sum_{i=1}^1 \\, [dup_i \\in top2(q_i)] = [dup_1 \\in top2(q_1)] = 1$ because $rank_{dup_1} = 2$.\n",
    "- [K = 4] $\\text{Hits@4} = \\frac{1}{1}\\sum_{i=1}^1 \\, [dup_i \\in top4(q_i)] = [dup_1 \\in top4(q_1)] = 1$\n",
    "\n",
    "Using the ranking above, calculate *DCG@K* metric for *K = 1, 2, 4*:\n",
    "\n",
    "- [K = 1] $\\text{DCG@1} = \\frac{1}{1} \\sum_{i=1}^1\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le 1] = \\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le 1] = 0$ because the correct answer doesn't appear in the top1 list.\n",
    "- [K = 2] $\\text{DCG@2} = \\frac{1}{1} \\sum_{i=1}^1\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le 2] = \\frac{1}{\\log_2{3}}$, because $rank_{dup_1} = 2$.\n",
    "- [K = 4] $\\text{DCG@4} = \\frac{1}{1} \\sum_{i=1}^1\\frac{1}{\\log_2(1+rank_{dup_i})}\\cdot[rank_{dup_i} \\le 4] = \\frac{1}{\\log_2{3}}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tasks 2 and 3 (HitsCount and DCGScore).** Implement the functions *hits_count* and *dcg_score* as described above. Each function has two arguments: *dup_ranks* and *k*. *dup_ranks* is a list which contains *values of ranks* of duplicates. For example, *dup_ranks* is *[2]* for the example provided above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hits_count(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list of duplicates' ranks; one rank per question; \n",
    "                   length is a number of questions which we are looking for duplicates; \n",
    "                   rank is a number from 1 to len(candidates of the question); \n",
    "                   e.g. [2, 3] means that the first duplicate has the rank 2, the second one — 3.\n",
    "        k: number of top-ranked elements (k in Hits@k metric)\n",
    "\n",
    "        result: return Hits@k value for current ranking\n",
    "    \"\"\"\n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    \n",
    "    out = [x<=k for x in dup_ranks]\n",
    "    \n",
    "    return sum(out)/len(out)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code on the tiny examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_hits():\n",
    "    # *Evaluation example*\n",
    "    # answers — dup_i\n",
    "    answers = [\"How does the catch keyword determine the type of exception that was thrown\"]\n",
    "    \n",
    "    # candidates_ranking — the ranked sentences provided by our model\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                           \"NSLog array description not memory address\",\n",
    "                           \"PECL_HTTP not recognised php ubuntu\"]]\n",
    "    # dup_ranks — position of the dup_i in the list of ranks +1\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    \n",
    "    # correct_answers — the expected values of the result for each k from 1 to 4\n",
    "    correct_answers = [0, 1, 1, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(hits_count(dup_ranks, k), correct):\n",
    "            return \"Check the function.\"\n",
    "    \n",
    "    # Other tests\n",
    "    answers = [\"How does the catch keyword determine the type of exception that was thrown\", \n",
    "               \"Convert Google results object (pure js) to Python object\"]\n",
    "    \n",
    "    # The first test: both duplicates on the first position in ranked list\n",
    "    candidates_ranking = [[\"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                           \"How Can I Make These Links Rotate in PHP\"], \n",
    "                          [\"Convert Google results object (pure js) to Python object\",\n",
    "                           \"WPF- How to update the changes in list item of a list\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [1, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(hits_count(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: both duplicates on the first position in ranked list).\"\n",
    "        \n",
    "    # The second test: one candidate on the first position, another — on the second\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\"], \n",
    "                          [\"Convert Google results object (pure js) to Python object\",\n",
    "                           \"WPF- How to update the changes in list item of a list\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [0.5, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(hits_count(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: one candidate on the first position, another — on the second).\"\n",
    "\n",
    "    # The third test: both candidates on the second position\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\"], \n",
    "                          [\"WPF- How to update the changes in list item of a list\",\n",
    "                           \"Convert Google results object (pure js) to Python object\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [0, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(hits_count(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: both candidates on the second position).\"\n",
    "\n",
    "    return \"Basic test are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic test are passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_hits())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dcg_score(dup_ranks, k):\n",
    "    \"\"\"\n",
    "        dup_ranks: list of duplicates' ranks; one rank per question; \n",
    "                   length is a number of questions which we are looking for duplicates; \n",
    "                   rank is a number from 1 to len(candidates of the question); \n",
    "                   e.g. [2, 3] means that the first duplicate has the rank 2, the second one — 3.\n",
    "        k: number of top-ranked elements (k in DCG@k metric)\n",
    "\n",
    "        result: return DCG@k value for current ranking\n",
    "    \"\"\"\n",
    "    \n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    \n",
    "    total_val = 0\n",
    "    for rank in dup_ranks:\n",
    "        out = rank <= k\n",
    "        out = np.log(2) / np.log(1+rank) * out\n",
    "        total_val += out\n",
    "    \n",
    "    return total_val/len(dup_ranks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_dcg():\n",
    "    # *Evaluation example*\n",
    "    # answers — dup_i\n",
    "    answers = [\"How does the catch keyword determine the type of exception that was thrown\"]\n",
    "    \n",
    "    # candidates_ranking — the ranked sentences provided by our model\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                           \"NSLog array description not memory address\",\n",
    "                           \"PECL_HTTP not recognised php ubuntu\"]]\n",
    "    # dup_ranks — position of the dup_i in the list of ranks +1\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    \n",
    "    # correct_answers — the expected values of the result for each k from 1 to 4\n",
    "    correct_answers = [0, 1 / (np.log2(3)), 1 / (np.log2(3)), 1 / (np.log2(3))]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(dcg_score(dup_ranks, k), correct):\n",
    "            return \"Check the function.\"\n",
    "    \n",
    "    # Other tests\n",
    "    answers = [\"How does the catch keyword determine the type of exception that was thrown\", \n",
    "               \"Convert Google results object (pure js) to Python object\"]\n",
    "\n",
    "    # The first test: both duplicates on the first position in ranked list\n",
    "    candidates_ranking = [[\"How does the catch keyword determine the type of exception that was thrown\",\n",
    "                           \"How Can I Make These Links Rotate in PHP\"], \n",
    "                          [\"Convert Google results object (pure js) to Python object\",\n",
    "                           \"WPF- How to update the changes in list item of a list\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [1, 1]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(dcg_score(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: both duplicates on the first position in ranked list).\"\n",
    "        \n",
    "    # The second test: one candidate on the first position, another — on the second\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\", \n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\"], \n",
    "                          [\"Convert Google results object (pure js) to Python object\",\n",
    "                           \"WPF- How to update the changes in list item of a list\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [0.5, (1 + (1 / (np.log2(3)))) / 2]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(dcg_score(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: one candidate on the first position, another — on the second).\"\n",
    "        \n",
    "    # The third test: both candidates on the second position\n",
    "    candidates_ranking = [[\"How Can I Make These Links Rotate in PHP\",\n",
    "                           \"How does the catch keyword determine the type of exception that was thrown\"], \n",
    "                          [\"WPF- How to update the changes in list item of a list\",\n",
    "                           \"Convert Google results object (pure js) to Python object\"]]\n",
    "    dup_ranks = [candidates_ranking[i].index(answers[i]) + 1 for i in range(len(answers))]\n",
    "    correct_answers = [0, 1 / (np.log2(3))]\n",
    "    for k, correct in enumerate(correct_answers, 1):\n",
    "        if not np.isclose(dcg_score(dup_ranks, k), correct):\n",
    "            return \"Check the function (test: both candidates on the second position).\"\n",
    "\n",
    "    return \"Basic test are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic test are passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_dcg())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Submit results of the functions *hits_count* and *dcg_score* for the following examples to earn the points."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_examples = [\n",
    "    [1],\n",
    "    [1, 2],\n",
    "    [2, 1],\n",
    "    [1, 2, 3],\n",
    "    [1, 2, 3, 4, 5, 6, 7, 8, 9, 10],\n",
    "    [9, 5, 4, 2, 8, 10, 7, 6, 1, 3],\n",
    "    [4, 3, 5, 1, 9, 10, 7, 8, 2, 6],\n",
    "    [5, 1, 7, 6, 2, 3, 8, 9, 10, 4],\n",
    "    [6, 3, 1, 4, 7, 2, 9, 8, 10, 5],\n",
    "    [10, 9, 8, 7, 6, 5, 4, 3, 2, 1],\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task HitsCount is: 1.0\n",
      "0.5\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1....\n"
     ]
    }
   ],
   "source": [
    "hits_results = []\n",
    "for example in test_examples:\n",
    "    for k in range(len(example)):\n",
    "        hits_results.append(hits_count(example, k + 1))\n",
    "grader.submit_tag('HitsCount', array_to_string(hits_results))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task DCGScore is: 1.0\n",
      "0.5\n",
      "0.815464876786\n",
      "0.5\n",
      "0.815464876786\n",
      "0.333333333333\n",
      "0.54364325119\n",
      "0.710309917857\n",
      "0.1\n",
      "0.16309297...\n"
     ]
    }
   ],
   "source": [
    "dcg_results = []\n",
    "for example in test_examples:\n",
    "    for k in range(len(example)):\n",
    "        dcg_results.append(dcg_score(example, k + 1))\n",
    "grader.submit_tag('DCGScore', array_to_string(dcg_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  First solution: pre-trained embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will work with predefined train, validation and test corpora. All the files are tab-separated, but have a different format:\n",
    " - *train* corpus contains similar sentences at the same row.\n",
    " - *validation* corpus contains the following columns: *question*, *similar question*, *negative example 1*, *negative example 2*, ... \n",
    " - *test* corpus contains the following columns: *question*, *example 1*, *example 2*, ...\n",
    "\n",
    "Validation corpus will be used for the intermediate validation of models. The test data will be necessary for submitting the quality of your model in the system."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you should upload *validation* corpus to evaluate current solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_corpus(filename):\n",
    "    data = []\n",
    "    for line in open(filename, encoding='utf-8'):\n",
    "        data.append(line.strip().split('\\t'))\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "validation = read_corpus('data/validation.tsv')  ######### YOUR CODE HERE #############"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use cosine distance to rank candidate questions which you need to implement in the function *rank_candidates*. The function should return a sorted list of pairs *(initial position in candidates list, candidate)*. Index of some pair corresponds to its rank (the first is the best). For example, if the list of candidates was *[a, b, c]* and the most similar is *c*, then *a* and *b*, the function should return a list *[(2, c), (0, a), (1, b)]*.\n",
    "\n",
    "Pay attention, if you use the function *cosine_similarity* from *sklearn.metrics.pairwise* to calculate similarity because it works in a different way: most similar objects has greatest similarity. It's preferable to use a vectorized version of *cosine_similarity* function. Try to compute similarity at once and not use list comprehension. It should speed up your computations significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rank_candidates(question, candidates, embeddings, dim=300):\n",
    "    \"\"\"\n",
    "        question: a string\n",
    "        candidates: a list of strings (candidates) which we want to rank\n",
    "        embeddings: some embeddings\n",
    "        dim: dimension of the current embeddings\n",
    "        \n",
    "        result: a list of pairs (initial position in the list, question)\n",
    "    \"\"\"\n",
    "    \n",
    "    ######################################\n",
    "    ######### YOUR CODE HERE #############\n",
    "    ######################################\n",
    "    \n",
    "    ref_vec = question_to_vec(question, embeddings, dim).reshape([1,-1])\n",
    "    cand_vec = np.array([question_to_vec(q, embeddings, dim) for q in candidates])\n",
    "    cand_vec = cand_vec.reshape([len(candidates),-1])\n",
    "    ind = np.argsort(cosine_similarity(ref_vec, cand_vec))\n",
    "    \n",
    "    return [(x, candidates[x]) for x in ind[0]][::-1]\n",
    "    \n",
    "    \"\"\"\n",
    "    # What did not work!\n",
    "    q_vec = np.asarray([question_to_vec(question, embeddings, dim=300)])\n",
    "    cand_vec = np.asarray([question_to_vec(candidate, embeddings, dim=300) for candidate in candidates])\n",
    "    similarity_index = cosine_similarity(q_vec, cand_vec)[0]\n",
    "    indices = np.argsort(-1.0*similarity_index)\n",
    "    unordered_list = [(u,v) for u, v in enumerate(candidates)]\n",
    "    ordered_list = [x for _,x in sorted(zip(indices,unordered_list))]\n",
    "    return ordered_list\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test your code on the tiny examples:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_rank_candidates():\n",
    "    questions = ['converting string to list', 'Sending array via Ajax fails']\n",
    "    candidates = [['Convert Google results object (pure js) to Python object', \n",
    "                   'C# create cookie from string and send it',\n",
    "                   'How to use jQuery AJAX for an outside domain?'], \n",
    "                  ['Getting all list items of an unordered list in PHP', \n",
    "                   'WPF- How to update the changes in list item of a list', \n",
    "                   'select2 not displaying search results']]\n",
    "    results = [[(1, 'C# create cookie from string and send it'), \n",
    "                (0, 'Convert Google results object (pure js) to Python object'), \n",
    "                (2, 'How to use jQuery AJAX for an outside domain?')],\n",
    "               [(0, 'Getting all list items of an unordered list in PHP'), \n",
    "                (2, 'select2 not displaying search results'), \n",
    "                (1, 'WPF- How to update the changes in list item of a list')]]\n",
    "    for question, q_candidates, result in zip(questions, candidates, results):\n",
    "        ranks = rank_candidates(question, q_candidates, wv_embeddings, 300)\n",
    "        if not np.all(ranks == result):\n",
    "            return \"Check the function.\"\n",
    "    return \"Basic tests are passed.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Basic tests are passed.\n"
     ]
    }
   ],
   "source": [
    "print(test_rank_candidates())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can test the quality of the current approach. Run the next two cells to get the results. Pay attention that calculation of similarity between vectors takes time and this calculation is computed approximately in 10 minutes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_ranking = []\n",
    "for line in validation:\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings)\n",
    "    wv_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_ranking, k), k, hits_count(wv_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you did all the steps correctly, you should be frustrated by the received results. Let's try to understand why the quality is so low. First of all, when you work with some data it is necessary to have an idea how the data looks like. Print several questions from the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "How to print a binary heap tree without recursion? How do you best convert a recursive function to an iterative one? How can i use ng-model with directive in angular js flash: drawing and erasing\n",
      "How to start PhoneStateListener programmatically? PhoneStateListener and service Java cast object[] to model WCF and What does this mean?\n",
      "jQuery: Show a div2 when mousenter over div1 is over when hover on div1 depenting on if it is on div2 or not it should act differently How to run selenium in google app engine/cloud? Python Comparing two lists of strings for similarities\n"
     ]
    }
   ],
   "source": [
    "for line in validation[:3]:\n",
    "    q, *examples = line\n",
    "    print(q, *examples[:3])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, we deal with the raw data. It means that we have many punctuation marks, special characters and unlowercased letters. In our case, it could lead to the situation where we can't find some embeddings, e.g. for the word \"grid?\". \n",
    "\n",
    "To solve this problem you should use the functions *text_prepare* from the previous assignments to prepare the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import text_prepare"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now transform all the questions from the validation set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "prepared_validation = []\n",
    "for line in validation:\n",
    "    prepared_validation.append([text_prepare(q) for q in line])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's evaluate the approach again after the preparation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wv_prepared_ranking = []\n",
    "for line in prepared_validation:\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings)\n",
    "    wv_prepared_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(wv_prepared_ranking, k), \n",
    "                                              k, hits_count(wv_prepared_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, prepare also train and test data, because you will need it in the future:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_file(in_, out_):\n",
    "    out = open(out_, 'w')\n",
    "    for line in open(in_, encoding='utf8'):\n",
    "        line = line.strip().split('\\t')\n",
    "        new_line = [text_prepare(q) for q in line]\n",
    "        print(*new_line, sep='\\t', file=out)\n",
    "    out.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "######################################\n",
    "######### YOUR CODE HERE #############\n",
    "######################################\n",
    "\n",
    "prepare_file('data/train.tsv', 'data/train_prepped.tsv')\n",
    "prepare_file('data/test.tsv', 'data/test_prepped.tsv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 4 (W2VTokenizedRanks).** For each question from prepared *test.tsv* submit the ranks of the candidates to earn the points. The calculations should take about 3-5 minutes. Pay attention that the function *rank_candidates* returns a ranking, while in this case you should find a position in this ranking. Ranks should start with 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from util import matrix_to_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task W2VTokenizedRanks is: 95\t94\t7\t9\t64\t36\t31\t93\t23\t100\t99\t20\t60\t6\t97\t48\t70\t37\t41\t96\t29\t56\t2\t65\t68\t44\t27\t25\t57\t62\t11\t87\t50\t66\t7...\n"
     ]
    }
   ],
   "source": [
    "w2v_ranks_results = []\n",
    "prepared_test_data = 'data/test_prepped.tsv'   ######### YOUR CODE HERE #############\n",
    "for line in open(prepared_test_data):\n",
    "    q, *ex = line.strip().split('\\t')\n",
    "    ranks = rank_candidates(q, ex, wv_embeddings, 300)\n",
    "    ranked_candidates = [r[0] for r in ranks]\n",
    "    w2v_ranks_results.append([ranked_candidates.index(i) + 1 for i in range(len(ranked_candidates))])\n",
    "    \n",
    "grader.submit_tag('W2VTokenizedRanks', matrix_to_string(w2v_ranks_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced solution: StarSpace embeddings\n",
    "\n",
    "Now you are ready to train your own word embeddings! In particular, you need to train embeddings specially for our task of duplicates detection. Unfortunately, StarSpace cannot be run on Windows and we recommend to use provided\n",
    "[docker container](https://github.com/hse-aml/natural-language-processing/blob/master/Docker-tutorial.md) or other alternatives. Don't delete results of this task because you will need it in the final project.\n",
    "\n",
    "### How it works and what's the main difference with word2vec?\n",
    "The main point in this section is that StarSpace can be trained specifically for some tasks. In contrast to word2vec model, which tries to train similar embeddings for words in similar contexts, StarSpace uses embeddings for the whole sentence (just as a sum of embeddings of words and phrases). Despite the fact that in both cases we get word embeddings as a result of the training, StarSpace embeddings are trained using some supervised data, e.g. a set of similar sentence pairs, and thus they can better suit the task.\n",
    "\n",
    "In our case, StarSpace should use two types of sentence pairs for training: \"positive\" and \"negative\". \"Positive\" examples are extracted from the train sample (duplicates, high similarity) and the \"negative\" examples are generated randomly (low similarity assumed). \n",
    "\n",
    "### How to choose the best params for the model?\n",
    "Normally, you would start with some default choice and then run extensive experiments to compare different strategies. However, we have some recommendations ready for you to save your time:\n",
    "- Be careful with choosing the suitable training mode. In this task we want to explore texts similarity which corresponds to *trainMode = 3*.\n",
    "- Use adagrad optimization (parameter *adagrad = true*).\n",
    "- Set the length of phrase equal to 1 (parameter *ngrams*), because we need embeddings only for words.\n",
    "- Don't use a large number of *epochs* (we think that 5 should be enough).\n",
    "- Try dimension *dim* equal to 100.\n",
    "- To compare embeddings usually *cosine* *similarity* is used.\n",
    "- Set *minCount* greater than 1 (for example, 2) if you don't want to get embeddings for extremely rare words.\n",
    "- Parameter *verbose = true* could show you the progress of the training process.\n",
    "- Set parameter *fileFormat* equals *labelDoc*.\n",
    "- Parameter *negSearchLimit* is responsible for a number of negative examples which is used during the training. We think that 10 will be enought for this task.\n",
    "- To increase a speed of training we recommend to set *learning rate* to 0.05."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train StarSpace embeddings for unigrams on the train dataset. You don't need to change the format of the input data. Just don't forget to use prepared version of the training data. \n",
    "\n",
    "If you follow the instruction, the training process will take about 1 hour."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arguments: \n",
      "lr: 0.05\n",
      "dim: 100\n",
      "epoch: 5\n",
      "maxTrainTime: 8640000\n",
      "saveEveryEpoch: 0\n",
      "loss: hinge\n",
      "margin: 0.05\n",
      "similarity: cosine\n",
      "maxNegSamples: 10\n",
      "negSearchLimit: 10\n",
      "thread: 4\n",
      "minCount: 2\n",
      "minCountLabel: 1\n",
      "label: __label__\n",
      "ngrams: 1\n",
      "bucket: 2000000\n",
      "adagrad: 1\n",
      "trainMode: 3\n",
      "fileFormat: labelDoc\n",
      "normalizeText: 0\n",
      "dropoutLHS: 0\n",
      "dropoutRHS: 0\n",
      "Start to initialize starspace model.\n",
      "Build dict from input file : data/train_prepped.tsv\n",
      "Read 12M words\n",
      "Number of words in dictionary:  95058\n",
      "Number of labels in dictionary: 0\n",
      "Loading data from file : data/train_prepped.tsv\n",
      "Total number of examples loaded : 999740\n",
      "Initialized model weights. Model size :\n",
      "matrix : 95058 100\n",
      "Training epoch 0: 0.05 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31.9%  lr: 0.046677  loss: 0.013675  eta: 0h44m  tot: 0h3m1s  (6.4%))1%  lr: 0.050000  loss: 0.096849  eta: 0h53m  tot: 0h0m0s  (0.0%)0.2%  lr: 0.049990  loss: 0.083848  eta: 0h51m  tot: 0h0m1s  (0.0%)0.4%  lr: 0.049970  loss: 0.066353  eta: 0h50m  tot: 0h0m2s  (0.1%)0.5%  lr: 0.049970  loss: 0.063756  eta: 0h50m  tot: 0h0m3s  (0.1%)0.5%  lr: 0.049970  loss: 0.062025  eta: 0h50m  tot: 0h0m3s  (0.1%)0.6%  lr: 0.049940  loss: 0.058346  eta: 0h49m  tot: 0h0m3s  (0.1%)0.7%  lr: 0.049930  loss: 0.057056  eta: 0h49m  tot: 0h0m3s  (0.1%)%  lr: 0.049860  loss: 0.047368  eta: 0h49m  tot: 0h0m7s  (0.2%)%  lr: 0.049850  loss: 0.046807  eta: 0h49m  tot: 0h0m7s  (0.2%)1.3%  lr: 0.049820  loss: 0.045733  eta: 0h49m  tot: 0h0m7s  (0.3%)1.3%  lr: 0.049820  loss: 0.045130  eta: 0h48m  tot: 0h0m7s  (0.3%)1.3%  lr: 0.049810  loss: 0.044686  eta: 0h48m  tot: 0h0m7s  (0.3%)1.5%  lr: 0.049790  loss: 0.043370  eta: 0h49m  tot: 0h0m8s  (0.3%)2.3%  lr: 0.049680  loss: 0.037703  eta: 0h48m  tot: 0h0m13s  (0.5%)%  lr: 0.049670  loss: 0.036783  eta: 0h48m  tot: 0h0m14s  (0.5%)3.6%  lr: 0.049590  loss: 0.032112  eta: 0h47m  tot: 0h0m21s  (0.7%)3.8%  lr: 0.049580  loss: 0.031714  eta: 0h47m  tot: 0h0m21s  (0.8%)3.8%  lr: 0.049570  loss: 0.031553  eta: 0h47m  tot: 0h0m22s  (0.8%)3.9%  lr: 0.049560  loss: 0.031399  eta: 0h47m  tot: 0h0m22s  (0.8%)4.0%  lr: 0.049540  loss: 0.031034  eta: 0h47m  tot: 0h0m23s  (0.8%)4.5%  lr: 0.049500  loss: 0.030022  eta: 0h47m  tot: 0h0m26s  (0.9%)%  lr: 0.049489  loss: 0.029093  eta: 0h47m  tot: 0h0m27s  (1.0%)4.8%  lr: 0.049479  loss: 0.029045  eta: 0h47m  tot: 0h0m27s  (1.0%)4.9%  lr: 0.049479  loss: 0.028805  eta: 0h47m  tot: 0h0m28s  (1.0%)5.0%  lr: 0.049479  loss: 0.028604  eta: 0h47m  tot: 0h0m28s  (1.0%)5.0%  lr: 0.049479  loss: 0.028461  eta: 0h47m  tot: 0h0m29s  (1.0%)7.3%  lr: 0.049219  loss: 0.024556  eta: 0h49m  tot: 0h0m43s  (1.5%)8.0%  lr: 0.049149  loss: 0.023696  eta: 0h49m  tot: 0h0m47s  (1.6%)8.1%  lr: 0.049119  loss: 0.023537  eta: 0h49m  tot: 0h0m48s  (1.6%)8.3%  lr: 0.049099  loss: 0.023265  eta: 0h49m  tot: 0h0m50s  (1.7%)8.6%  lr: 0.049079  loss: 0.022957  eta: 0h49m  tot: 0h0m51s  (1.7%)8.7%  lr: 0.049039  loss: 0.022828  eta: 0h49m  tot: 0h0m52s  (1.7%)8.9%  lr: 0.048999  loss: 0.022531  eta: 0h49m  tot: 0h0m54s  (1.8%)9.0%  lr: 0.048989  loss: 0.022418  eta: 0h49m  tot: 0h0m54s  (1.8%)9.2%  lr: 0.048989  loss: 0.022251  eta: 0h49m  tot: 0h0m56s  (1.8%)9.5%  lr: 0.048969  loss: 0.022036  eta: 0h49m  tot: 0h0m57s  (1.9%)9.6%  lr: 0.048959  loss: 0.021915  eta: 0h50m  tot: 0h0m59s  (1.9%)9.8%  lr: 0.048949  loss: 0.021796  eta: 0h50m  tot: 0h0m59s  (2.0%)9.9%  lr: 0.048939  loss: 0.021715  eta: 0h50m  tot: 0h1m0s  (2.0%)10.2%  lr: 0.048929  loss: 0.021402  eta: 0h49m  tot: 0h1m2s  (2.0%)10.9%  lr: 0.048899  loss: 0.020872  eta: 0h49m  tot: 0h1m5s  (2.2%)11.4%  lr: 0.048859  loss: 0.020435  eta: 0h49m  tot: 0h1m9s  (2.3%)11.6%  lr: 0.048839  loss: 0.020259  eta: 0h48m  tot: 0h1m9s  (2.3%)11.8%  lr: 0.048819  loss: 0.020221  eta: 0h48m  tot: 0h1m10s  (2.4%)11.9%  lr: 0.048789  loss: 0.020072  eta: 0h48m  tot: 0h1m11s  (2.4%)12.0%  lr: 0.048789  loss: 0.020028  eta: 0h48m  tot: 0h1m11s  (2.4%)12.1%  lr: 0.048789  loss: 0.020005  eta: 0h48m  tot: 0h1m12s  (2.4%)12.5%  lr: 0.048729  loss: 0.019738  eta: 0h48m  tot: 0h1m14s  (2.5%)12.8%  lr: 0.048729  loss: 0.019617  eta: 0h48m  tot: 0h1m15s  (2.6%)13.5%  lr: 0.048649  loss: 0.019190  eta: 0h47m  tot: 0h1m19s  (2.7%)13.6%  lr: 0.048639  loss: 0.019139  eta: 0h47m  tot: 0h1m19s  (2.7%)13.9%  lr: 0.048599  loss: 0.018958  eta: 0h47m  tot: 0h1m21s  (2.8%)13.9%  lr: 0.048599  loss: 0.018934  eta: 0h47m  tot: 0h1m21s  (2.8%)14.4%  lr: 0.048539  loss: 0.018665  eta: 0h46m  tot: 0h1m23s  (2.9%)14.5%  lr: 0.048539  loss: 0.018655  eta: 0h46m  tot: 0h1m23s  (2.9%)%  lr: 0.048509  loss: 0.018437  eta: 0h46m  tot: 0h1m26s  (3.0%)15.3%  lr: 0.048458  loss: 0.018222  eta: 0h46m  tot: 0h1m28s  (3.1%)15.5%  lr: 0.048438  loss: 0.018172  eta: 0h46m  tot: 0h1m28s  (3.1%)15.7%  lr: 0.048398  loss: 0.018075  eta: 0h46m  tot: 0h1m29s  (3.1%)15.7%  lr: 0.048388  loss: 0.018067  eta: 0h46m  tot: 0h1m30s  (3.1%)15.8%  lr: 0.048368  loss: 0.018042  eta: 0h46m  tot: 0h1m30s  (3.2%)16.3%  lr: 0.048328  loss: 0.017850  eta: 0h46m  tot: 0h1m33s  (3.3%)16.8%  lr: 0.048268  loss: 0.017615  eta: 0h45m  tot: 0h1m36s  (3.4%)17.1%  lr: 0.048248  loss: 0.017469  eta: 0h46m  tot: 0h1m37s  (3.4%)17.4%  lr: 0.048218  loss: 0.017359  eta: 0h46m  tot: 0h1m39s  (3.5%)17.7%  lr: 0.048178  loss: 0.017268  eta: 0h46m  tot: 0h1m41s  (3.5%)%  lr: 0.048178  loss: 0.017261  eta: 0h46m  tot: 0h1m41s  (3.5%)17.8%  lr: 0.048168  loss: 0.017257  eta: 0h46m  tot: 0h1m41s  (3.6%)18.0%  lr: 0.048158  loss: 0.017167  eta: 0h46m  tot: 0h1m43s  (3.6%)18.3%  lr: 0.048128  loss: 0.017044  eta: 0h45m  tot: 0h1m44s  (3.7%)18.6%  lr: 0.048088  loss: 0.016955  eta: 0h45m  tot: 0h1m46s  (3.7%)19.1%  lr: 0.048038  loss: 0.016821  eta: 0h45m  tot: 0h1m48s  (3.8%)19.7%  lr: 0.047958  loss: 0.016585  eta: 0h45m  tot: 0h1m52s  (3.9%)19.8%  lr: 0.047958  loss: 0.016554  eta: 0h45m  tot: 0h1m53s  (4.0%)20.3%  lr: 0.047878  loss: 0.016382  eta: 0h45m  tot: 0h1m56s  (4.1%)20.3%  lr: 0.047878  loss: 0.016355  eta: 0h45m  tot: 0h1m56s  (4.1%)20.8%  lr: 0.047778  loss: 0.016215  eta: 0h45m  tot: 0h1m59s  (4.2%)20.8%  lr: 0.047768  loss: 0.016205  eta: 0h45m  tot: 0h1m59s  (4.2%)20.9%  lr: 0.047728  loss: 0.016159  eta: 0h45m  tot: 0h2m0s  (4.2%)21.5%  lr: 0.047678  loss: 0.015959  eta: 0h45m  tot: 0h2m3s  (4.3%)22.0%  lr: 0.047608  loss: 0.015802  eta: 0h45m  tot: 0h2m6s  (4.4%)22.2%  lr: 0.047598  loss: 0.015724  eta: 0h45m  tot: 0h2m7s  (4.4%)22.3%  lr: 0.047578  loss: 0.015709  eta: 0h45m  tot: 0h2m7s  (4.5%)23.1%  lr: 0.047528  loss: 0.015470  eta: 0h45m  tot: 0h2m12s  (4.6%)23.6%  lr: 0.047498  loss: 0.015350  eta: 0h45m  tot: 0h2m14s  (4.7%)24.2%  lr: 0.047417  loss: 0.015189  eta: 0h45m  tot: 0h2m18s  (4.8%)24.6%  lr: 0.047357  loss: 0.015111  eta: 0h45m  tot: 0h2m20s  (4.9%)24.7%  lr: 0.047347  loss: 0.015084  eta: 0h45m  tot: 0h2m21s  (4.9%)25.3%  lr: 0.047317  loss: 0.014968  eta: 0h45m  tot: 0h2m24s  (5.1%)25.4%  lr: 0.047307  loss: 0.014949  eta: 0h45m  tot: 0h2m25s  (5.1%)25.8%  lr: 0.047257  loss: 0.014866  eta: 0h45m  tot: 0h2m27s  (5.2%)25.9%  lr: 0.047207  loss: 0.014845  eta: 0h45m  tot: 0h2m28s  (5.2%)26.1%  lr: 0.047177  loss: 0.014806  eta: 0h45m  tot: 0h2m29s  (5.2%)26.2%  lr: 0.047177  loss: 0.014784  eta: 0h45m  tot: 0h2m29s  (5.2%)27.0%  lr: 0.047097  loss: 0.014589  eta: 0h44m  tot: 0h2m34s  (5.4%)27.4%  lr: 0.047067  loss: 0.014510  eta: 0h44m  tot: 0h2m36s  (5.5%)27.6%  lr: 0.047057  loss: 0.014470  eta: 0h44m  tot: 0h2m37s  (5.5%)28.0%  lr: 0.047037  loss: 0.014399  eta: 0h44m  tot: 0h2m39s  (5.6%)28.0%  lr: 0.047037  loss: 0.014381  eta: 0h44m  tot: 0h2m39s  (5.6%)28.3%  lr: 0.047007  loss: 0.014329  eta: 0h44m  tot: 0h2m41s  (5.7%)28.5%  lr: 0.046967  loss: 0.014283  eta: 0h44m  tot: 0h2m42s  (5.7%)28.7%  lr: 0.046927  loss: 0.014261  eta: 0h44m  tot: 0h2m43s  (5.7%)28.8%  lr: 0.046897  loss: 0.014239  eta: 0h44m  tot: 0h2m44s  (5.8%)28.8%  lr: 0.046897  loss: 0.014221  eta: 0h44m  tot: 0h2m44s  (5.8%)29.4%  lr: 0.046857  loss: 0.014114  eta: 0h44m  tot: 0h2m47s  (5.9%)29.4%  lr: 0.046857  loss: 0.014107  eta: 0h44m  tot: 0h2m47s  (5.9%)29.5%  lr: 0.046857  loss: 0.014093  eta: 0h44m  tot: 0h2m47s  (5.9%)29.7%  lr: 0.046827  loss: 0.014055  eta: 0h44m  tot: 0h2m49s  (5.9%)29.9%  lr: 0.046827  loss: 0.014029  eta: 0h44m  tot: 0h2m49s  (6.0%)30.1%  lr: 0.046827  loss: 0.013988  eta: 0h44m  tot: 0h2m50s  (6.0%)30.1%  lr: 0.046827  loss: 0.013984  eta: 0h44m  tot: 0h2m50s  (6.0%)30.2%  lr: 0.046827  loss: 0.013965  eta: 0h44m  tot: 0h2m51s  (6.0%)%  lr: 0.046827  loss: 0.013937  eta: 0h44m  tot: 0h2m52s  (6.1%)31.2%  lr: 0.046737  loss: 0.013800  eta: 0h44m  tot: 0h2m57s  (6.2%)31.6%  lr: 0.046717  loss: 0.013731  eta: 0h44m  tot: 0h2m59s  (6.3%)31.7%  lr: 0.046717  loss: 0.013719  eta: 0h44m  tot: 0h2m59s  (6.3%)31.8%  lr: 0.046707  loss: 0.013690  eta: 0h44m  tot: 0h3m0s  (6.4%)31.8%  lr: 0.046677  loss: 0.013689  eta: 0h44m  tot: 0h3m0s  (6.4%)31.9%  lr: 0.046677  loss: 0.013673  eta: 0h44m  tot: 0h3m1s  (6.4%)Epoch: 65.5%  lr: 0.043073  loss: 0.010276  eta: 0h41m  tot: 0h6m19s  (13.1%) lr: 0.046667  loss: 0.013647  eta: 0h44m  tot: 0h3m2s  (6.4%)32.3%  lr: 0.046657  loss: 0.013607  eta: 0h44m  tot: 0h3m3s  (6.5%)32.9%  lr: 0.046627  loss: 0.013497  eta: 0h44m  tot: 0h3m6s  (6.6%)33.0%  lr: 0.046617  loss: 0.013479  eta: 0h44m  tot: 0h3m7s  (6.6%)33.0%  lr: 0.046617  loss: 0.013470  eta: 0h44m  tot: 0h3m7s  (6.6%)33.1%  lr: 0.046617  loss: 0.013463  eta: 0h44m  tot: 0h3m8s  (6.6%)33.2%  lr: 0.046607  loss: 0.013439  eta: 0h44m  tot: 0h3m9s  (6.6%)33.4%  lr: 0.046597  loss: 0.013413  eta: 0h44m  tot: 0h3m10s  (6.7%)33.5%  lr: 0.046597  loss: 0.013406  eta: 0h44m  tot: 0h3m10s  (6.7%)34.1%  lr: 0.046547  loss: 0.013300  eta: 0h44m  tot: 0h3m13s  (6.8%)34.7%  lr: 0.046507  loss: 0.013201  eta: 0h44m  tot: 0h3m17s  (6.9%)35.0%  lr: 0.046467  loss: 0.013163  eta: 0h44m  tot: 0h3m19s  (7.0%)35.0%  lr: 0.046457  loss: 0.013159  eta: 0h44m  tot: 0h3m19s  (7.0%)35.4%  lr: 0.046436  loss: 0.013094  eta: 0h44m  tot: 0h3m21s  (7.1%)35.8%  lr: 0.046396  loss: 0.013024  eta: 0h44m  tot: 0h3m24s  (7.2%)36.5%  lr: 0.046326  loss: 0.012935  eta: 0h44m  tot: 0h3m27s  (7.3%)37.1%  lr: 0.046216  loss: 0.012843  eta: 0h44m  tot: 0h3m31s  (7.4%)37.3%  lr: 0.046196  loss: 0.012809  eta: 0h43m  tot: 0h3m33s  (7.5%)37.5%  lr: 0.046186  loss: 0.012776  eta: 0h43m  tot: 0h3m34s  (7.5%)38.1%  lr: 0.046086  loss: 0.012702  eta: 0h43m  tot: 0h3m37s  (7.6%)38.7%  lr: 0.046046  loss: 0.012620  eta: 0h43m  tot: 0h3m40s  (7.7%)38.7%  lr: 0.046046  loss: 0.012613  eta: 0h43m  tot: 0h3m40s  (7.7%)39.2%  lr: 0.046006  loss: 0.012561  eta: 0h43m  tot: 0h3m43s  (7.8%)39.9%  lr: 0.045966  loss: 0.012464  eta: 0h43m  tot: 0h3m47s  (8.0%)40.4%  lr: 0.045936  loss: 0.012403  eta: 0h43m  tot: 0h3m49s  (8.1%)40.6%  lr: 0.045916  loss: 0.012381  eta: 0h43m  tot: 0h3m50s  (8.1%)40.9%  lr: 0.045886  loss: 0.012353  eta: 0h43m  tot: 0h3m52s  (8.2%)41.1%  lr: 0.045886  loss: 0.012322  eta: 0h43m  tot: 0h3m53s  (8.2%)41.4%  lr: 0.045866  loss: 0.012292  eta: 0h43m  tot: 0h3m55s  (8.3%)41.9%  lr: 0.045806  loss: 0.012234  eta: 0h43m  tot: 0h3m57s  (8.4%)42.3%  lr: 0.045756  loss: 0.012186  eta: 0h43m  tot: 0h4m0s  (8.5%)42.5%  lr: 0.045736  loss: 0.012169  eta: 0h43m  tot: 0h4m0s  (8.5%)42.5%  lr: 0.045716  loss: 0.012160  eta: 0h43m  tot: 0h4m1s  (8.5%)42.9%  lr: 0.045686  loss: 0.012120  eta: 0h43m  tot: 0h4m2s  (8.6%)43.2%  lr: 0.045636  loss: 0.012079  eta: 0h43m  tot: 0h4m4s  (8.6%)43.2%  lr: 0.045626  loss: 0.012068  eta: 0h43m  tot: 0h4m5s  (8.6%)43.6%  lr: 0.045586  loss: 0.012035  eta: 0h43m  tot: 0h4m6s  (8.7%)44.0%  lr: 0.045556  loss: 0.011994  eta: 0h43m  tot: 0h4m9s  (8.8%)44.1%  lr: 0.045546  loss: 0.011989  eta: 0h43m  tot: 0h4m9s  (8.8%)44.2%  lr: 0.045516  loss: 0.011979  eta: 0h42m  tot: 0h4m9s  (8.8%)%  lr: 0.045476  loss: 0.011935  eta: 0h42m  tot: 0h4m12s  (8.9%)44.7%  lr: 0.045466  loss: 0.011913  eta: 0h42m  tot: 0h4m13s  (8.9%)44.8%  lr: 0.045466  loss: 0.011911  eta: 0h42m  tot: 0h4m13s  (9.0%)45.2%  lr: 0.045456  loss: 0.011866  eta: 0h42m  tot: 0h4m15s  (9.0%)45.6%  lr: 0.045345  loss: 0.011815  eta: 0h42m  tot: 0h4m17s  (9.1%)45.9%  lr: 0.045285  loss: 0.011792  eta: 0h42m  tot: 0h4m19s  (9.2%)46.0%  lr: 0.045275  loss: 0.011780  eta: 0h42m  tot: 0h4m19s  (9.2%)46.2%  lr: 0.045215  loss: 0.011759  eta: 0h42m  tot: 0h4m20s  (9.2%)46.3%  lr: 0.045195  loss: 0.011747  eta: 0h42m  tot: 0h4m21s  (9.3%)46.4%  lr: 0.045195  loss: 0.011743  eta: 0h42m  tot: 0h4m21s  (9.3%)47.1%  lr: 0.045165  loss: 0.011663  eta: 0h42m  tot: 0h4m25s  (9.4%)47.2%  lr: 0.045145  loss: 0.011654  eta: 0h42m  tot: 0h4m26s  (9.4%)47.4%  lr: 0.045105  loss: 0.011633  eta: 0h42m  tot: 0h4m27s  (9.5%)47.5%  lr: 0.045105  loss: 0.011628  eta: 0h42m  tot: 0h4m27s  (9.5%)47.6%  lr: 0.045095  loss: 0.011616  eta: 0h42m  tot: 0h4m28s  (9.5%)47.9%  lr: 0.045075  loss: 0.011588  eta: 0h42m  tot: 0h4m30s  (9.6%)48.0%  lr: 0.045065  loss: 0.011580  eta: 0h42m  tot: 0h4m30s  (9.6%)48.1%  lr: 0.045055  loss: 0.011570  eta: 0h42m  tot: 0h4m31s  (9.6%)48.2%  lr: 0.045025  loss: 0.011559  eta: 0h42m  tot: 0h4m32s  (9.6%)48.3%  lr: 0.045005  loss: 0.011549  eta: 0h42m  tot: 0h4m33s  (9.7%)48.4%  lr: 0.044985  loss: 0.011542  eta: 0h42m  tot: 0h4m33s  (9.7%)48.5%  lr: 0.044975  loss: 0.011524  eta: 0h42m  tot: 0h4m34s  (9.7%)48.6%  lr: 0.044965  loss: 0.011520  eta: 0h42m  tot: 0h4m34s  (9.7%)49.5%  lr: 0.044885  loss: 0.011443  eta: 0h42m  tot: 0h4m40s  (9.9%)49.8%  lr: 0.044845  loss: 0.011411  eta: 0h42m  tot: 0h4m42s  (10.0%)50.1%  lr: 0.044825  loss: 0.011381  eta: 0h42m  tot: 0h4m44s  (10.0%)50.4%  lr: 0.044785  loss: 0.011358  eta: 0h42m  tot: 0h4m45s  (10.1%)50.8%  lr: 0.044775  loss: 0.011322  eta: 0h42m  tot: 0h4m48s  (10.2%)51.0%  lr: 0.044755  loss: 0.011300  eta: 0h42m  tot: 0h4m49s  (10.2%)51.3%  lr: 0.044725  loss: 0.011271  eta: 0h42m  tot: 0h4m51s  (10.3%)51.5%  lr: 0.044695  loss: 0.011253  eta: 0h42m  tot: 0h4m52s  (10.3%)51.6%  lr: 0.044695  loss: 0.011252  eta: 0h42m  tot: 0h4m53s  (10.3%)52.1%  lr: 0.044595  loss: 0.011210  eta: 0h42m  tot: 0h4m56s  (10.4%)52.4%  lr: 0.044585  loss: 0.011192  eta: 0h42m  tot: 0h4m58s  (10.5%)52.9%  lr: 0.044575  loss: 0.011147  eta: 0h42m  tot: 0h5m1s  (10.6%)53.0%  lr: 0.044575  loss: 0.011140  eta: 0h42m  tot: 0h5m2s  (10.6%)53.1%  lr: 0.044515  loss: 0.011136  eta: 0h42m  tot: 0h5m2s  (10.6%)53.6%  lr: 0.044455  loss: 0.011093  eta: 0h42m  tot: 0h5m5s  (10.7%)0h5m17s  (11.1%)55.7%  lr: 0.044224  loss: 0.010926  eta: 0h42m  tot: 0h5m18s  (11.1%)55.8%  lr: 0.044224  loss: 0.010921  eta: 0h42m  tot: 0h5m19s  (11.2%)56.3%  lr: 0.044194  loss: 0.010880  eta: 0h42m  tot: 0h5m22s  (11.3%)56.3%  lr: 0.044194  loss: 0.010872  eta: 0h42m  tot: 0h5m22s  (11.3%)56.6%  lr: 0.044154  loss: 0.010848  eta: 0h42m  tot: 0h5m24s  (11.3%)57.0%  lr: 0.044114  loss: 0.010816  eta: 0h42m  tot: 0h5m26s  (11.4%)57.5%  lr: 0.044014  loss: 0.010783  eta: 0h42m  tot: 0h5m30s  (11.5%)57.7%  lr: 0.043984  loss: 0.010767  eta: 0h42m  tot: 0h5m31s  (11.5%)58.1%  lr: 0.043934  loss: 0.010747  eta: 0h42m  tot: 0h5m33s  (11.6%)58.2%  lr: 0.043924  loss: 0.010736  eta: 0h42m  tot: 0h5m34s  (11.6%)58.3%  lr: 0.043924  loss: 0.010731  eta: 0h42m  tot: 0h5m35s  (11.7%)59.0%  lr: 0.043884  loss: 0.010678  eta: 0h42m  tot: 0h5m39s  (11.8%)59.4%  lr: 0.043794  loss: 0.010656  eta: 0h42m  tot: 0h5m41s  (11.9%)59.7%  lr: 0.043764  loss: 0.010633  eta: 0h42m  tot: 0h5m43s  (11.9%)59.9%  lr: 0.043744  loss: 0.010614  eta: 0h42m  tot: 0h5m45s  (12.0%)60.0%  lr: 0.043724  loss: 0.010611  eta: 0h42m  tot: 0h5m45s  (12.0%)60.0%  lr: 0.043714  loss: 0.010606  eta: 0h42m  tot: 0h5m46s  (12.0%)60.2%  lr: 0.043694  loss: 0.010599  eta: 0h42m  tot: 0h5m46s  (12.0%)60.6%  lr: 0.043664  loss: 0.010575  eta: 0h42m  tot: 0h5m49s  (12.1%)61.1%  lr: 0.043604  loss: 0.010546  eta: 0h42m  tot: 0h5m52s  (12.2%)61.4%  lr: 0.043574  loss: 0.010526  eta: 0h42m  tot: 0h5m53s  (12.3%)61.5%  lr: 0.043574  loss: 0.010518  eta: 0h42m  tot: 0h5m54s  (12.3%)62.1%  lr: 0.043514  loss: 0.010485  eta: 0h42m  tot: 0h5m58s  (12.4%)62.3%  lr: 0.043434  loss: 0.010468  eta: 0h42m  tot: 0h6m0s  (12.5%)62.4%  lr: 0.043424  loss: 0.010467  eta: 0h42m  tot: 0h6m0s  (12.5%)62.5%  lr: 0.043404  loss: 0.010460  eta: 0h42m  tot: 0h6m1s  (12.5%)62.6%  lr: 0.043363  loss: 0.010455  eta: 0h42m  tot: 0h6m1s  (12.5%)62.7%  lr: 0.043343  loss: 0.010450  eta: 0h42m  tot: 0h6m2s  (12.5%)63.1%  lr: 0.043313  loss: 0.010428  eta: 0h42m  tot: 0h6m4s  (12.6%)63.2%  lr: 0.043293  loss: 0.010417  eta: 0h42m  tot: 0h6m5s  (12.6%)63.5%  lr: 0.043263  loss: 0.010396  eta: 0h42m  tot: 0h6m7s  (12.7%)63.5%  lr: 0.043263  loss: 0.010394  eta: 0h42m  tot: 0h6m7s  (12.7%)63.9%  lr: 0.043233  loss: 0.010376  eta: 0h42m  tot: 0h6m9s  (12.8%)64.0%  lr: 0.043223  loss: 0.010368  eta: 0h42m  tot: 0h6m10s  (12.8%)64.8%  lr: 0.043163  loss: 0.010320  eta: 0h41m  tot: 0h6m15s  (13.0%)65.1%  lr: 0.043133  loss: 0.010298  eta: 0h41m  tot: 0h6m17s  (13.0%)65.2%  lr: 0.043123  loss: 0.010295  eta: 0h41m  tot: 0h6m17s  (13.0%)65.3%  lr: 0.043093  loss: 0.010286  eta: 0h41m  tot: 0h6m18s  (13.1%)65.4%  lr: 0.043073  loss: 0.010281  eta: 0h41m  tot: 0h6m19s  (13.1%)65.5%  lr: 0.043063  loss: 0.010275  eta: 0h41m  tot: 0h6m19s  (13.1%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100.0%  lr: 0.040000  loss: 0.008810  eta: 0h38m  tot: 0h9m37s  (20.0%)5.6%  lr: 0.043043  loss: 0.010267  eta: 0h41m  tot: 0h6m20s  (13.1%)65.9%  lr: 0.043023  loss: 0.010247  eta: 0h41m  tot: 0h6m22s  (13.2%)66.0%  lr: 0.043013  loss: 0.010242  eta: 0h41m  tot: 0h6m22s  (13.2%)66.1%  lr: 0.043013  loss: 0.010232  eta: 0h41m  tot: 0h6m23s  (13.2%)%  lr: 0.042983  loss: 0.010220  eta: 0h41m  tot: 0h6m25s  (13.3%)66.5%  lr: 0.042983  loss: 0.010214  eta: 0h41m  tot: 0h6m25s  (13.3%)66.7%  lr: 0.042973  loss: 0.010203  eta: 0h41m  tot: 0h6m27s  (13.3%)66.8%  lr: 0.042953  loss: 0.010200  eta: 0h41m  tot: 0h6m27s  (13.4%)66.9%  lr: 0.042943  loss: 0.010198  eta: 0h41m  tot: 0h6m27s  (13.4%)67.4%  lr: 0.042893  loss: 0.010168  eta: 0h41m  tot: 0h6m31s  (13.5%)67.5%  lr: 0.042853  loss: 0.010159  eta: 0h41m  tot: 0h6m32s  (13.5%)67.9%  lr: 0.042833  loss: 0.010138  eta: 0h41m  tot: 0h6m34s  (13.6%)68.1%  lr: 0.042823  loss: 0.010131  eta: 0h41m  tot: 0h6m35s  (13.6%)68.4%  lr: 0.042763  loss: 0.010115  eta: 0h41m  tot: 0h6m37s  (13.7%)68.8%  lr: 0.042753  loss: 0.010085  eta: 0h41m  tot: 0h6m40s  (13.8%)69.0%  lr: 0.042723  loss: 0.010073  eta: 0h41m  tot: 0h6m41s  (13.8%)69.4%  lr: 0.042683  loss: 0.010053  eta: 0h41m  tot: 0h6m44s  (13.9%)69.6%  lr: 0.042673  loss: 0.010044  eta: 0h41m  tot: 0h6m44s  (13.9%)70.2%  lr: 0.042573  loss: 0.010011  eta: 0h41m  tot: 0h6m48s  (14.0%)70.6%  lr: 0.042553  loss: 0.009995  eta: 0h41m  tot: 0h6m51s  (14.1%)71.1%  lr: 0.042503  loss: 0.009968  eta: 0h41m  tot: 0h6m54s  (14.2%)71.4%  lr: 0.042503  loss: 0.009948  eta: 0h41m  tot: 0h6m56s  (14.3%)71.8%  lr: 0.042433  loss: 0.009927  eta: 0h41m  tot: 0h6m58s  (14.4%)72.0%  lr: 0.042413  loss: 0.009916  eta: 0h41m  tot: 0h7m0s  (14.4%)72.1%  lr: 0.042393  loss: 0.009913  eta: 0h41m  tot: 0h7m0s  (14.4%)72.3%  lr: 0.042393  loss: 0.009905  eta: 0h41m  tot: 0h7m1s  (14.5%)72.4%  lr: 0.042362  loss: 0.009900  eta: 0h41m  tot: 0h7m2s  (14.5%)72.5%  lr: 0.042362  loss: 0.009897  eta: 0h41m  tot: 0h7m2s  (14.5%)72.9%  lr: 0.042322  loss: 0.009871  eta: 0h41m  tot: 0h7m5s  (14.6%)73.2%  lr: 0.042312  loss: 0.009857  eta: 0h41m  tot: 0h7m7s  (14.6%)73.3%  lr: 0.042312  loss: 0.009852  eta: 0h41m  tot: 0h7m7s  (14.7%)73.5%  lr: 0.042302  loss: 0.009839  eta: 0h41m  tot: 0h7m8s  (14.7%)73.8%  lr: 0.042282  loss: 0.009826  eta: 0h41m  tot: 0h7m10s  (14.8%)74.2%  lr: 0.042262  loss: 0.009809  eta: 0h41m  tot: 0h7m13s  (14.8%)74.4%  lr: 0.042232  loss: 0.009803  eta: 0h41m  tot: 0h7m14s  (14.9%)75.0%  lr: 0.042182  loss: 0.009785  eta: 0h41m  tot: 0h7m18s  (15.0%)75.1%  lr: 0.042172  loss: 0.009780  eta: 0h41m  tot: 0h7m19s  (15.0%)75.4%  lr: 0.042162  loss: 0.009768  eta: 0h41m  tot: 0h7m20s  (15.1%)76.1%  lr: 0.042082  loss: 0.009732  eta: 0h41m  tot: 0h7m25s  (15.2%)76.2%  lr: 0.042072  loss: 0.009728  eta: 0h41m  tot: 0h7m25s  (15.2%)76.4%  lr: 0.042042  loss: 0.009717  eta: 0h41m  tot: 0h7m27s  (15.3%)76.6%  lr: 0.042032  loss: 0.009710  eta: 0h41m  tot: 0h7m28s  (15.3%)77.1%  lr: 0.042012  loss: 0.009677  eta: 0h41m  tot: 0h7m31s  (15.4%)77.4%  lr: 0.041992  loss: 0.009665  eta: 0h41m  tot: 0h7m32s  (15.5%)78.2%  lr: 0.041962  loss: 0.009634  eta: 0h41m  tot: 0h7m37s  (15.6%)78.5%  lr: 0.041922  loss: 0.009621  eta: 0h41m  tot: 0h7m39s  (15.7%)78.9%  lr: 0.041892  loss: 0.009610  eta: 0h41m  tot: 0h7m41s  (15.8%)79.0%  lr: 0.041892  loss: 0.009606  eta: 0h41m  tot: 0h7m42s  (15.8%)79.6%  lr: 0.041792  loss: 0.009573  eta: 0h41m  tot: 0h7m46s  (15.9%)80.0%  lr: 0.041742  loss: 0.009554  eta: 0h41m  tot: 0h7m49s  (16.0%)80.2%  lr: 0.041742  loss: 0.009543  eta: 0h41m  tot: 0h7m50s  (16.0%)80.5%  lr: 0.041732  loss: 0.009536  eta: 0h41m  tot: 0h7m51s  (16.1%)80.8%  lr: 0.041672  loss: 0.009519  eta: 0h40m  tot: 0h7m54s  (16.2%)81.5%  lr: 0.041622  loss: 0.009484  eta: 0h40m  tot: 0h7m58s  (16.3%)81.6%  lr: 0.041612  loss: 0.009480  eta: 0h40m  tot: 0h7m58s  (16.3%)81.7%  lr: 0.041612  loss: 0.009477  eta: 0h40m  tot: 0h7m59s  (16.3%)81.7%  lr: 0.041602  loss: 0.009473  eta: 0h40m  tot: 0h7m59s  (16.3%)82.0%  lr: 0.041592  loss: 0.009460  eta: 0h40m  tot: 0h8m1s  (16.4%)82.4%  lr: 0.041582  loss: 0.009447  eta: 0h40m  tot: 0h8m3s  (16.5%)82.6%  lr: 0.041572  loss: 0.009441  eta: 0h40m  tot: 0h8m4s  (16.5%)82.9%  lr: 0.041542  loss: 0.009432  eta: 0h40m  tot: 0h8m6s  (16.6%)82.9%  lr: 0.041542  loss: 0.009430  eta: 0h40m  tot: 0h8m6s  (16.6%)83.0%  lr: 0.041542  loss: 0.009426  eta: 0h40m  tot: 0h8m7s  (16.6%)83.2%  lr: 0.041522  loss: 0.009417  eta: 0h40m  tot: 0h8m8s  (16.6%)83.7%  lr: 0.041462  loss: 0.009397  eta: 0h40m  tot: 0h8m11s  (16.7%)%  lr: 0.041462  loss: 0.009396  eta: 0h40m  tot: 0h8m11s  (16.8%)84.2%  lr: 0.041412  loss: 0.009378  eta: 0h40m  tot: 0h8m13s  (16.8%)%  lr: 0.041402  loss: 0.009373  eta: 0h40m  tot: 0h8m14s  (16.9%)84.6%  lr: 0.041361  loss: 0.009369  eta: 0h40m  tot: 0h8m15s  (16.9%)84.6%  lr: 0.041361  loss: 0.009368  eta: 0h40m  tot: 0h8m16s  (16.9%)84.7%  lr: 0.041361  loss: 0.009366  eta: 0h40m  tot: 0h8m16s  (16.9%)84.8%  lr: 0.041341  loss: 0.009359  eta: 0h40m  tot: 0h8m17s  (17.0%)85.0%  lr: 0.041331  loss: 0.009354  eta: 0h40m  tot: 0h8m18s  (17.0%)85.1%  lr: 0.041331  loss: 0.009350  eta: 0h40m  tot: 0h8m18s  (17.0%)85.4%  lr: 0.041301  loss: 0.009336  eta: 0h40m  tot: 0h8m20s  (17.1%)%  lr: 0.041301  loss: 0.009328  eta: 0h40m  tot: 0h8m21s  (17.1%)85.9%  lr: 0.041261  loss: 0.009314  eta: 0h40m  tot: 0h8m22s  (17.2%)86.0%  lr: 0.041231  loss: 0.009310  eta: 0h40m  tot: 0h8m23s  (17.2%)86.2%  lr: 0.041231  loss: 0.009302  eta: 0h40m  tot: 0h8m24s  (17.2%)86.5%  lr: 0.041201  loss: 0.009288  eta: 0h40m  tot: 0h8m25s  (17.3%)86.7%  lr: 0.041181  loss: 0.009279  eta: 0h40m  tot: 0h8m27s  (17.3%)%)87.2%  lr: 0.041161  loss: 0.009260  eta: 0h40m  tot: 0h8m29s  (17.4%)87.4%  lr: 0.041141  loss: 0.009249  eta: 0h40m  tot: 0h8m30s  (17.5%)88.4%  lr: 0.041031  loss: 0.009210  eta: 0h40m  tot: 0h8m36s  (17.7%)88.8%  lr: 0.041011  loss: 0.009192  eta: 0h40m  tot: 0h8m38s  (17.8%)88.8%  lr: 0.041001  loss: 0.009189  eta: 0h39m  tot: 0h8m38s  (17.8%)88.9%  lr: 0.040991  loss: 0.009187  eta: 0h39m  tot: 0h8m38s  (17.8%)89.0%  lr: 0.040991  loss: 0.009182  eta: 0h39m  tot: 0h8m39s  (17.8%)89.4%  lr: 0.040961  loss: 0.009164  eta: 0h39m  tot: 0h8m41s  (17.9%)89.8%  lr: 0.040931  loss: 0.009151  eta: 0h39m  tot: 0h8m44s  (18.0%)90.1%  lr: 0.040931  loss: 0.009144  eta: 0h39m  tot: 0h8m46s  (18.0%)90.1%  lr: 0.040931  loss: 0.009142  eta: 0h39m  tot: 0h8m46s  (18.0%)90.9%  lr: 0.040821  loss: 0.009112  eta: 0h39m  tot: 0h8m51s  (18.2%)91.0%  lr: 0.040791  loss: 0.009109  eta: 0h39m  tot: 0h8m51s  (18.2%)91.3%  lr: 0.040771  loss: 0.009102  eta: 0h39m  tot: 0h8m53s  (18.3%)91.3%  lr: 0.040761  loss: 0.009101  eta: 0h39m  tot: 0h8m53s  (18.3%)91.5%  lr: 0.040741  loss: 0.009095  eta: 0h39m  tot: 0h8m54s  (18.3%)91.5%  lr: 0.040721  loss: 0.009093  eta: 0h39m  tot: 0h8m55s  (18.3%)91.8%  lr: 0.040701  loss: 0.009081  eta: 0h39m  tot: 0h8m56s  (18.4%)92.5%  lr: 0.040601  loss: 0.009058  eta: 0h39m  tot: 0h9m0s  (18.5%)92.7%  lr: 0.040591  loss: 0.009052  eta: 0h39m  tot: 0h9m2s  (18.5%)92.9%  lr: 0.040571  loss: 0.009044  eta: 0h39m  tot: 0h9m3s  (18.6%)93.3%  lr: 0.040551  loss: 0.009034  eta: 0h39m  tot: 0h9m5s  (18.7%)93.9%  lr: 0.040461  loss: 0.009014  eta: 0h39m  tot: 0h9m9s  (18.8%)%  lr: 0.040371  loss: 0.008991  eta: 0h39m  tot: 0h9m12s  (18.9%)95.4%  lr: 0.040280  loss: 0.008958  eta: 0h39m  tot: 0h9m19s  (19.1%)95.5%  lr: 0.040280  loss: 0.008956  eta: 0h39m  tot: 0h9m19s  (19.1%)95.6%  lr: 0.040280  loss: 0.008952  eta: 0h39m  tot: 0h9m20s  (19.1%)95.8%  lr: 0.040250  loss: 0.008944  eta: 0h39m  tot: 0h9m21s  (19.2%)95.8%  lr: 0.040250  loss: 0.008941  eta: 0h39m  tot: 0h9m21s  (19.2%)96.0%  lr: 0.040230  loss: 0.008938  eta: 0h39m  tot: 0h9m22s  (19.2%)96.9%  lr: 0.040100  loss: 0.008914  eta: 0h39m  tot: 0h9m27s  (19.4%)\n",
      " ---+++                Epoch    0 Train error : 0.00891806 +++--- ���\n",
      "Training epoch 1: 0.04 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 29.4%  lr: 0.036857  loss: 0.002649  eta: 0h37m  tot: 0h12m33s  (25.9%)9%  lr: 0.039860  loss: 0.002882  eta: 0h40m  tot: 0h9m42s  (20.2%)1.3%  lr: 0.039820  loss: 0.002736  eta: 0h40m  tot: 0h9m45s  (20.3%)1.5%  lr: 0.039810  loss: 0.002672  eta: 0h40m  tot: 0h9m46s  (20.3%)1.5%  lr: 0.039810  loss: 0.002645  eta: 0h40m  tot: 0h9m46s  (20.3%)2.0%  lr: 0.039760  loss: 0.002652  eta: 0h40m  tot: 0h9m49s  (20.4%)2.1%  lr: 0.039760  loss: 0.002728  eta: 0h40m  tot: 0h9m50s  (20.4%)2.4%  lr: 0.039720  loss: 0.002732  eta: 0h39m  tot: 0h9m51s  (20.5%)2.7%  lr: 0.039680  loss: 0.002711  eta: 0h39m  tot: 0h9m53s  (20.5%)3.0%  lr: 0.039640  loss: 0.002640  eta: 0h39m  tot: 0h9m55s  (20.6%)3.6%  lr: 0.039590  loss: 0.002706  eta: 0h39m  tot: 0h9m58s  (20.7%)3.8%  lr: 0.039570  loss: 0.002729  eta: 0h39m  tot: 0h9m59s  (20.8%)4.1%  lr: 0.039550  loss: 0.002686  eta: 0h39m  tot: 0h10m1s  (20.8%)4.3%  lr: 0.039510  loss: 0.002691  eta: 0h39m  tot: 0h10m2s  (20.9%)4.5%  lr: 0.039500  loss: 0.002682  eta: 0h39m  tot: 0h10m3s  (20.9%)4.6%  lr: 0.039500  loss: 0.002652  eta: 0h39m  tot: 0h10m4s  (20.9%)4.7%  lr: 0.039479  loss: 0.002667  eta: 0h39m  tot: 0h10m5s  (20.9%)5.0%  lr: 0.039439  loss: 0.002663  eta: 0h39m  tot: 0h10m6s  (21.0%)5.3%  lr: 0.039419  loss: 0.002667  eta: 0h39m  tot: 0h10m8s  (21.1%)5.4%  lr: 0.039419  loss: 0.002678  eta: 0h39m  tot: 0h10m9s  (21.1%)5.5%  lr: 0.039399  loss: 0.002673  eta: 0h39m  tot: 0h10m10s  (21.1%)5.6%  lr: 0.039399  loss: 0.002668  eta: 0h39m  tot: 0h10m10s  (21.1%)6.2%  lr: 0.039319  loss: 0.002667  eta: 0h39m  tot: 0h10m13s  (21.2%)6.2%  lr: 0.039299  loss: 0.002674  eta: 0h39m  tot: 0h10m14s  (21.2%)6.5%  lr: 0.039279  loss: 0.002663  eta: 0h39m  tot: 0h10m16s  (21.3%)7.0%  lr: 0.039139  loss: 0.002641  eta: 0h39m  tot: 0h10m19s  (21.4%)7.3%  lr: 0.039089  loss: 0.002627  eta: 0h39m  tot: 0h10m20s  (21.5%)7.7%  lr: 0.039059  loss: 0.002645  eta: 0h38m  tot: 0h10m23s  (21.5%)7.7%  lr: 0.039049  loss: 0.002648  eta: 0h38m  tot: 0h10m23s  (21.5%)7.9%  lr: 0.039049  loss: 0.002654  eta: 0h38m  tot: 0h10m24s  (21.6%)8.0%  lr: 0.039049  loss: 0.002653  eta: 0h38m  tot: 0h10m24s  (21.6%)8.0%  lr: 0.039039  loss: 0.002648  eta: 0h39m  tot: 0h10m24s  (21.6%)8.3%  lr: 0.039009  loss: 0.002626  eta: 0h39m  tot: 0h10m26s  (21.7%)8.7%  lr: 0.038959  loss: 0.002636  eta: 0h38m  tot: 0h10m29s  (21.7%)8.8%  lr: 0.038949  loss: 0.002650  eta: 0h38m  tot: 0h10m29s  (21.8%)9.7%  lr: 0.038859  loss: 0.002610  eta: 0h38m  tot: 0h10m35s  (21.9%)9.8%  lr: 0.038829  loss: 0.002600  eta: 0h38m  tot: 0h10m35s  (22.0%)10.3%  lr: 0.038769  loss: 0.002583  eta: 0h38m  tot: 0h10m39s  (22.1%)10.4%  lr: 0.038759  loss: 0.002586  eta: 0h38m  tot: 0h10m39s  (22.1%)10.9%  lr: 0.038669  loss: 0.002560  eta: 0h38m  tot: 0h10m42s  (22.2%)11.0%  lr: 0.038649  loss: 0.002561  eta: 0h38m  tot: 0h10m42s  (22.2%)11.5%  lr: 0.038589  loss: 0.002600  eta: 0h38m  tot: 0h10m45s  (22.3%)11.6%  lr: 0.038579  loss: 0.002598  eta: 0h38m  tot: 0h10m46s  (22.3%)11.7%  lr: 0.038579  loss: 0.002600  eta: 0h38m  tot: 0h10m46s  (22.3%)11.8%  lr: 0.038579  loss: 0.002606  eta: 0h38m  tot: 0h10m47s  (22.4%)12.2%  lr: 0.038509  loss: 0.002610  eta: 0h38m  tot: 0h10m49s  (22.4%)12.3%  lr: 0.038509  loss: 0.002601  eta: 0h38m  tot: 0h10m50s  (22.5%)12.3%  lr: 0.038509  loss: 0.002599  eta: 0h38m  tot: 0h10m50s  (22.5%)12.5%  lr: 0.038479  loss: 0.002595  eta: 0h38m  tot: 0h10m51s  (22.5%)13.0%  lr: 0.038448  loss: 0.002587  eta: 0h38m  tot: 0h10m53s  (22.6%)13.6%  lr: 0.038428  loss: 0.002582  eta: 0h37m  tot: 0h10m57s  (22.7%)13.9%  lr: 0.038418  loss: 0.002576  eta: 0h37m  tot: 0h10m58s  (22.8%)14.0%  lr: 0.038398  loss: 0.002576  eta: 0h37m  tot: 0h10m59s  (22.8%)14.0%  lr: 0.038398  loss: 0.002582  eta: 0h37m  tot: 0h10m59s  (22.8%)14.1%  lr: 0.038398  loss: 0.002582  eta: 0h37m  tot: 0h10m59s  (22.8%)15.1%  lr: 0.038258  loss: 0.002603  eta: 0h38m  tot: 0h11m6s  (23.0%)15.2%  lr: 0.038238  loss: 0.002616  eta: 0h38m  tot: 0h11m8s  (23.0%)15.4%  lr: 0.038228  loss: 0.002610  eta: 0h38m  tot: 0h11m9s  (23.1%)15.5%  lr: 0.038218  loss: 0.002619  eta: 0h38m  tot: 0h11m10s  (23.1%)15.7%  lr: 0.038218  loss: 0.002615  eta: 0h38m  tot: 0h11m10s  (23.1%)15.8%  lr: 0.038218  loss: 0.002610  eta: 0h38m  tot: 0h11m11s  (23.2%)16.0%  lr: 0.038218  loss: 0.002613  eta: 0h38m  tot: 0h11m12s  (23.2%)16.2%  lr: 0.038208  loss: 0.002619  eta: 0h38m  tot: 0h11m14s  (23.2%)16.6%  lr: 0.038168  loss: 0.002606  eta: 0h38m  tot: 0h11m16s  (23.3%)16.6%  lr: 0.038168  loss: 0.002605  eta: 0h38m  tot: 0h11m16s  (23.3%)17.2%  lr: 0.038068  loss: 0.002604  eta: 0h38m  tot: 0h11m20s  (23.4%)17.3%  lr: 0.038058  loss: 0.002606  eta: 0h38m  tot: 0h11m21s  (23.5%)17.5%  lr: 0.038048  loss: 0.002602  eta: 0h38m  tot: 0h11m22s  (23.5%)17.6%  lr: 0.038038  loss: 0.002599  eta: 0h38m  tot: 0h11m22s  (23.5%)17.9%  lr: 0.038018  loss: 0.002597  eta: 0h38m  tot: 0h11m24s  (23.6%)18.1%  lr: 0.037998  loss: 0.002602  eta: 0h38m  tot: 0h11m26s  (23.6%)18.5%  lr: 0.037938  loss: 0.002611  eta: 0h38m  tot: 0h11m29s  (23.7%)18.6%  lr: 0.037938  loss: 0.002610  eta: 0h38m  tot: 0h11m29s  (23.7%)18.6%  lr: 0.037938  loss: 0.002609  eta: 0h38m  tot: 0h11m29s  (23.7%)18.8%  lr: 0.037918  loss: 0.002603  eta: 0h38m  tot: 0h11m30s  (23.8%)18.9%  lr: 0.037908  loss: 0.002603  eta: 0h38m  tot: 0h11m31s  (23.8%)19.1%  lr: 0.037898  loss: 0.002603  eta: 0h38m  tot: 0h11m32s  (23.8%)19.5%  lr: 0.037858  loss: 0.002611  eta: 0h38m  tot: 0h11m35s  (23.9%)19.7%  lr: 0.037818  loss: 0.002614  eta: 0h38m  tot: 0h11m36s  (23.9%)19.9%  lr: 0.037798  loss: 0.002615  eta: 0h38m  tot: 0h11m37s  (24.0%)20.0%  lr: 0.037788  loss: 0.002613  eta: 0h38m  tot: 0h11m38s  (24.0%)20.0%  lr: 0.037778  loss: 0.002616  eta: 0h38m  tot: 0h11m38s  (24.0%)20.5%  lr: 0.037728  loss: 0.002622  eta: 0h38m  tot: 0h11m41s  (24.1%)20.6%  lr: 0.037698  loss: 0.002621  eta: 0h38m  tot: 0h11m41s  (24.1%)20.9%  lr: 0.037668  loss: 0.002630  eta: 0h38m  tot: 0h11m44s  (24.2%)21.0%  lr: 0.037668  loss: 0.002627  eta: 0h38m  tot: 0h11m44s  (24.2%)21.1%  lr: 0.037628  loss: 0.002626  eta: 0h38m  tot: 0h11m45s  (24.2%)21.2%  lr: 0.037608  loss: 0.002627  eta: 0h38m  tot: 0h11m46s  (24.2%)21.3%  lr: 0.037578  loss: 0.002624  eta: 0h38m  tot: 0h11m46s  (24.3%)21.4%  lr: 0.037568  loss: 0.002628  eta: 0h38m  tot: 0h11m47s  (24.3%)22.0%  lr: 0.037518  loss: 0.002627  eta: 0h38m  tot: 0h11m51s  (24.4%)22.1%  lr: 0.037478  loss: 0.002625  eta: 0h38m  tot: 0h11m51s  (24.4%)22.2%  lr: 0.037478  loss: 0.002621  eta: 0h38m  tot: 0h11m52s  (24.4%)22.3%  lr: 0.037457  loss: 0.002620  eta: 0h38m  tot: 0h11m52s  (24.5%)23.0%  lr: 0.037417  loss: 0.002617  eta: 0h38m  tot: 0h11m57s  (24.6%)23.3%  lr: 0.037397  loss: 0.002615  eta: 0h38m  tot: 0h11m58s  (24.7%)23.5%  lr: 0.037387  loss: 0.002610  eta: 0h38m  tot: 0h12m0s  (24.7%)23.9%  lr: 0.037347  loss: 0.002619  eta: 0h38m  tot: 0h12m2s  (24.8%)24.5%  lr: 0.037267  loss: 0.002620  eta: 0h38m  tot: 0h12m6s  (24.9%)24.5%  lr: 0.037267  loss: 0.002620  eta: 0h38m  tot: 0h12m6s  (24.9%)24.6%  lr: 0.037247  loss: 0.002622  eta: 0h38m  tot: 0h12m7s  (24.9%)25.0%  lr: 0.037227  loss: 0.002626  eta: 0h38m  tot: 0h12m9s  (25.0%)25.2%  lr: 0.037197  loss: 0.002631  eta: 0h38m  tot: 0h12m11s  (25.0%)25.3%  lr: 0.037187  loss: 0.002633  eta: 0h38m  tot: 0h12m11s  (25.1%)26.1%  lr: 0.037147  loss: 0.002638  eta: 0h37m  tot: 0h12m16s  (25.2%)27.2%  lr: 0.037047  loss: 0.002645  eta: 0h37m  tot: 0h12m21s  (25.4%)27.3%  lr: 0.037047  loss: 0.002647  eta: 0h37m  tot: 0h12m22s  (25.5%)27.8%  lr: 0.037017  loss: 0.002650  eta: 0h37m  tot: 0h12m24s  (25.6%)28.2%  lr: 0.036957  loss: 0.002652  eta: 0h37m  tot: 0h12m27s  (25.6%)28.3%  lr: 0.036947  loss: 0.002652  eta: 0h37m  tot: 0h12m27s  (25.7%)28.4%  lr: 0.036947  loss: 0.002651  eta: 0h37m  tot: 0h12m27s  (25.7%)28.7%  lr: 0.036887  loss: 0.002653  eta: 0h37m  tot: 0h12m29s  (25.7%)28.7%  lr: 0.036887  loss: 0.002654  eta: 0h37m  tot: 0h12m29s  (25.7%)29.2%  lr: 0.036867  loss: 0.002653  eta: 0h37m  tot: 0h12m32s  (25.8%)29.2%  lr: 0.036867  loss: 0.002654  eta: 0h37m  tot: 0h12m32s  (25.8%)29.3%  lr: 0.036867  loss: 0.002654  eta: 0h37m  tot: 0h12m32s  (25.9%)29.4%  lr: 0.036857  loss: 0.002649  eta: 0h36m  tot: 0h12m33s  (25.9%)Epoch: 59.0%  lr: 0.033684  loss: 0.002699  eta: 0h33m  tot: 0h15m29s  (31.8%)30.3%  lr: 0.036747  loss: 0.002651  eta: 0h36m  tot: 0h12m38s  (26.1%)30.6%  lr: 0.036717  loss: 0.002650  eta: 0h36m  tot: 0h12m40s  (26.1%)30.6%  lr: 0.036707  loss: 0.002649  eta: 0h36m  tot: 0h12m40s  (26.1%)30.7%  lr: 0.036687  loss: 0.002649  eta: 0h36m  tot: 0h12m41s  (26.1%)30.8%  lr: 0.036677  loss: 0.002651  eta: 0h36m  tot: 0h12m41s  (26.2%)30.9%  lr: 0.036677  loss: 0.002653  eta: 0h36m  tot: 0h12m42s  (26.2%)45s  (26.3%)32.3%  lr: 0.036507  loss: 0.002666  eta: 0h36m  tot: 0h12m50s  (26.5%)32.4%  lr: 0.036497  loss: 0.002672  eta: 0h36m  tot: 0h12m51s  (26.5%)32.7%  lr: 0.036487  loss: 0.002674  eta: 0h36m  tot: 0h12m53s  (26.5%)32.9%  lr: 0.036477  loss: 0.002674  eta: 0h36m  tot: 0h12m54s  (26.6%)32.9%  lr: 0.036467  loss: 0.002677  eta: 0h36m  tot: 0h12m54s  (26.6%)%  lr: 0.036416  loss: 0.002670  eta: 0h36m  tot: 0h12m59s  (26.7%)33.8%  lr: 0.036406  loss: 0.002671  eta: 0h36m  tot: 0h12m59s  (26.8%)33.9%  lr: 0.036396  loss: 0.002671  eta: 0h36m  tot: 0h13m0s  (26.8%)34.0%  lr: 0.036396  loss: 0.002671  eta: 0h36m  tot: 0h13m0s  (26.8%)34.0%  lr: 0.036396  loss: 0.002670  eta: 0h36m  tot: 0h13m1s  (26.8%)34.2%  lr: 0.036356  loss: 0.002677  eta: 0h36m  tot: 0h13m2s  (26.8%)34.4%  lr: 0.036336  loss: 0.002681  eta: 0h36m  tot: 0h13m3s  (26.9%)34.7%  lr: 0.036296  loss: 0.002679  eta: 0h36m  tot: 0h13m4s  (26.9%)35.2%  lr: 0.036236  loss: 0.002679  eta: 0h36m  tot: 0h13m8s  (27.0%)35.3%  lr: 0.036236  loss: 0.002675  eta: 0h36m  tot: 0h13m9s  (27.1%)35.4%  lr: 0.036236  loss: 0.002675  eta: 0h36m  tot: 0h13m9s  (27.1%)35.9%  lr: 0.036196  loss: 0.002678  eta: 0h36m  tot: 0h13m12s  (27.2%)36.1%  lr: 0.036176  loss: 0.002676  eta: 0h36m  tot: 0h13m13s  (27.2%)36.7%  lr: 0.036106  loss: 0.002665  eta: 0h36m  tot: 0h13m17s  (27.3%)36.9%  lr: 0.036066  loss: 0.002664  eta: 0h36m  tot: 0h13m18s  (27.4%)37.2%  lr: 0.036036  loss: 0.002664  eta: 0h36m  tot: 0h13m20s  (27.4%)37.3%  lr: 0.036006  loss: 0.002665  eta: 0h36m  tot: 0h13m20s  (27.5%)38.2%  lr: 0.035956  loss: 0.002673  eta: 0h36m  tot: 0h13m26s  (27.6%)38.8%  lr: 0.035876  loss: 0.002666  eta: 0h36m  tot: 0h13m29s  (27.8%)39.0%  lr: 0.035856  loss: 0.002669  eta: 0h36m  tot: 0h13m30s  (27.8%)39.4%  lr: 0.035846  loss: 0.002671  eta: 0h35m  tot: 0h13m32s  (27.9%)39.6%  lr: 0.035846  loss: 0.002673  eta: 0h35m  tot: 0h13m33s  (27.9%)40.1%  lr: 0.035796  loss: 0.002667  eta: 0h35m  tot: 0h13m36s  (28.0%)40.2%  lr: 0.035796  loss: 0.002666  eta: 0h35m  tot: 0h13m37s  (28.0%)40.7%  lr: 0.035726  loss: 0.002665  eta: 0h35m  tot: 0h13m40s  (28.1%)41.0%  lr: 0.035696  loss: 0.002665  eta: 0h35m  tot: 0h13m41s  (28.2%)13m42s  (28.2%)41.5%  lr: 0.035656  loss: 0.002671  eta: 0h35m  tot: 0h13m45s  (28.3%)41.6%  lr: 0.035656  loss: 0.002671  eta: 0h35m  tot: 0h13m45s  (28.3%)42.0%  lr: 0.035646  loss: 0.002673  eta: 0h35m  tot: 0h13m48s  (28.4%)42.1%  lr: 0.035636  loss: 0.002675  eta: 0h35m  tot: 0h13m48s  (28.4%)42.4%  lr: 0.035596  loss: 0.002675  eta: 0h35m  tot: 0h13m50s  (28.5%)42.4%  lr: 0.035586  loss: 0.002675  eta: 0h35m  tot: 0h13m50s  (28.5%)42.6%  lr: 0.035576  loss: 0.002677  eta: 0h35m  tot: 0h13m52s  (28.5%)42.7%  lr: 0.035556  loss: 0.002676  eta: 0h35m  tot: 0h13m52s  (28.5%)42.8%  lr: 0.035546  loss: 0.002676  eta: 0h35m  tot: 0h13m52s  (28.6%)43.2%  lr: 0.035486  loss: 0.002676  eta: 0h35m  tot: 0h13m55s  (28.6%)43.4%  lr: 0.035466  loss: 0.002674  eta: 0h35m  tot: 0h13m56s  (28.7%)43.5%  lr: 0.035446  loss: 0.002671  eta: 0h35m  tot: 0h13m57s  (28.7%)43.7%  lr: 0.035425  loss: 0.002668  eta: 0h35m  tot: 0h13m58s  (28.7%)43.9%  lr: 0.035425  loss: 0.002670  eta: 0h35m  tot: 0h13m59s  (28.8%)44.1%  lr: 0.035395  loss: 0.002671  eta: 0h35m  tot: 0h14m0s  (28.8%)44.3%  lr: 0.035355  loss: 0.002673  eta: 0h35m  tot: 0h14m2s  (28.9%)%  lr: 0.035285  loss: 0.002676  eta: 0h35m  tot: 0h14m5s  (29.0%)45.2%  lr: 0.035245  loss: 0.002675  eta: 0h35m  tot: 0h14m7s  (29.0%)45.5%  lr: 0.035185  loss: 0.002679  eta: 0h35m  tot: 0h14m9s  (29.1%)45.6%  lr: 0.035155  loss: 0.002678  eta: 0h35m  tot: 0h14m9s  (29.1%)45.7%  lr: 0.035155  loss: 0.002678  eta: 0h35m  tot: 0h14m10s  (29.1%)45.8%  lr: 0.035155  loss: 0.002680  eta: 0h35m  tot: 0h14m10s  (29.2%)45.9%  lr: 0.035145  loss: 0.002679  eta: 0h35m  tot: 0h14m11s  (29.2%)46.1%  lr: 0.035125  loss: 0.002680  eta: 0h35m  tot: 0h14m12s  (29.2%)46.4%  lr: 0.035105  loss: 0.002680  eta: 0h35m  tot: 0h14m14s  (29.3%)46.5%  lr: 0.035085  loss: 0.002682  eta: 0h35m  tot: 0h14m15s  (29.3%)46.8%  lr: 0.035035  loss: 0.002681  eta: 0h35m  tot: 0h14m16s  (29.4%)46.9%  lr: 0.035015  loss: 0.002682  eta: 0h35m  tot: 0h14m17s  (29.4%)46.9%  lr: 0.035005  loss: 0.002680  eta: 0h35m  tot: 0h14m17s  (29.4%)47.0%  lr: 0.034985  loss: 0.002681  eta: 0h35m  tot: 0h14m18s  (29.4%)47.2%  lr: 0.034975  loss: 0.002680  eta: 0h35m  tot: 0h14m19s  (29.4%)47.3%  lr: 0.034975  loss: 0.002681  eta: 0h35m  tot: 0h14m19s  (29.5%)47.6%  lr: 0.034945  loss: 0.002683  eta: 0h35m  tot: 0h14m21s  (29.5%)48.0%  lr: 0.034865  loss: 0.002682  eta: 0h35m  tot: 0h14m24s  (29.6%)48.1%  lr: 0.034865  loss: 0.002682  eta: 0h35m  tot: 0h14m24s  (29.6%)48.3%  lr: 0.034855  loss: 0.002679  eta: 0h35m  tot: 0h14m25s  (29.7%)48.5%  lr: 0.034835  loss: 0.002685  eta: 0h34m  tot: 0h14m26s  (29.7%)48.6%  lr: 0.034835  loss: 0.002688  eta: 0h34m  tot: 0h14m27s  (29.7%)48.9%  lr: 0.034785  loss: 0.002691  eta: 0h34m  tot: 0h14m29s  (29.8%)49.2%  lr: 0.034785  loss: 0.002691  eta: 0h34m  tot: 0h14m31s  (29.8%)49.7%  lr: 0.034705  loss: 0.002690  eta: 0h34m  tot: 0h14m34s  (29.9%)49.8%  lr: 0.034695  loss: 0.002691  eta: 0h34m  tot: 0h14m34s  (30.0%)50.5%  lr: 0.034635  loss: 0.002690  eta: 0h34m  tot: 0h14m38s  (30.1%)50.5%  lr: 0.034625  loss: 0.002692  eta: 0h34m  tot: 0h14m39s  (30.1%)51.0%  lr: 0.034575  loss: 0.002691  eta: 0h34m  tot: 0h14m41s  (30.2%)51.6%  lr: 0.034505  loss: 0.002692  eta: 0h34m  tot: 0h14m45s  (30.3%)51.6%  lr: 0.034505  loss: 0.002691  eta: 0h34m  tot: 0h14m45s  (30.3%)52.2%  lr: 0.034475  loss: 0.002687  eta: 0h34m  tot: 0h14m48s  (30.4%)52.2%  lr: 0.034475  loss: 0.002687  eta: 0h34m  tot: 0h14m49s  (30.4%)52.3%  lr: 0.034455  loss: 0.002686  eta: 0h34m  tot: 0h14m49s  (30.5%)52.4%  lr: 0.034445  loss: 0.002691  eta: 0h34m  tot: 0h14m50s  (30.5%)52.5%  lr: 0.034425  loss: 0.002692  eta: 0h34m  tot: 0h14m51s  (30.5%)52.9%  lr: 0.034404  loss: 0.002690  eta: 0h34m  tot: 0h14m52s  (30.6%)53.2%  lr: 0.034344  loss: 0.002693  eta: 0h34m  tot: 0h14m54s  (30.6%)53.4%  lr: 0.034334  loss: 0.002691  eta: 0h34m  tot: 0h14m55s  (30.7%)53.4%  lr: 0.034304  loss: 0.002689  eta: 0h34m  tot: 0h14m56s  (30.7%)53.6%  lr: 0.034294  loss: 0.002692  eta: 0h34m  tot: 0h14m57s  (30.7%)53.7%  lr: 0.034294  loss: 0.002691  eta: 0h34m  tot: 0h14m57s  (30.7%)53.8%  lr: 0.034294  loss: 0.002690  eta: 0h34m  tot: 0h14m58s  (30.8%)54.7%  lr: 0.034204  loss: 0.002693  eta: 0h34m  tot: 0h15m3s  (30.9%)55.2%  lr: 0.034134  loss: 0.002692  eta: 0h34m  tot: 0h15m6s  (31.0%)55.6%  lr: 0.034064  loss: 0.002694  eta: 0h34m  tot: 0h15m8s  (31.1%)55.7%  lr: 0.034064  loss: 0.002694  eta: 0h34m  tot: 0h15m9s  (31.1%)55.8%  lr: 0.034054  loss: 0.002695  eta: 0h34m  tot: 0h15m9s  (31.2%)55.8%  lr: 0.034044  loss: 0.002695  eta: 0h34m  tot: 0h15m10s  (31.2%)56.0%  lr: 0.034034  loss: 0.002692  eta: 0h34m  tot: 0h15m11s  (31.2%)56.6%  lr: 0.033974  loss: 0.002690  eta: 0h34m  tot: 0h15m14s  (31.3%)56.7%  lr: 0.033954  loss: 0.002689  eta: 0h34m  tot: 0h15m15s  (31.3%)56.7%  lr: 0.033934  loss: 0.002690  eta: 0h34m  tot: 0h15m15s  (31.3%)56.9%  lr: 0.033914  loss: 0.002692  eta: 0h34m  tot: 0h15m16s  (31.4%)57.0%  lr: 0.033914  loss: 0.002690  eta: 0h34m  tot: 0h15m17s  (31.4%)57.2%  lr: 0.033894  loss: 0.002691  eta: 0h34m  tot: 0h15m18s  (31.4%)57.9%  lr: 0.033824  loss: 0.002693  eta: 0h34m  tot: 0h15m22s  (31.6%)58.1%  lr: 0.033794  loss: 0.002694  eta: 0h34m  tot: 0h15m24s  (31.6%)58.4%  lr: 0.033774  loss: 0.002695  eta: 0h34m  tot: 0h15m26s  (31.7%)58.6%  lr: 0.033724  loss: 0.002698  eta: 0h33m  tot: 0h15m27s  (31.7%)59.0%  lr: 0.033694  loss: 0.002699  eta: 0h33m  tot: 0h15m29s  (31.8%)59.1%  lr: 0.033684  loss: 0.002698  eta: 0h33m  tot: 0h15m30s  (31.8%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 87.7%  lr: 0.031101  loss: 0.002696  eta: 0h31m  tot: 0h18m22s  (37.5%)59.5%  lr: 0.033634  loss: 0.002702  eta: 0h33m  tot: 0h15m32s  (31.9%)59.7%  lr: 0.033634  loss: 0.002702  eta: 0h33m  tot: 0h15m33s  (31.9%)59.8%  lr: 0.033614  loss: 0.002703  eta: 0h33m  tot: 0h15m34s  (32.0%)60.0%  lr: 0.033604  loss: 0.002703  eta: 0h33m  tot: 0h15m36s  (32.0%)60.3%  lr: 0.033604  loss: 0.002702  eta: 0h33m  tot: 0h15m37s  (32.1%)60.3%  lr: 0.033584  loss: 0.002702  eta: 0h33m  tot: 0h15m37s  (32.1%)61.0%  lr: 0.033544  loss: 0.002703  eta: 0h33m  tot: 0h15m41s  (32.2%)61.8%  lr: 0.033434  loss: 0.002696  eta: 0h33m  tot: 0h15m46s  (32.4%)61.9%  lr: 0.033434  loss: 0.002699  eta: 0h33m  tot: 0h15m47s  (32.4%)62.0%  lr: 0.033434  loss: 0.002700  eta: 0h33m  tot: 0h15m47s  (32.4%)62.1%  lr: 0.033424  loss: 0.002701  eta: 0h33m  tot: 0h15m48s  (32.4%)62.4%  lr: 0.033424  loss: 0.002701  eta: 0h33m  tot: 0h15m50s  (32.5%)62.4%  lr: 0.033424  loss: 0.002702  eta: 0h33m  tot: 0h15m50s  (32.5%)62.6%  lr: 0.033393  loss: 0.002703  eta: 0h33m  tot: 0h15m51s  (32.5%)62.9%  lr: 0.033383  loss: 0.002702  eta: 0h33m  tot: 0h15m53s  (32.6%)63.0%  lr: 0.033373  loss: 0.002701  eta: 0h33m  tot: 0h15m53s  (32.6%)63.6%  lr: 0.033273  loss: 0.002698  eta: 0h33m  tot: 0h15m57s  (32.7%)63.9%  lr: 0.033183  loss: 0.002697  eta: 0h33m  tot: 0h15m59s  (32.8%)64.2%  lr: 0.033183  loss: 0.002699  eta: 0h33m  tot: 0h16m0s  (32.8%)64.2%  lr: 0.033183  loss: 0.002699  eta: 0h33m  tot: 0h16m1s  (32.8%)64.5%  lr: 0.033163  loss: 0.002697  eta: 0h33m  tot: 0h16m2s  (32.9%)64.5%  lr: 0.033153  loss: 0.002696  eta: 0h33m  tot: 0h16m2s  (32.9%)64.7%  lr: 0.033143  loss: 0.002696  eta: 0h33m  tot: 0h16m3s  (32.9%)65.7%  lr: 0.033033  loss: 0.002698  eta: 0h33m  tot: 0h16m10s  (33.1%)66.1%  lr: 0.033003  loss: 0.002698  eta: 0h33m  tot: 0h16m12s  (33.2%)66.3%  lr: 0.033003  loss: 0.002697  eta: 0h33m  tot: 0h16m13s  (33.3%)66.6%  lr: 0.032953  loss: 0.002695  eta: 0h33m  tot: 0h16m15s  (33.3%)66.8%  lr: 0.032903  loss: 0.002695  eta: 0h33m  tot: 0h16m16s  (33.4%)67.0%  lr: 0.032863  loss: 0.002695  eta: 0h33m  tot: 0h16m17s  (33.4%)67.4%  lr: 0.032853  loss: 0.002697  eta: 0h33m  tot: 0h16m20s  (33.5%)67.6%  lr: 0.032833  loss: 0.002697  eta: 0h33m  tot: 0h16m21s  (33.5%)67.7%  lr: 0.032833  loss: 0.002697  eta: 0h33m  tot: 0h16m22s  (33.5%)68.1%  lr: 0.032803  loss: 0.002696  eta: 0h33m  tot: 0h16m24s  (33.6%)68.4%  lr: 0.032803  loss: 0.002696  eta: 0h33m  tot: 0h16m26s  (33.7%)68.4%  lr: 0.032803  loss: 0.002696  eta: 0h33m  tot: 0h16m26s  (33.7%)68.4%  lr: 0.032803  loss: 0.002696  eta: 0h33m  tot: 0h16m27s  (33.7%)68.7%  lr: 0.032763  loss: 0.002695  eta: 0h33m  tot: 0h16m28s  (33.7%)68.7%  lr: 0.032763  loss: 0.002696  eta: 0h33m  tot: 0h16m28s  (33.7%)69.0%  lr: 0.032763  loss: 0.002695  eta: 0h33m  tot: 0h16m30s  (33.8%)69.2%  lr: 0.032723  loss: 0.002693  eta: 0h33m  tot: 0h16m31s  (33.8%)69.3%  lr: 0.032723  loss: 0.002695  eta: 0h32m  tot: 0h16m32s  (33.9%)69.6%  lr: 0.032703  loss: 0.002694  eta: 0h32m  tot: 0h16m33s  (33.9%)69.9%  lr: 0.032663  loss: 0.002696  eta: 0h32m  tot: 0h16m35s  (34.0%)69.9%  lr: 0.032663  loss: 0.002695  eta: 0h32m  tot: 0h16m36s  (34.0%)70.4%  lr: 0.032613  loss: 0.002699  eta: 0h32m  tot: 0h16m38s  (34.1%)70.7%  lr: 0.032543  loss: 0.002697  eta: 0h32m  tot: 0h16m40s  (34.1%)71.3%  lr: 0.032503  loss: 0.002699  eta: 0h32m  tot: 0h16m44s  (34.3%)71.3%  lr: 0.032493  loss: 0.002699  eta: 0h32m  tot: 0h16m44s  (34.3%)71.7%  lr: 0.032483  loss: 0.002699  eta: 0h32m  tot: 0h16m46s  (34.3%)71.9%  lr: 0.032483  loss: 0.002699  eta: 0h32m  tot: 0h16m47s  (34.4%)72.1%  lr: 0.032473  loss: 0.002700  eta: 0h32m  tot: 0h16m49s  (34.4%)72.3%  lr: 0.032463  loss: 0.002701  eta: 0h32m  tot: 0h16m50s  (34.5%)72.4%  lr: 0.032443  loss: 0.002701  eta: 0h32m  tot: 0h16m51s  (34.5%)72.5%  lr: 0.032443  loss: 0.002701  eta: 0h32m  tot: 0h16m51s  (34.5%)72.6%  lr: 0.032433  loss: 0.002700  eta: 0h32m  tot: 0h16m52s  (34.5%)72.7%  lr: 0.032423  loss: 0.002700  eta: 0h32m  tot: 0h16m52s  (34.5%)73.1%  lr: 0.032403  loss: 0.002700  eta: 0h32m  tot: 0h16m55s  (34.6%)73.5%  lr: 0.032342  loss: 0.002699  eta: 0h32m  tot: 0h16m57s  (34.7%)73.6%  lr: 0.032332  loss: 0.002697  eta: 0h32m  tot: 0h16m58s  (34.7%)73.9%  lr: 0.032312  loss: 0.002695  eta: 0h32m  tot: 0h17m0s  (34.8%)74.3%  lr: 0.032282  loss: 0.002695  eta: 0h32m  tot: 0h17m2s  (34.9%)74.6%  lr: 0.032242  loss: 0.002695  eta: 0h32m  tot: 0h17m4s  (34.9%)75.0%  lr: 0.032212  loss: 0.002694  eta: 0h32m  tot: 0h17m6s  (35.0%)75.1%  lr: 0.032192  loss: 0.002695  eta: 0h32m  tot: 0h17m7s  (35.0%)75.4%  lr: 0.032162  loss: 0.002696  eta: 0h32m  tot: 0h17m9s  (35.1%)76.5%  lr: 0.032112  loss: 0.002693  eta: 0h32m  tot: 0h17m15s  (35.3%)76.7%  lr: 0.032082  loss: 0.002692  eta: 0h32m  tot: 0h17m17s  (35.3%)76.8%  lr: 0.032072  loss: 0.002692  eta: 0h32m  tot: 0h17m17s  (35.4%)76.9%  lr: 0.032042  loss: 0.002692  eta: 0h32m  tot: 0h17m18s  (35.4%)77.3%  lr: 0.032022  loss: 0.002691  eta: 0h32m  tot: 0h17m20s  (35.5%)77.9%  lr: 0.031982  loss: 0.002693  eta: 0h32m  tot: 0h17m24s  (35.6%)78.5%  lr: 0.031932  loss: 0.002696  eta: 0h32m  tot: 0h17m27s  (35.7%)78.6%  lr: 0.031932  loss: 0.002695  eta: 0h32m  tot: 0h17m28s  (35.7%)79.2%  lr: 0.031842  loss: 0.002693  eta: 0h32m  tot: 0h17m31s  (35.8%)79.2%  lr: 0.031842  loss: 0.002693  eta: 0h32m  tot: 0h17m31s  (35.8%)79.4%  lr: 0.031832  loss: 0.002694  eta: 0h32m  tot: 0h17m33s  (35.9%)79.7%  lr: 0.031822  loss: 0.002695  eta: 0h31m  tot: 0h17m34s  (35.9%)80.1%  lr: 0.031792  loss: 0.002695  eta: 0h31m  tot: 0h17m36s  (36.0%)80.2%  lr: 0.031792  loss: 0.002694  eta: 0h31m  tot: 0h17m37s  (36.0%)80.6%  lr: 0.031772  loss: 0.002692  eta: 0h31m  tot: 0h17m39s  (36.1%)81.1%  lr: 0.031742  loss: 0.002687  eta: 0h31m  tot: 0h17m42s  (36.2%)81.1%  lr: 0.031742  loss: 0.002687  eta: 0h31m  tot: 0h17m43s  (36.2%)81.3%  lr: 0.031722  loss: 0.002686  eta: 0h31m  tot: 0h17m43s  (36.3%)81.3%  lr: 0.031712  loss: 0.002687  eta: 0h31m  tot: 0h17m43s  (36.3%)81.4%  lr: 0.031712  loss: 0.002687  eta: 0h31m  tot: 0h17m44s  (36.3%)81.7%  lr: 0.031712  loss: 0.002687  eta: 0h31m  tot: 0h17m45s  (36.3%)81.7%  lr: 0.031702  loss: 0.002687  eta: 0h31m  tot: 0h17m46s  (36.3%)81.8%  lr: 0.031692  loss: 0.002688  eta: 0h31m  tot: 0h17m47s  (36.4%)82.4%  lr: 0.031652  loss: 0.002691  eta: 0h31m  tot: 0h17m50s  (36.5%)82.5%  lr: 0.031632  loss: 0.002691  eta: 0h31m  tot: 0h17m50s  (36.5%)82.5%  lr: 0.031612  loss: 0.002691  eta: 0h31m  tot: 0h17m51s  (36.5%)82.7%  lr: 0.031592  loss: 0.002690  eta: 0h31m  tot: 0h17m52s  (36.5%)82.9%  lr: 0.031552  loss: 0.002691  eta: 0h31m  tot: 0h17m53s  (36.6%)83.5%  lr: 0.031512  loss: 0.002690  eta: 0h31m  tot: 0h17m57s  (36.7%)83.7%  lr: 0.031472  loss: 0.002691  eta: 0h31m  tot: 0h17m58s  (36.7%)83.9%  lr: 0.031452  loss: 0.002691  eta: 0h31m  tot: 0h17m59s  (36.8%)84.1%  lr: 0.031442  loss: 0.002691  eta: 0h31m  tot: 0h18m0s  (36.8%)84.4%  lr: 0.031412  loss: 0.002691  eta: 0h31m  tot: 0h18m2s  (36.9%)84.4%  lr: 0.031412  loss: 0.002691  eta: 0h31m  tot: 0h18m2s  (36.9%)84.6%  lr: 0.031412  loss: 0.002691  eta: 0h31m  tot: 0h18m3s  (36.9%)85.1%  lr: 0.031351  loss: 0.002687  eta: 0h31m  tot: 0h18m6s  (37.0%)85.6%  lr: 0.031311  loss: 0.002691  eta: 0h31m  tot: 0h18m9s  (37.1%)85.6%  lr: 0.031311  loss: 0.002692  eta: 0h31m  tot: 0h18m9s  (37.1%)85.7%  lr: 0.031301  loss: 0.002692  eta: 0h31m  tot: 0h18m10s  (37.1%)85.7%  lr: 0.031301  loss: 0.002692  eta: 0h31m  tot: 0h18m10s  (37.1%)86.0%  lr: 0.031271  loss: 0.002689  eta: 0h31m  tot: 0h18m12s  (37.2%)86.1%  lr: 0.031251  loss: 0.002690  eta: 0h31m  tot: 0h18m12s  (37.2%)86.5%  lr: 0.031251  loss: 0.002689  eta: 0h31m  tot: 0h18m14s  (37.3%)86.6%  lr: 0.031241  loss: 0.002691  eta: 0h31m  tot: 0h18m15s  (37.3%)86.7%  lr: 0.031231  loss: 0.002691  eta: 0h31m  tot: 0h18m16s  (37.3%)87.0%  lr: 0.031231  loss: 0.002693  eta: 0h31m  tot: 0h18m17s  (37.4%)87.1%  lr: 0.031201  loss: 0.002694  eta: 0h31m  tot: 0h18m18s  (37.4%)87.5%  lr: 0.031151  loss: 0.002694  eta: 0h31m  tot: 0h18m21s  (37.5%)87.7%  lr: 0.031101  loss: 0.002696  eta: 0h31m  tot: 0h18m22s  (37.5%)87.7%  lr: 0.031101  loss: 0.002696  eta: 0h31m  tot: 0h18m22s  (37.5%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100.0%  lr: 0.030000  loss: 0.002690  eta: 0h29m  tot: 0h19m27s  (40.0%)7.8%  lr: 0.031101  loss: 0.002696  eta: 0h31m  tot: 0h18m23s  (37.6%)87.9%  lr: 0.031101  loss: 0.002696  eta: 0h31m  tot: 0h18m23s  (37.6%)88.4%  lr: 0.031091  loss: 0.002697  eta: 0h31m  tot: 0h18m26s  (37.7%)89.4%  lr: 0.030981  loss: 0.002698  eta: 0h31m  tot: 0h18m32s  (37.9%)89.7%  lr: 0.030951  loss: 0.002698  eta: 0h30m  tot: 0h18m34s  (37.9%)89.8%  lr: 0.030951  loss: 0.002698  eta: 0h30m  tot: 0h18m34s  (38.0%)90.0%  lr: 0.030941  loss: 0.002699  eta: 0h30m  tot: 0h18m36s  (38.0%)90.1%  lr: 0.030941  loss: 0.002699  eta: 0h30m  tot: 0h18m37s  (38.0%)90.8%  lr: 0.030871  loss: 0.002700  eta: 0h30m  tot: 0h18m41s  (38.2%)91.0%  lr: 0.030851  loss: 0.002700  eta: 0h30m  tot: 0h18m42s  (38.2%)91.1%  lr: 0.030851  loss: 0.002700  eta: 0h30m  tot: 0h18m42s  (38.2%)91.1%  lr: 0.030831  loss: 0.002700  eta: 0h30m  tot: 0h18m43s  (38.2%)91.3%  lr: 0.030801  loss: 0.002699  eta: 0h30m  tot: 0h18m44s  (38.3%)91.5%  lr: 0.030801  loss: 0.002699  eta: 0h30m  tot: 0h18m45s  (38.3%)92.5%  lr: 0.030681  loss: 0.002698  eta: 0h30m  tot: 0h18m51s  (38.5%)92.7%  lr: 0.030661  loss: 0.002697  eta: 0h30m  tot: 0h18m52s  (38.5%)92.7%  lr: 0.030661  loss: 0.002697  eta: 0h30m  tot: 0h18m52s  (38.5%)93.4%  lr: 0.030581  loss: 0.002696  eta: 0h30m  tot: 0h18m56s  (38.7%)93.7%  lr: 0.030551  loss: 0.002695  eta: 0h30m  tot: 0h18m58s  (38.7%)93.8%  lr: 0.030531  loss: 0.002694  eta: 0h30m  tot: 0h18m59s  (38.8%)94.2%  lr: 0.030471  loss: 0.002696  eta: 0h30m  tot: 0h19m1s  (38.8%)94.7%  lr: 0.030401  loss: 0.002695  eta: 0h30m  tot: 0h19m4s  (38.9%)95.3%  lr: 0.030300  loss: 0.002695  eta: 0h30m  tot: 0h19m8s  (39.1%)95.4%  lr: 0.030300  loss: 0.002695  eta: 0h30m  tot: 0h19m8s  (39.1%)95.4%  lr: 0.030290  loss: 0.002695  eta: 0h30m  tot: 0h19m8s  (39.1%)96.1%  lr: 0.030230  loss: 0.002695  eta: 0h30m  tot: 0h19m13s  (39.2%)96.3%  lr: 0.030200  loss: 0.002695  eta: 0h30m  tot: 0h19m14s  (39.3%)96.4%  lr: 0.030190  loss: 0.002694  eta: 0h30m  tot: 0h19m14s  (39.3%)96.7%  lr: 0.030150  loss: 0.002694  eta: 0h30m  tot: 0h19m16s  (39.3%)96.7%  lr: 0.030130  loss: 0.002694  eta: 0h30m  tot: 0h19m16s  (39.3%)97.0%  lr: 0.030130  loss: 0.002694  eta: 0h30m  tot: 0h19m17s  (39.4%)\n",
      " ---+++                Epoch    1 Train error : 0.00266981 +++--- ���\n",
      "Training epoch 2: 0.03 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 27.8%  lr: 0.027257  loss: 0.001845  eta: 0h24m  tot: 0h21m58s  (45.6%).1%  lr: 0.029980  loss: 0.001651  eta: 0h27m  tot: 0h19m27s  (40.0%)0.2%  lr: 0.029980  loss: 0.002560  eta: 0h29m  tot: 0h19m28s  (40.0%)0.5%  lr: 0.029950  loss: 0.001812  eta: 0h28m  tot: 0h19m29s  (40.1%)0.7%  lr: 0.029930  loss: 0.001863  eta: 0h27m  tot: 0h19m31s  (40.1%)0.8%  lr: 0.029930  loss: 0.001847  eta: 0h27m  tot: 0h19m31s  (40.2%)0.8%  lr: 0.029930  loss: 0.001827  eta: 0h27m  tot: 0h19m31s  (40.2%)0.9%  lr: 0.029920  loss: 0.001820  eta: 0h27m  tot: 0h19m31s  (40.2%)0.9%  lr: 0.029920  loss: 0.001782  eta: 0h27m  tot: 0h19m32s  (40.2%)0.9%  lr: 0.029920  loss: 0.001800  eta: 0h27m  tot: 0h19m32s  (40.2%)1.1%  lr: 0.029900  loss: 0.001825  eta: 0h28m  tot: 0h19m33s  (40.2%)1.3%  lr: 0.029900  loss: 0.001696  eta: 0h28m  tot: 0h19m34s  (40.3%)1.4%  lr: 0.029880  loss: 0.001781  eta: 0h28m  tot: 0h19m35s  (40.3%)2.5%  lr: 0.029740  loss: 0.001894  eta: 0h28m  tot: 0h19m41s  (40.5%)2.7%  lr: 0.029740  loss: 0.001854  eta: 0h28m  tot: 0h19m42s  (40.5%)3.1%  lr: 0.029710  loss: 0.001872  eta: 0h28m  tot: 0h19m44s  (40.6%)%  lr: 0.029700  loss: 0.001847  eta: 0h28m  tot: 0h19m45s  (40.6%)3.3%  lr: 0.029690  loss: 0.001850  eta: 0h28m  tot: 0h19m45s  (40.7%)3.3%  lr: 0.029690  loss: 0.001859  eta: 0h28m  tot: 0h19m46s  (40.7%)3.4%  lr: 0.029690  loss: 0.001864  eta: 0h28m  tot: 0h19m46s  (40.7%)3.5%  lr: 0.029680  loss: 0.001851  eta: 0h28m  tot: 0h19m46s  (40.7%)4.4%  lr: 0.029530  loss: 0.001832  eta: 0h28m  tot: 0h19m52s  (40.9%)4.7%  lr: 0.029520  loss: 0.001870  eta: 0h28m  tot: 0h19m53s  (40.9%)4.7%  lr: 0.029510  loss: 0.001872  eta: 0h28m  tot: 0h19m54s  (40.9%)4.8%  lr: 0.029510  loss: 0.001859  eta: 0h28m  tot: 0h19m54s  (41.0%)5.1%  lr: 0.029469  loss: 0.001834  eta: 0h28m  tot: 0h19m56s  (41.0%)  loss: 0.001816  eta: 0h28m  tot: 0h19m57s  (41.1%)5.3%  lr: 0.029469  loss: 0.001828  eta: 0h28m  tot: 0h19m57s  (41.1%)5.3%  lr: 0.029469  loss: 0.001825  eta: 0h28m  tot: 0h19m57s  (41.1%)5.6%  lr: 0.029439  loss: 0.001816  eta: 0h28m  tot: 0h19m59s  (41.1%)5.7%  lr: 0.029409  loss: 0.001823  eta: 0h28m  tot: 0h19m59s  (41.1%)6.2%  lr: 0.029339  loss: 0.001843  eta: 0h27m  tot: 0h20m2s  (41.2%)6.3%  lr: 0.029329  loss: 0.001839  eta: 0h27m  tot: 0h20m3s  (41.3%)6.5%  lr: 0.029309  loss: 0.001842  eta: 0h27m  tot: 0h20m3s  (41.3%)6.6%  lr: 0.029289  loss: 0.001846  eta: 0h27m  tot: 0h20m4s  (41.3%)6.8%  lr: 0.029259  loss: 0.001842  eta: 0h27m  tot: 0h20m5s  (41.4%)7.3%  lr: 0.029209  loss: 0.001830  eta: 0h27m  tot: 0h20m7s  (41.5%)7.5%  lr: 0.029199  loss: 0.001817  eta: 0h27m  tot: 0h20m8s  (41.5%)7.9%  lr: 0.029139  loss: 0.001813  eta: 0h26m  tot: 0h20m10s  (41.6%)8.0%  lr: 0.029129  loss: 0.001813  eta: 0h26m  tot: 0h20m11s  (41.6%)8.6%  lr: 0.029079  loss: 0.001811  eta: 0h26m  tot: 0h20m14s  (41.7%)8.9%  lr: 0.029079  loss: 0.001808  eta: 0h26m  tot: 0h20m16s  (41.8%)8.9%  lr: 0.029069  loss: 0.001804  eta: 0h26m  tot: 0h20m16s  (41.8%)9.1%  lr: 0.029059  loss: 0.001813  eta: 0h26m  tot: 0h20m17s  (41.8%)9.3%  lr: 0.029039  loss: 0.001827  eta: 0h26m  tot: 0h20m18s  (41.9%)9.8%  lr: 0.028999  loss: 0.001820  eta: 0h26m  tot: 0h20m20s  (42.0%)10.0%  lr: 0.028979  loss: 0.001819  eta: 0h26m  tot: 0h20m21s  (42.0%)10.3%  lr: 0.028969  loss: 0.001825  eta: 0h26m  tot: 0h20m22s  (42.1%)10.4%  lr: 0.028969  loss: 0.001814  eta: 0h26m  tot: 0h20m23s  (42.1%)10.7%  lr: 0.028919  loss: 0.001812  eta: 0h26m  tot: 0h20m24s  (42.1%)11.4%  lr: 0.028819  loss: 0.001829  eta: 0h26m  tot: 0h20m28s  (42.3%)11.4%  lr: 0.028819  loss: 0.001829  eta: 0h26m  tot: 0h20m28s  (42.3%)11.5%  lr: 0.028819  loss: 0.001829  eta: 0h26m  tot: 0h20m29s  (42.3%)11.7%  lr: 0.028779  loss: 0.001820  eta: 0h25m  tot: 0h20m30s  (42.3%)12.2%  lr: 0.028719  loss: 0.001839  eta: 0h25m  tot: 0h20m32s  (42.4%)12.7%  lr: 0.028689  loss: 0.001845  eta: 0h25m  tot: 0h20m35s  (42.5%)12.7%  lr: 0.028689  loss: 0.001844  eta: 0h25m  tot: 0h20m35s  (42.5%)12.7%  lr: 0.028679  loss: 0.001844  eta: 0h25m  tot: 0h20m35s  (42.5%)13.1%  lr: 0.028639  loss: 0.001827  eta: 0h25m  tot: 0h20m37s  (42.6%)13.8%  lr: 0.028559  loss: 0.001828  eta: 0h25m  tot: 0h20m41s  (42.8%)13.9%  lr: 0.028559  loss: 0.001828  eta: 0h25m  tot: 0h20m42s  (42.8%)14.0%  lr: 0.028549  loss: 0.001825  eta: 0h25m  tot: 0h20m43s  (42.8%)14.2%  lr: 0.028529  loss: 0.001827  eta: 0h25m  tot: 0h20m44s  (42.8%)14.4%  lr: 0.028509  loss: 0.001829  eta: 0h25m  tot: 0h20m45s  (42.9%)15.4%  lr: 0.028458  loss: 0.001836  eta: 0h25m  tot: 0h20m51s  (43.1%)15.5%  lr: 0.028438  loss: 0.001833  eta: 0h25m  tot: 0h20m51s  (43.1%)15.5%  lr: 0.028428  loss: 0.001834  eta: 0h25m  tot: 0h20m51s  (43.1%)15.5%  lr: 0.028408  loss: 0.001835  eta: 0h25m  tot: 0h20m52s  (43.1%)16.3%  lr: 0.028358  loss: 0.001830  eta: 0h25m  tot: 0h20m56s  (43.3%)16.6%  lr: 0.028348  loss: 0.001826  eta: 0h25m  tot: 0h20m57s  (43.3%)16.7%  lr: 0.028338  loss: 0.001823  eta: 0h25m  tot: 0h20m58s  (43.3%)17.1%  lr: 0.028338  loss: 0.001837  eta: 0h25m  tot: 0h21m0s  (43.4%)17.2%  lr: 0.028338  loss: 0.001835  eta: 0h25m  tot: 0h21m0s  (43.4%)17.5%  lr: 0.028258  loss: 0.001831  eta: 0h25m  tot: 0h21m2s  (43.5%)17.6%  lr: 0.028258  loss: 0.001834  eta: 0h25m  tot: 0h21m3s  (43.5%)18.4%  lr: 0.028208  loss: 0.001840  eta: 0h25m  tot: 0h21m7s  (43.7%)18.9%  lr: 0.028178  loss: 0.001847  eta: 0h25m  tot: 0h21m9s  (43.8%)19.2%  lr: 0.028138  loss: 0.001844  eta: 0h25m  tot: 0h21m11s  (43.8%)19.3%  lr: 0.028128  loss: 0.001849  eta: 0h25m  tot: 0h21m12s  (43.9%)19.5%  lr: 0.028108  loss: 0.001850  eta: 0h25m  tot: 0h21m12s  (43.9%)19.8%  lr: 0.028078  loss: 0.001849  eta: 0h25m  tot: 0h21m14s  (44.0%)20.0%  lr: 0.028058  loss: 0.001845  eta: 0h25m  tot: 0h21m15s  (44.0%)20.3%  lr: 0.028018  loss: 0.001842  eta: 0h25m  tot: 0h21m17s  (44.1%)20.5%  lr: 0.027998  loss: 0.001837  eta: 0h25m  tot: 0h21m18s  (44.1%)20.6%  lr: 0.027968  loss: 0.001842  eta: 0h25m  tot: 0h21m19s  (44.1%)20.8%  lr: 0.027928  loss: 0.001844  eta: 0h25m  tot: 0h21m20s  (44.2%)20.8%  lr: 0.027918  loss: 0.001845  eta: 0h25m  tot: 0h21m20s  (44.2%)20.9%  lr: 0.027908  loss: 0.001845  eta: 0h25m  tot: 0h21m20s  (44.2%)21.2%  lr: 0.027888  loss: 0.001845  eta: 0h25m  tot: 0h21m22s  (44.2%)21.3%  lr: 0.027878  loss: 0.001845  eta: 0h25m  tot: 0h21m22s  (44.3%)21.3%  lr: 0.027878  loss: 0.001844  eta: 0h25m  tot: 0h21m23s  (44.3%)21.7%  lr: 0.027848  loss: 0.001846  eta: 0h25m  tot: 0h21m25s  (44.3%)22.1%  lr: 0.027808  loss: 0.001854  eta: 0h25m  tot: 0h21m26s  (44.4%)22.5%  lr: 0.027758  loss: 0.001862  eta: 0h25m  tot: 0h21m29s  (44.5%)22.7%  lr: 0.027728  loss: 0.001863  eta: 0h25m  tot: 0h21m30s  (44.5%)22.7%  lr: 0.027728  loss: 0.001862  eta: 0h25m  tot: 0h21m30s  (44.5%)23.0%  lr: 0.027698  loss: 0.001864  eta: 0h25m  tot: 0h21m31s  (44.6%)23.2%  lr: 0.027698  loss: 0.001863  eta: 0h25m  tot: 0h21m32s  (44.6%)23.3%  lr: 0.027668  loss: 0.001865  eta: 0h25m  tot: 0h21m33s  (44.7%)23.3%  lr: 0.027658  loss: 0.001863  eta: 0h25m  tot: 0h21m34s  (44.7%)23.6%  lr: 0.027628  loss: 0.001861  eta: 0h25m  tot: 0h21m36s  (44.7%)23.7%  lr: 0.027608  loss: 0.001860  eta: 0h25m  tot: 0h21m36s  (44.7%)23.8%  lr: 0.027608  loss: 0.001858  eta: 0h25m  tot: 0h21m36s  (44.8%)24.2%  lr: 0.027558  loss: 0.001861  eta: 0h25m  tot: 0h21m39s  (44.8%)24.3%  lr: 0.027548  loss: 0.001860  eta: 0h25m  tot: 0h21m39s  (44.9%)24.7%  lr: 0.027528  loss: 0.001859  eta: 0h24m  tot: 0h21m41s  (44.9%)25.4%  lr: 0.027447  loss: 0.001859  eta: 0h24m  tot: 0h21m44s  (45.1%)25.4%  lr: 0.027437  loss: 0.001860  eta: 0h24m  tot: 0h21m45s  (45.1%)25.6%  lr: 0.027427  loss: 0.001857  eta: 0h24m  tot: 0h21m46s  (45.1%)25.7%  lr: 0.027417  loss: 0.001856  eta: 0h24m  tot: 0h21m46s  (45.1%)26.1%  lr: 0.027397  loss: 0.001851  eta: 0h24m  tot: 0h21m49s  (45.2%)26.3%  lr: 0.027387  loss: 0.001849  eta: 0h24m  tot: 0h21m50s  (45.3%)26.4%  lr: 0.027387  loss: 0.001848  eta: 0h24m  tot: 0h21m50s  (45.3%)27.0%  lr: 0.027317  loss: 0.001843  eta: 0h24m  tot: 0h21m54s  (45.4%)27.2%  lr: 0.027317  loss: 0.001846  eta: 0h24m  tot: 0h21m55s  (45.4%)27.5%  lr: 0.027297  loss: 0.001846  eta: 0h24m  tot: 0h21m57s  (45.5%)27.8%  lr: 0.027247  loss: 0.001846  eta: 0h24m  tot: 0h21m59s  (45.6%)Epoch: 54.5%  lr: 0.024154  loss: 0.001890  eta: 0h23m  tot: 0h24m36s  (50.9%)27.9%  lr: 0.027237  loss: 0.001844  eta: 0h24m  tot: 0h21m59s  (45.6%)28.1%  lr: 0.027197  loss: 0.001844  eta: 0h24m  tot: 0h22m0s  (45.6%)28.1%  lr: 0.027177  loss: 0.001850  eta: 0h24m  tot: 0h22m0s  (45.6%)28.8%  lr: 0.027107  loss: 0.001843  eta: 0h24m  tot: 0h22m4s  (45.8%)29.0%  lr: 0.027097  loss: 0.001847  eta: 0h24m  tot: 0h22m5s  (45.8%)29.0%  lr: 0.027097  loss: 0.001848  eta: 0h24m  tot: 0h22m5s  (45.8%)%  lr: 0.027057  loss: 0.001853  eta: 0h24m  tot: 0h22m8s  (45.9%)29.7%  lr: 0.027027  loss: 0.001850  eta: 0h24m  tot: 0h22m9s  (45.9%)30.0%  lr: 0.026987  loss: 0.001848  eta: 0h24m  tot: 0h22m11s  (46.0%)30.2%  lr: 0.026957  loss: 0.001846  eta: 0h24m  tot: 0h22m12s  (46.0%)30.4%  lr: 0.026907  loss: 0.001844  eta: 0h24m  tot: 0h22m13s  (46.1%)30.5%  lr: 0.026897  loss: 0.001845  eta: 0h24m  tot: 0h22m14s  (46.1%)30.6%  lr: 0.026877  loss: 0.001846  eta: 0h24m  tot: 0h22m15s  (46.1%)30.6%  lr: 0.026877  loss: 0.001846  eta: 0h24m  tot: 0h22m15s  (46.1%)30.7%  lr: 0.026867  loss: 0.001846  eta: 0h24m  tot: 0h22m15s  (46.1%)30.9%  lr: 0.026827  loss: 0.001841  eta: 0h24m  tot: 0h22m17s  (46.2%)31.1%  lr: 0.026817  loss: 0.001843  eta: 0h24m  tot: 0h22m17s  (46.2%)31.8%  lr: 0.026727  loss: 0.001850  eta: 0h24m  tot: 0h22m22s  (46.4%)32.3%  lr: 0.026667  loss: 0.001848  eta: 0h24m  tot: 0h22m25s  (46.5%)32.4%  lr: 0.026657  loss: 0.001848  eta: 0h24m  tot: 0h22m25s  (46.5%)32.4%  lr: 0.026657  loss: 0.001848  eta: 0h24m  tot: 0h22m26s  (46.5%)32.8%  lr: 0.026617  loss: 0.001844  eta: 0h24m  tot: 0h22m28s  (46.6%)33.0%  lr: 0.026607  loss: 0.001844  eta: 0h24m  tot: 0h22m29s  (46.6%)33.0%  lr: 0.026597  loss: 0.001846  eta: 0h24m  tot: 0h22m29s  (46.6%)33.3%  lr: 0.026567  loss: 0.001845  eta: 0h24m  tot: 0h22m31s  (46.7%)33.5%  lr: 0.026527  loss: 0.001848  eta: 0h24m  tot: 0h22m32s  (46.7%)33.5%  lr: 0.026527  loss: 0.001848  eta: 0h24m  tot: 0h22m32s  (46.7%)33.7%  lr: 0.026507  loss: 0.001848  eta: 0h24m  tot: 0h22m33s  (46.7%)33.8%  lr: 0.026507  loss: 0.001847  eta: 0h24m  tot: 0h22m34s  (46.8%)34.2%  lr: 0.026467  loss: 0.001854  eta: 0h24m  tot: 0h22m36s  (46.8%)34.3%  lr: 0.026467  loss: 0.001853  eta: 0h24m  tot: 0h22m37s  (46.9%)34.5%  lr: 0.026436  loss: 0.001856  eta: 0h24m  tot: 0h22m38s  (46.9%)34.9%  lr: 0.026366  loss: 0.001859  eta: 0h24m  tot: 0h22m40s  (47.0%)35.0%  lr: 0.026356  loss: 0.001857  eta: 0h24m  tot: 0h22m41s  (47.0%)35.1%  lr: 0.026356  loss: 0.001857  eta: 0h24m  tot: 0h22m42s  (47.0%)35.2%  lr: 0.026346  loss: 0.001855  eta: 0h24m  tot: 0h22m42s  (47.0%)35.3%  lr: 0.026346  loss: 0.001854  eta: 0h24m  tot: 0h22m43s  (47.1%)35.6%  lr: 0.026306  loss: 0.001851  eta: 0h24m  tot: 0h22m45s  (47.1%)36.3%  lr: 0.026276  loss: 0.001847  eta: 0h24m  tot: 0h22m49s  (47.3%)36.4%  lr: 0.026276  loss: 0.001847  eta: 0h24m  tot: 0h22m49s  (47.3%)37.1%  lr: 0.026206  loss: 0.001852  eta: 0h24m  tot: 0h22m54s  (47.4%)37.2%  lr: 0.026206  loss: 0.001851  eta: 0h24m  tot: 0h22m54s  (47.4%)37.3%  lr: 0.026186  loss: 0.001852  eta: 0h24m  tot: 0h22m55s  (47.5%)37.4%  lr: 0.026186  loss: 0.001852  eta: 0h24m  tot: 0h22m56s  (47.5%)37.7%  lr: 0.026126  loss: 0.001856  eta: 0h24m  tot: 0h22m58s  (47.5%)37.8%  lr: 0.026126  loss: 0.001855  eta: 0h24m  tot: 0h22m58s  (47.6%)38.3%  lr: 0.026066  loss: 0.001853  eta: 0h24m  tot: 0h23m1s  (47.7%)38.5%  lr: 0.026046  loss: 0.001853  eta: 0h24m  tot: 0h23m2s  (47.7%)38.8%  lr: 0.025976  loss: 0.001858  eta: 0h24m  tot: 0h23m4s  (47.8%)38.9%  lr: 0.025966  loss: 0.001858  eta: 0h24m  tot: 0h23m4s  (47.8%)39.0%  lr: 0.025956  loss: 0.001859  eta: 0h24m  tot: 0h23m5s  (47.8%)39.1%  lr: 0.025936  loss: 0.001860  eta: 0h24m  tot: 0h23m6s  (47.8%)39.2%  lr: 0.025926  loss: 0.001860  eta: 0h24m  tot: 0h23m6s  (47.8%)39.4%  lr: 0.025856  loss: 0.001861  eta: 0h24m  tot: 0h23m8s  (47.9%)39.5%  lr: 0.025846  loss: 0.001861  eta: 0h24m  tot: 0h23m8s  (47.9%)39.6%  lr: 0.025836  loss: 0.001860  eta: 0h24m  tot: 0h23m9s  (47.9%)39.7%  lr: 0.025826  loss: 0.001862  eta: 0h24m  tot: 0h23m10s  (47.9%)40.3%  lr: 0.025746  loss: 0.001867  eta: 0h24m  tot: 0h23m13s  (48.1%)40.4%  lr: 0.025736  loss: 0.001869  eta: 0h24m  tot: 0h23m13s  (48.1%)41.9%  lr: 0.025546  loss: 0.001866  eta: 0h24m  tot: 0h23m22s  (48.4%)42.2%  lr: 0.025526  loss: 0.001868  eta: 0h24m  tot: 0h23m24s  (48.4%)42.2%  lr: 0.025526  loss: 0.001868  eta: 0h24m  tot: 0h23m24s  (48.4%)42.4%  lr: 0.025506  loss: 0.001868  eta: 0h24m  tot: 0h23m25s  (48.5%)42.5%  lr: 0.025496  loss: 0.001867  eta: 0h24m  tot: 0h23m26s  (48.5%)42.5%  lr: 0.025486  loss: 0.001866  eta: 0h24m  tot: 0h23m26s  (48.5%)42.7%  lr: 0.025486  loss: 0.001870  eta: 0h24m  tot: 0h23m27s  (48.5%)42.8%  lr: 0.025486  loss: 0.001871  eta: 0h24m  tot: 0h23m27s  (48.6%)42.9%  lr: 0.025415  loss: 0.001870  eta: 0h24m  tot: 0h23m28s  (48.6%)43.1%  lr: 0.025405  loss: 0.001868  eta: 0h24m  tot: 0h23m29s  (48.6%)43.2%  lr: 0.025405  loss: 0.001870  eta: 0h24m  tot: 0h23m30s  (48.6%)43.3%  lr: 0.025395  loss: 0.001871  eta: 0h24m  tot: 0h23m30s  (48.7%)43.4%  lr: 0.025395  loss: 0.001872  eta: 0h24m  tot: 0h23m31s  (48.7%)43.4%  lr: 0.025395  loss: 0.001871  eta: 0h24m  tot: 0h23m31s  (48.7%)43.4%  lr: 0.025395  loss: 0.001871  eta: 0h24m  tot: 0h23m31s  (48.7%)43.6%  lr: 0.025385  loss: 0.001873  eta: 0h24m  tot: 0h23m32s  (48.7%)43.9%  lr: 0.025325  loss: 0.001875  eta: 0h24m  tot: 0h23m34s  (48.8%)44.1%  lr: 0.025315  loss: 0.001873  eta: 0h24m  tot: 0h23m35s  (48.8%)44.3%  lr: 0.025305  loss: 0.001876  eta: 0h23m  tot: 0h23m36s  (48.9%)44.7%  lr: 0.025245  loss: 0.001875  eta: 0h23m  tot: 0h23m38s  (48.9%)44.8%  lr: 0.025215  loss: 0.001873  eta: 0h23m  tot: 0h23m39s  (49.0%)44.9%  lr: 0.025205  loss: 0.001873  eta: 0h23m  tot: 0h23m39s  (49.0%)45.2%  lr: 0.025175  loss: 0.001876  eta: 0h23m  tot: 0h23m41s  (49.0%)45.5%  lr: 0.025155  loss: 0.001877  eta: 0h23m  tot: 0h23m43s  (49.1%)45.5%  lr: 0.025155  loss: 0.001878  eta: 0h23m  tot: 0h23m43s  (49.1%)45.8%  lr: 0.025105  loss: 0.001882  eta: 0h23m  tot: 0h23m45s  (49.2%)46.4%  lr: 0.025045  loss: 0.001880  eta: 0h23m  tot: 0h23m48s  (49.3%)46.9%  lr: 0.024975  loss: 0.001877  eta: 0h23m  tot: 0h23m51s  (49.4%)47.2%  lr: 0.024925  loss: 0.001877  eta: 0h23m  tot: 0h23m53s  (49.4%)47.3%  lr: 0.024915  loss: 0.001877  eta: 0h23m  tot: 0h23m53s  (49.5%)47.9%  lr: 0.024845  loss: 0.001874  eta: 0h23m  tot: 0h23m57s  (49.6%)48.2%  lr: 0.024785  loss: 0.001876  eta: 0h23m  tot: 0h23m59s  (49.6%)48.3%  lr: 0.024785  loss: 0.001876  eta: 0h23m  tot: 0h24m0s  (49.7%)48.4%  lr: 0.024775  loss: 0.001877  eta: 0h23m  tot: 0h24m1s  (49.7%)48.5%  lr: 0.024775  loss: 0.001877  eta: 0h23m  tot: 0h24m1s  (49.7%)48.8%  lr: 0.024735  loss: 0.001879  eta: 0h23m  tot: 0h24m3s  (49.8%)48.9%  lr: 0.024735  loss: 0.001880  eta: 0h23m  tot: 0h24m4s  (49.8%)49.8%  lr: 0.024685  loss: 0.001883  eta: 0h23m  tot: 0h24m9s  (50.0%)50.2%  lr: 0.024665  loss: 0.001882  eta: 0h23m  tot: 0h24m12s  (50.0%)50.2%  lr: 0.024665  loss: 0.001881  eta: 0h23m  tot: 0h24m12s  (50.0%)50.3%  lr: 0.024665  loss: 0.001880  eta: 0h23m  tot: 0h24m12s  (50.1%)50.5%  lr: 0.024655  loss: 0.001880  eta: 0h23m  tot: 0h24m13s  (50.1%)50.6%  lr: 0.024625  loss: 0.001880  eta: 0h23m  tot: 0h24m14s  (50.1%)50.7%  lr: 0.024615  loss: 0.001880  eta: 0h23m  tot: 0h24m15s  (50.1%)51.4%  lr: 0.024545  loss: 0.001882  eta: 0h23m  tot: 0h24m19s  (50.3%)51.6%  lr: 0.024525  loss: 0.001884  eta: 0h23m  tot: 0h24m20s  (50.3%)51.6%  lr: 0.024515  loss: 0.001884  eta: 0h23m  tot: 0h24m20s  (50.3%)52.1%  lr: 0.024425  loss: 0.001883  eta: 0h23m  tot: 0h24m23s  (50.4%)52.2%  lr: 0.024415  loss: 0.001883  eta: 0h23m  tot: 0h24m23s  (50.4%)52.2%  lr: 0.024415  loss: 0.001884  eta: 0h23m  tot: 0h24m24s  (50.4%)52.3%  lr: 0.024415  loss: 0.001884  eta: 0h23m  tot: 0h24m24s  (50.5%)53.3%  lr: 0.024314  loss: 0.001888  eta: 0h23m  tot: 0h24m29s  (50.7%)53.6%  lr: 0.024284  loss: 0.001891  eta: 0h23m  tot: 0h24m31s  (50.7%)54.0%  lr: 0.024224  loss: 0.001888  eta: 0h23m  tot: 0h24m33s  (50.8%)54.2%  lr: 0.024194  loss: 0.001888  eta: 0h23m  tot: 0h24m34s  (50.8%)54.5%  lr: 0.024154  loss: 0.001890  eta: 0h23m  tot: 0h24m36s  (50.9%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 84.3%  lr: 0.021301  loss: 0.001903  eta: 0h20m  tot: 0h27m33s  (56.9%)54.6%  lr: 0.024154  loss: 0.001890  eta: 0h23m  tot: 0h24m37s  (50.9%)54.6%  lr: 0.024154  loss: 0.001890  eta: 0h23m  tot: 0h24m37s  (50.9%)54.8%  lr: 0.024144  loss: 0.001891  eta: 0h23m  tot: 0h24m38s  (51.0%)55.0%  lr: 0.024104  loss: 0.001891  eta: 0h23m  tot: 0h24m39s  (51.0%)55.1%  lr: 0.024094  loss: 0.001890  eta: 0h23m  tot: 0h24m40s  (51.0%)55.5%  lr: 0.024074  loss: 0.001891  eta: 0h23m  tot: 0h24m42s  (51.1%)55.9%  lr: 0.024044  loss: 0.001891  eta: 0h23m  tot: 0h24m45s  (51.2%)56.1%  lr: 0.024024  loss: 0.001892  eta: 0h23m  tot: 0h24m45s  (51.2%)56.1%  lr: 0.024004  loss: 0.001891  eta: 0h23m  tot: 0h24m46s  (51.2%)56.6%  lr: 0.023934  loss: 0.001893  eta: 0h23m  tot: 0h24m49s  (51.3%)56.8%  lr: 0.023874  loss: 0.001893  eta: 0h23m  tot: 0h24m50s  (51.4%)57.1%  lr: 0.023874  loss: 0.001894  eta: 0h23m  tot: 0h24m51s  (51.4%)57.5%  lr: 0.023834  loss: 0.001895  eta: 0h22m  tot: 0h24m54s  (51.5%)57.9%  lr: 0.023794  loss: 0.001895  eta: 0h22m  tot: 0h24m56s  (51.6%)58.2%  lr: 0.023764  loss: 0.001897  eta: 0h22m  tot: 0h24m58s  (51.6%)58.3%  lr: 0.023754  loss: 0.001896  eta: 0h22m  tot: 0h24m58s  (51.7%)59.0%  lr: 0.023674  loss: 0.001900  eta: 0h22m  tot: 0h25m2s  (51.8%)59.1%  lr: 0.023674  loss: 0.001901  eta: 0h22m  tot: 0h25m3s  (51.8%)59.2%  lr: 0.023674  loss: 0.001902  eta: 0h22m  tot: 0h25m3s  (51.8%)59.5%  lr: 0.023644  loss: 0.001901  eta: 0h22m  tot: 0h25m5s  (51.9%)60.0%  lr: 0.023594  loss: 0.001906  eta: 0h22m  tot: 0h25m8s  (52.0%)60.1%  lr: 0.023574  loss: 0.001907  eta: 0h22m  tot: 0h25m9s  (52.0%)60.1%  lr: 0.023544  loss: 0.001908  eta: 0h22m  tot: 0h25m9s  (52.0%)60.3%  lr: 0.023514  loss: 0.001906  eta: 0h22m  tot: 0h25m10s  (52.1%)60.7%  lr: 0.023504  loss: 0.001903  eta: 0h22m  tot: 0h25m12s  (52.1%)60.8%  lr: 0.023504  loss: 0.001903  eta: 0h22m  tot: 0h25m13s  (52.2%)61.2%  lr: 0.023484  loss: 0.001901  eta: 0h22m  tot: 0h25m15s  (52.2%)%  lr: 0.023454  loss: 0.001903  eta: 0h22m  tot: 0h25m17s  (52.3%)61.6%  lr: 0.023454  loss: 0.001902  eta: 0h22m  tot: 0h25m18s  (52.3%)61.7%  lr: 0.023444  loss: 0.001901  eta: 0h22m  tot: 0h25m18s  (52.3%)61.8%  lr: 0.023424  loss: 0.001901  eta: 0h22m  tot: 0h25m19s  (52.4%)61.9%  lr: 0.023404  loss: 0.001901  eta: 0h22m  tot: 0h25m20s  (52.4%)62.4%  lr: 0.023333  loss: 0.001903  eta: 0h22m  tot: 0h25m23s  (52.5%)62.6%  lr: 0.023313  loss: 0.001902  eta: 0h22m  tot: 0h25m24s  (52.5%)63.2%  lr: 0.023263  loss: 0.001900  eta: 0h22m  tot: 0h25m27s  (52.6%)63.3%  lr: 0.023263  loss: 0.001899  eta: 0h22m  tot: 0h25m28s  (52.7%)63.7%  lr: 0.023213  loss: 0.001902  eta: 0h22m  tot: 0h25m31s  (52.7%)63.9%  lr: 0.023203  loss: 0.001903  eta: 0h22m  tot: 0h25m31s  (52.8%)64.5%  lr: 0.023163  loss: 0.001902  eta: 0h22m  tot: 0h25m35s  (52.9%)64.7%  lr: 0.023143  loss: 0.001902  eta: 0h22m  tot: 0h25m36s  (52.9%)64.8%  lr: 0.023123  loss: 0.001901  eta: 0h22m  tot: 0h25m37s  (53.0%)64.8%  lr: 0.023113  loss: 0.001900  eta: 0h22m  tot: 0h25m37s  (53.0%)65.2%  lr: 0.023073  loss: 0.001897  eta: 0h22m  tot: 0h25m40s  (53.0%)65.4%  lr: 0.023043  loss: 0.001896  eta: 0h22m  tot: 0h25m40s  (53.1%)41s  (53.1%)0.001898  eta: 0h22m  tot: 0h25m43s  (53.2%)m43s  (53.2%)66.0%  lr: 0.022983  loss: 0.001898  eta: 0h22m  tot: 0h25m44s  (53.2%)66.2%  lr: 0.022983  loss: 0.001898  eta: 0h22m  tot: 0h25m45s  (53.2%)66.6%  lr: 0.022953  loss: 0.001898  eta: 0h22m  tot: 0h25m48s  (53.3%)66.9%  lr: 0.022943  loss: 0.001897  eta: 0h22m  tot: 0h25m49s  (53.4%)67.0%  lr: 0.022923  loss: 0.001898  eta: 0h22m  tot: 0h25m50s  (53.4%)%  lr: 0.022923  loss: 0.001898  eta: 0h22m  tot: 0h25m50s  (53.4%)67.7%  lr: 0.022863  loss: 0.001897  eta: 0h22m  tot: 0h25m54s  (53.5%)68.3%  lr: 0.022813  loss: 0.001898  eta: 0h22m  tot: 0h25m58s  (53.7%)68.5%  lr: 0.022783  loss: 0.001897  eta: 0h22m  tot: 0h25m59s  (53.7%)68.6%  lr: 0.022783  loss: 0.001897  eta: 0h22m  tot: 0h25m59s  (53.7%)68.8%  lr: 0.022783  loss: 0.001896  eta: 0h22m  tot: 0h26m1s  (53.8%)69.2%  lr: 0.022743  loss: 0.001895  eta: 0h22m  tot: 0h26m3s  (53.8%)69.2%  lr: 0.022733  loss: 0.001895  eta: 0h22m  tot: 0h26m3s  (53.8%)69.6%  lr: 0.022713  loss: 0.001898  eta: 0h21m  tot: 0h26m5s  (53.9%)70.6%  lr: 0.022593  loss: 0.001897  eta: 0h21m  tot: 0h26m10s  (54.1%)71.1%  lr: 0.022553  loss: 0.001896  eta: 0h21m  tot: 0h26m13s  (54.2%)71.4%  lr: 0.022543  loss: 0.001897  eta: 0h21m  tot: 0h26m15s  (54.3%)71.6%  lr: 0.022543  loss: 0.001896  eta: 0h21m  tot: 0h26m16s  (54.3%)71.8%  lr: 0.022523  loss: 0.001896  eta: 0h21m  tot: 0h26m17s  (54.4%)71.9%  lr: 0.022503  loss: 0.001895  eta: 0h21m  tot: 0h26m18s  (54.4%)72.1%  lr: 0.022463  loss: 0.001895  eta: 0h21m  tot: 0h26m20s  (54.4%)72.3%  lr: 0.022453  loss: 0.001894  eta: 0h21m  tot: 0h26m21s  (54.5%)72.5%  lr: 0.022423  loss: 0.001894  eta: 0h21m  tot: 0h26m22s  (54.5%)72.8%  lr: 0.022382  loss: 0.001894  eta: 0h21m  tot: 0h26m24s  (54.6%)72.9%  lr: 0.022382  loss: 0.001894  eta: 0h21m  tot: 0h26m24s  (54.6%)73.2%  lr: 0.022352  loss: 0.001894  eta: 0h21m  tot: 0h26m26s  (54.6%)73.6%  lr: 0.022302  loss: 0.001893  eta: 0h21m  tot: 0h26m28s  (54.7%)73.7%  lr: 0.022292  loss: 0.001893  eta: 0h21m  tot: 0h26m29s  (54.7%)74.3%  lr: 0.022262  loss: 0.001893  eta: 0h21m  tot: 0h26m33s  (54.9%)74.4%  lr: 0.022242  loss: 0.001893  eta: 0h21m  tot: 0h26m33s  (54.9%)74.6%  lr: 0.022232  loss: 0.001893  eta: 0h21m  tot: 0h26m34s  (54.9%)74.7%  lr: 0.022232  loss: 0.001892  eta: 0h21m  tot: 0h26m35s  (54.9%)74.9%  lr: 0.022142  loss: 0.001892  eta: 0h21m  tot: 0h26m36s  (55.0%)  loss: 0.001893  eta: 0h21m  tot: 0h26m38s  (55.0%)75.5%  lr: 0.022092  loss: 0.001893  eta: 0h21m  tot: 0h26m40s  (55.1%)75.8%  lr: 0.022062  loss: 0.001896  eta: 0h21m  tot: 0h26m41s  (55.2%)76.0%  lr: 0.022062  loss: 0.001897  eta: 0h21m  tot: 0h26m43s  (55.2%)76.0%  lr: 0.022062  loss: 0.001897  eta: 0h21m  tot: 0h26m43s  (55.2%)76.2%  lr: 0.022012  loss: 0.001897  eta: 0h21m  tot: 0h26m44s  (55.2%)76.8%  lr: 0.021972  loss: 0.001896  eta: 0h21m  tot: 0h26m47s  (55.4%)77.0%  lr: 0.021972  loss: 0.001896  eta: 0h21m  tot: 0h26m49s  (55.4%)77.1%  lr: 0.021972  loss: 0.001896  eta: 0h21m  tot: 0h26m49s  (55.4%)78.2%  lr: 0.021912  loss: 0.001896  eta: 0h21m  tot: 0h26m56s  (55.6%)78.6%  lr: 0.021862  loss: 0.001895  eta: 0h21m  tot: 0h26m58s  (55.7%)79.1%  lr: 0.021812  loss: 0.001896  eta: 0h21m  tot: 0h27m1s  (55.8%)79.1%  lr: 0.021812  loss: 0.001896  eta: 0h21m  tot: 0h27m1s  (55.8%)79.7%  lr: 0.021742  loss: 0.001899  eta: 0h21m  tot: 0h27m4s  (55.9%)79.8%  lr: 0.021722  loss: 0.001899  eta: 0h21m  tot: 0h27m5s  (56.0%)79.9%  lr: 0.021712  loss: 0.001899  eta: 0h21m  tot: 0h27m6s  (56.0%)79.9%  lr: 0.021692  loss: 0.001899  eta: 0h21m  tot: 0h27m6s  (56.0%)80.2%  lr: 0.021662  loss: 0.001900  eta: 0h21m  tot: 0h27m7s  (56.0%)80.2%  lr: 0.021662  loss: 0.001900  eta: 0h21m  tot: 0h27m8s  (56.0%)80.5%  lr: 0.021622  loss: 0.001899  eta: 0h21m  tot: 0h27m9s  (56.1%)80.7%  lr: 0.021602  loss: 0.001899  eta: 0h21m  tot: 0h27m10s  (56.1%)80.8%  lr: 0.021592  loss: 0.001899  eta: 0h21m  tot: 0h27m11s  (56.2%)80.9%  lr: 0.021582  loss: 0.001899  eta: 0h20m  tot: 0h27m12s  (56.2%)81.1%  lr: 0.021572  loss: 0.001899  eta: 0h20m  tot: 0h27m13s  (56.2%)81.2%  lr: 0.021572  loss: 0.001900  eta: 0h20m  tot: 0h27m14s  (56.2%)81.3%  lr: 0.021562  loss: 0.001901  eta: 0h20m  tot: 0h27m14s  (56.3%)81.6%  lr: 0.021552  loss: 0.001901  eta: 0h20m  tot: 0h27m16s  (56.3%)81.8%  lr: 0.021542  loss: 0.001899  eta: 0h20m  tot: 0h27m17s  (56.4%)82.2%  lr: 0.021512  loss: 0.001899  eta: 0h20m  tot: 0h27m19s  (56.4%)82.4%  lr: 0.021492  loss: 0.001899  eta: 0h20m  tot: 0h27m21s  (56.5%)82.6%  lr: 0.021472  loss: 0.001899  eta: 0h20m  tot: 0h27m23s  (56.5%)83.0%  lr: 0.021442  loss: 0.001902  eta: 0h20m  tot: 0h27m25s  (56.6%)m  tot: 0h27m27s  (56.7%)83.6%  lr: 0.021372  loss: 0.001903  eta: 0h20m  tot: 0h27m29s  (56.7%)83.9%  lr: 0.021331  loss: 0.001904  eta: 0h20m  tot: 0h27m31s  (56.8%)84.1%  lr: 0.021321  loss: 0.001904  eta: 0h20m  tot: 0h27m32s  (56.8%)84.1%  lr: 0.021321  loss: 0.001904  eta: 0h20m  tot: 0h27m32s  (56.8%)84.3%  lr: 0.021301  loss: 0.001903  eta: 0h20m  tot: 0h27m33s  (56.9%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100.0%  lr: 0.020000  loss: 0.001904  eta: 0h19m  tot: 0h29m0s  (60.0%)84.4%  lr: 0.021301  loss: 0.001903  eta: 0h20m  tot: 0h27m34s  (56.9%)84.5%  lr: 0.021291  loss: 0.001903  eta: 0h20m  tot: 0h27m35s  (56.9%)84.6%  lr: 0.021271  loss: 0.001902  eta: 0h20m  tot: 0h27m36s  (56.9%)84.7%  lr: 0.021271  loss: 0.001902  eta: 0h20m  tot: 0h27m36s  (56.9%)84.9%  lr: 0.021261  loss: 0.001902  eta: 0h20m  tot: 0h27m37s  (57.0%)85.2%  lr: 0.021251  loss: 0.001902  eta: 0h20m  tot: 0h27m39s  (57.0%)85.3%  lr: 0.021221  loss: 0.001902  eta: 0h20m  tot: 0h27m40s  (57.1%)85.5%  lr: 0.021201  loss: 0.001902  eta: 0h20m  tot: 0h27m41s  (57.1%)85.8%  lr: 0.021171  loss: 0.001901  eta: 0h20m  tot: 0h27m43s  (57.2%)%  lr: 0.021131  loss: 0.001902  eta: 0h20m  tot: 0h27m45s  (57.2%)  lr: 0.021121  loss: 0.001901  eta: 0h20m  tot: 0h27m47s  (57.2%)86.3%  lr: 0.021111  loss: 0.001900  eta: 0h20m  tot: 0h27m48s  (57.3%)86.5%  lr: 0.021101  loss: 0.001899  eta: 0h20m  tot: 0h27m49s  (57.3%)86.6%  lr: 0.021101  loss: 0.001899  eta: 0h20m  tot: 0h27m50s  (57.3%)86.6%  lr: 0.021091  loss: 0.001900  eta: 0h20m  tot: 0h27m50s  (57.3%)86.8%  lr: 0.021081  loss: 0.001900  eta: 0h20m  tot: 0h27m51s  (57.4%)86.9%  lr: 0.021081  loss: 0.001900  eta: 0h20m  tot: 0h27m51s  (57.4%)86.9%  lr: 0.021081  loss: 0.001900  eta: 0h20m  tot: 0h27m52s  (57.4%)87.0%  lr: 0.021071  loss: 0.001900  eta: 0h20m  tot: 0h27m52s  (57.4%)87.4%  lr: 0.021021  loss: 0.001901  eta: 0h20m  tot: 0h27m55s  (57.5%)87.5%  lr: 0.021021  loss: 0.001900  eta: 0h20m  tot: 0h27m55s  (57.5%)87.7%  lr: 0.021001  loss: 0.001900  eta: 0h20m  tot: 0h27m56s  (57.5%)87.7%  lr: 0.021001  loss: 0.001899  eta: 0h20m  tot: 0h27m56s  (57.5%)87.9%  lr: 0.020981  loss: 0.001899  eta: 0h20m  tot: 0h27m57s  (57.6%)88.0%  lr: 0.020981  loss: 0.001898  eta: 0h20m  tot: 0h27m58s  (57.6%)88.2%  lr: 0.020911  loss: 0.001897  eta: 0h20m  tot: 0h27m59s  (57.6%)88.4%  lr: 0.020911  loss: 0.001898  eta: 0h20m  tot: 0h28m1s  (57.7%)88.5%  lr: 0.020901  loss: 0.001899  eta: 0h20m  tot: 0h28m1s  (57.7%)88.8%  lr: 0.020861  loss: 0.001899  eta: 0h20m  tot: 0h28m3s  (57.8%)88.9%  lr: 0.020861  loss: 0.001899  eta: 0h20m  tot: 0h28m4s  (57.8%)89.0%  lr: 0.020861  loss: 0.001898  eta: 0h20m  tot: 0h28m4s  (57.8%)89.2%  lr: 0.020821  loss: 0.001898  eta: 0h20m  tot: 0h28m5s  (57.8%)%  lr: 0.020791  loss: 0.001899  eta: 0h20m  tot: 0h28m8s  (57.9%)89.8%  lr: 0.020791  loss: 0.001899  eta: 0h20m  tot: 0h28m9s  (58.0%)%  lr: 0.020781  loss: 0.001899  eta: 0h20m  tot: 0h28m9s  (58.0%)90.3%  lr: 0.020731  loss: 0.001899  eta: 0h20m  tot: 0h28m12s  (58.1%)90.4%  lr: 0.020731  loss: 0.001899  eta: 0h20m  tot: 0h28m12s  (58.1%)90.6%  lr: 0.020731  loss: 0.001898  eta: 0h20m  tot: 0h28m13s  (58.1%)90.6%  lr: 0.020731  loss: 0.001898  eta: 0h20m  tot: 0h28m14s  (58.1%)90.8%  lr: 0.020721  loss: 0.001899  eta: 0h20m  tot: 0h28m15s  (58.2%)91.0%  lr: 0.020701  loss: 0.001899  eta: 0h20m  tot: 0h28m16s  (58.2%)91.0%  lr: 0.020691  loss: 0.001899  eta: 0h20m  tot: 0h28m16s  (58.2%)91.2%  lr: 0.020681  loss: 0.001898  eta: 0h20m  tot: 0h28m17s  (58.2%)91.4%  lr: 0.020681  loss: 0.001899  eta: 0h20m  tot: 0h28m18s  (58.3%)91.4%  lr: 0.020681  loss: 0.001899  eta: 0h20m  tot: 0h28m19s  (58.3%)91.6%  lr: 0.020681  loss: 0.001899  eta: 0h20m  tot: 0h28m19s  (58.3%)91.6%  lr: 0.020681  loss: 0.001899  eta: 0h20m  tot: 0h28m20s  (58.3%)92.1%  lr: 0.020601  loss: 0.001899  eta: 0h20m  tot: 0h28m23s  (58.4%)92.4%  lr: 0.020551  loss: 0.001897  eta: 0h20m  tot: 0h28m25s  (58.5%)92.5%  lr: 0.020551  loss: 0.001897  eta: 0h20m  tot: 0h28m25s  (58.5%)92.8%  lr: 0.020521  loss: 0.001901  eta: 0h20m  tot: 0h28m27s  (58.6%)92.9%  lr: 0.020511  loss: 0.001901  eta: 0h20m  tot: 0h28m27s  (58.6%)93.6%  lr: 0.020361  loss: 0.001903  eta: 0h20m  tot: 0h28m32s  (58.7%)93.7%  lr: 0.020350  loss: 0.001904  eta: 0h20m  tot: 0h28m32s  (58.7%)94.3%  lr: 0.020310  loss: 0.001904  eta: 0h19m  tot: 0h28m36s  (58.9%)94.5%  lr: 0.020250  loss: 0.001903  eta: 0h19m  tot: 0h28m37s  (58.9%)94.6%  lr: 0.020240  loss: 0.001904  eta: 0h19m  tot: 0h28m38s  (58.9%)95.5%  lr: 0.020180  loss: 0.001905  eta: 0h19m  tot: 0h28m43s  (59.1%)95.6%  lr: 0.020180  loss: 0.001905  eta: 0h19m  tot: 0h28m44s  (59.1%)95.9%  lr: 0.020170  loss: 0.001906  eta: 0h19m  tot: 0h28m45s  (59.2%)96.3%  lr: 0.020130  loss: 0.001905  eta: 0h19m  tot: 0h28m47s  (59.3%)96.7%  lr: 0.020110  loss: 0.001904  eta: 0h19m  tot: 0h28m49s  (59.3%)97.6%  lr: 0.020080  loss: 0.001901  eta: 0h19m  tot: 0h28m53s  (59.5%)\n",
      " ---+++                Epoch    2 Train error : 0.00189127 +++--- ���\n",
      "Training epoch 3: 0.02 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 26.4%  lr: 0.017207  loss: 0.001582  eta: 0h17m  tot: 0h31m39s  (65.3%)2%  lr: 0.019980  loss: 0.001774  eta: 0h19m  tot: 0h29m2s  (60.0%)0.4%  lr: 0.019920  loss: 0.001996  eta: 0h19m  tot: 0h29m3s  (60.1%)0.5%  lr: 0.019900  loss: 0.001924  eta: 0h19m  tot: 0h29m4s  (60.1%)0.7%  lr: 0.019890  loss: 0.001830  eta: 0h19m  tot: 0h29m4s  (60.1%)0.9%  lr: 0.019880  loss: 0.001797  eta: 0h19m  tot: 0h29m6s  (60.2%)1.0%  lr: 0.019850  loss: 0.001758  eta: 0h19m  tot: 0h29m7s  (60.2%)1.7%  lr: 0.019790  loss: 0.001656  eta: 0h19m  tot: 0h29m11s  (60.3%)2.2%  lr: 0.019730  loss: 0.001619  eta: 0h20m  tot: 0h29m14s  (60.4%)2.4%  lr: 0.019710  loss: 0.001627  eta: 0h20m  tot: 0h29m15s  (60.5%)3.0%  lr: 0.019650  loss: 0.001689  eta: 0h20m  tot: 0h29m19s  (60.6%)3.2%  lr: 0.019630  loss: 0.001681  eta: 0h19m  tot: 0h29m20s  (60.6%)3.9%  lr: 0.019590  loss: 0.001658  eta: 0h19m  tot: 0h29m24s  (60.8%)4.6%  lr: 0.019540  loss: 0.001579  eta: 0h19m  tot: 0h29m28s  (60.9%)4.9%  lr: 0.019510  loss: 0.001585  eta: 0h19m  tot: 0h29m30s  (61.0%)4.9%  lr: 0.019510  loss: 0.001596  eta: 0h19m  tot: 0h29m30s  (61.0%)5.1%  lr: 0.019500  loss: 0.001600  eta: 0h19m  tot: 0h29m31s  (61.0%)5.3%  lr: 0.019459  loss: 0.001598  eta: 0h19m  tot: 0h29m32s  (61.1%)5.3%  lr: 0.019459  loss: 0.001598  eta: 0h19m  tot: 0h29m33s  (61.1%)5.4%  lr: 0.019439  loss: 0.001625  eta: 0h19m  tot: 0h29m33s  (61.1%)5.7%  lr: 0.019379  loss: 0.001630  eta: 0h19m  tot: 0h29m35s  (61.1%)6.1%  lr: 0.019319  loss: 0.001639  eta: 0h19m  tot: 0h29m37s  (61.2%)6.1%  lr: 0.019309  loss: 0.001645  eta: 0h19m  tot: 0h29m37s  (61.2%)6.5%  lr: 0.019249  loss: 0.001620  eta: 0h19m  tot: 0h29m40s  (61.3%)6.7%  lr: 0.019239  loss: 0.001617  eta: 0h19m  tot: 0h29m41s  (61.3%)7.0%  lr: 0.019179  loss: 0.001605  eta: 0h19m  tot: 0h29m42s  (61.4%)7.3%  lr: 0.019139  loss: 0.001587  eta: 0h19m  tot: 0h29m44s  (61.5%)7.4%  lr: 0.019129  loss: 0.001580  eta: 0h19m  tot: 0h29m45s  (61.5%)7.5%  lr: 0.019129  loss: 0.001594  eta: 0h19m  tot: 0h29m45s  (61.5%)8.3%  lr: 0.019029  loss: 0.001592  eta: 0h19m  tot: 0h29m50s  (61.7%)8.9%  lr: 0.018959  loss: 0.001588  eta: 0h19m  tot: 0h29m54s  (61.8%)9.0%  lr: 0.018959  loss: 0.001584  eta: 0h19m  tot: 0h29m54s  (61.8%)9.5%  lr: 0.018949  loss: 0.001583  eta: 0h18m  tot: 0h29m57s  (61.9%)9.6%  lr: 0.018949  loss: 0.001580  eta: 0h18m  tot: 0h29m58s  (61.9%)9.8%  lr: 0.018929  loss: 0.001590  eta: 0h19m  tot: 0h29m59s  (62.0%)9.8%  lr: 0.018909  loss: 0.001593  eta: 0h19m  tot: 0h30m0s  (62.0%)9.9%  lr: 0.018889  loss: 0.001592  eta: 0h19m  tot: 0h30m1s  (62.0%)10.1%  lr: 0.018889  loss: 0.001605  eta: 0h19m  tot: 0h30m1s  (62.0%)10.2%  lr: 0.018889  loss: 0.001597  eta: 0h19m  tot: 0h30m2s  (62.0%)10.4%  lr: 0.018869  loss: 0.001602  eta: 0h19m  tot: 0h30m3s  (62.1%)10.4%  lr: 0.018869  loss: 0.001601  eta: 0h19m  tot: 0h30m3s  (62.1%)10.6%  lr: 0.018869  loss: 0.001594  eta: 0h19m  tot: 0h30m4s  (62.1%)10.7%  lr: 0.018839  loss: 0.001589  eta: 0h19m  tot: 0h30m5s  (62.1%)10.9%  lr: 0.018829  loss: 0.001588  eta: 0h18m  tot: 0h30m6s  (62.2%)11.0%  lr: 0.018829  loss: 0.001587  eta: 0h18m  tot: 0h30m7s  (62.2%)11.5%  lr: 0.018789  loss: 0.001599  eta: 0h18m  tot: 0h30m10s  (62.3%)11.6%  lr: 0.018789  loss: 0.001598  eta: 0h18m  tot: 0h30m10s  (62.3%)12.0%  lr: 0.018739  loss: 0.001589  eta: 0h18m  tot: 0h30m13s  (62.4%)12.0%  lr: 0.018729  loss: 0.001586  eta: 0h18m  tot: 0h30m13s  (62.4%)12.2%  lr: 0.018719  loss: 0.001589  eta: 0h18m  tot: 0h30m14s  (62.4%)12.4%  lr: 0.018689  loss: 0.001589  eta: 0h18m  tot: 0h30m15s  (62.5%)12.9%  lr: 0.018619  loss: 0.001586  eta: 0h18m  tot: 0h30m18s  (62.6%)13.1%  lr: 0.018599  loss: 0.001585  eta: 0h18m  tot: 0h30m19s  (62.6%)13.3%  lr: 0.018589  loss: 0.001590  eta: 0h18m  tot: 0h30m21s  (62.7%)14.0%  lr: 0.018479  loss: 0.001598  eta: 0h18m  tot: 0h30m25s  (62.8%)14.1%  lr: 0.018468  loss: 0.001598  eta: 0h18m  tot: 0h30m25s  (62.8%)14.2%  lr: 0.018458  loss: 0.001596  eta: 0h18m  tot: 0h30m26s  (62.8%)14.4%  lr: 0.018428  loss: 0.001595  eta: 0h18m  tot: 0h30m27s  (62.9%)14.5%  lr: 0.018408  loss: 0.001594  eta: 0h18m  tot: 0h30m28s  (62.9%)14.6%  lr: 0.018388  loss: 0.001589  eta: 0h18m  tot: 0h30m29s  (62.9%)14.8%  lr: 0.018378  loss: 0.001588  eta: 0h18m  tot: 0h30m29s  (63.0%)14.9%  lr: 0.018358  loss: 0.001588  eta: 0h18m  tot: 0h30m30s  (63.0%)15.1%  lr: 0.018358  loss: 0.001591  eta: 0h18m  tot: 0h30m31s  (63.0%)15.1%  lr: 0.018348  loss: 0.001590  eta: 0h18m  tot: 0h30m32s  (63.0%)16.1%  lr: 0.018228  loss: 0.001595  eta: 0h18m  tot: 0h30m38s  (63.2%)16.6%  lr: 0.018208  loss: 0.001586  eta: 0h18m  tot: 0h30m40s  (63.3%)16.8%  lr: 0.018178  loss: 0.001586  eta: 0h18m  tot: 0h30m41s  (63.4%)17.0%  lr: 0.018158  loss: 0.001589  eta: 0h18m  tot: 0h30m43s  (63.4%)17.4%  lr: 0.018148  loss: 0.001592  eta: 0h18m  tot: 0h30m45s  (63.5%)17.7%  lr: 0.018118  loss: 0.001585  eta: 0h18m  tot: 0h30m47s  (63.5%)17.9%  lr: 0.018078  loss: 0.001579  eta: 0h18m  tot: 0h30m48s  (63.6%)18.0%  lr: 0.018078  loss: 0.001576  eta: 0h18m  tot: 0h30m48s  (63.6%)18.2%  lr: 0.018048  loss: 0.001581  eta: 0h18m  tot: 0h30m49s  (63.6%)18.4%  lr: 0.018038  loss: 0.001579  eta: 0h18m  tot: 0h30m51s  (63.7%)18.9%  lr: 0.017968  loss: 0.001574  eta: 0h18m  tot: 0h30m54s  (63.8%)19.0%  lr: 0.017938  loss: 0.001576  eta: 0h18m  tot: 0h30m55s  (63.8%)19.3%  lr: 0.017888  loss: 0.001583  eta: 0h18m  tot: 0h30m56s  (63.9%)19.4%  lr: 0.017878  loss: 0.001583  eta: 0h18m  tot: 0h30m56s  (63.9%)19.8%  lr: 0.017828  loss: 0.001582  eta: 0h17m  tot: 0h30m59s  (64.0%)19.9%  lr: 0.017798  loss: 0.001581  eta: 0h17m  tot: 0h31m0s  (64.0%)20.2%  lr: 0.017778  loss: 0.001581  eta: 0h17m  tot: 0h31m1s  (64.0%)20.4%  lr: 0.017748  loss: 0.001575  eta: 0h17m  tot: 0h31m3s  (64.1%)20.5%  lr: 0.017748  loss: 0.001577  eta: 0h17m  tot: 0h31m3s  (64.1%)20.7%  lr: 0.017718  loss: 0.001572  eta: 0h17m  tot: 0h31m5s  (64.1%)20.8%  lr: 0.017718  loss: 0.001575  eta: 0h17m  tot: 0h31m5s  (64.2%)20.9%  lr: 0.017708  loss: 0.001575  eta: 0h17m  tot: 0h31m6s  (64.2%)21.0%  lr: 0.017698  loss: 0.001573  eta: 0h17m  tot: 0h31m6s  (64.2%)21.1%  lr: 0.017698  loss: 0.001573  eta: 0h17m  tot: 0h31m6s  (64.2%)21.2%  lr: 0.017688  loss: 0.001569  eta: 0h17m  tot: 0h31m7s  (64.2%)21.3%  lr: 0.017688  loss: 0.001567  eta: 0h17m  tot: 0h31m8s  (64.3%)21.6%  lr: 0.017678  loss: 0.001565  eta: 0h17m  tot: 0h31m10s  (64.3%)21.7%  lr: 0.017678  loss: 0.001562  eta: 0h17m  tot: 0h31m10s  (64.3%)21.9%  lr: 0.017668  loss: 0.001560  eta: 0h17m  tot: 0h31m12s  (64.4%)22.5%  lr: 0.017648  loss: 0.001570  eta: 0h17m  tot: 0h31m15s  (64.5%)22.8%  lr: 0.017638  loss: 0.001570  eta: 0h17m  tot: 0h31m17s  (64.6%)23.1%  lr: 0.017608  loss: 0.001569  eta: 0h17m  tot: 0h31m19s  (64.6%)  loss: 0.001571  eta: 0h17m  tot: 0h31m19s  (64.6%)  lr: 0.017608  loss: 0.001570  eta: 0h17m  tot: 0h31m20s  (64.6%)23.2%  lr: 0.017598  loss: 0.001570  eta: 0h17m  tot: 0h31m20s  (64.6%)23.2%  lr: 0.017598  loss: 0.001570  eta: 0h17m  tot: 0h31m20s  (64.6%)23.4%  lr: 0.017588  loss: 0.001569  eta: 0h17m  tot: 0h31m21s  (64.7%)23.5%  lr: 0.017548  loss: 0.001572  eta: 0h17m  tot: 0h31m22s  (64.7%)23.6%  lr: 0.017538  loss: 0.001570  eta: 0h17m  tot: 0h31m22s  (64.7%)23.6%  lr: 0.017538  loss: 0.001569  eta: 0h17m  tot: 0h31m23s  (64.7%)23.8%  lr: 0.017488  loss: 0.001567  eta: 0h17m  tot: 0h31m24s  (64.8%)24.1%  lr: 0.017457  loss: 0.001572  eta: 0h17m  tot: 0h31m25s  (64.8%)24.4%  lr: 0.017447  loss: 0.001574  eta: 0h17m  tot: 0h31m27s  (64.9%)24.9%  lr: 0.017397  loss: 0.001575  eta: 0h17m  tot: 0h31m30s  (65.0%)24.9%  lr: 0.017397  loss: 0.001576  eta: 0h17m  tot: 0h31m30s  (65.0%)25.4%  lr: 0.017357  loss: 0.001577  eta: 0h17m  tot: 0h31m33s  (65.1%)25.6%  lr: 0.017307  loss: 0.001579  eta: 0h17m  tot: 0h31m34s  (65.1%)25.7%  lr: 0.017297  loss: 0.001578  eta: 0h17m  tot: 0h31m35s  (65.1%)26.0%  lr: 0.017267  loss: 0.001580  eta: 0h17m  tot: 0h31m37s  (65.2%)26.2%  lr: 0.017217  loss: 0.001583  eta: 0h17m  tot: 0h31m38s  (65.2%)26.2%  lr: 0.017217  loss: 0.001582  eta: 0h17m  tot: 0h31m38s  (65.2%)26.3%  lr: 0.017217  loss: 0.001582  eta: 0h17m  tot: 0h31m38s  (65.3%)26.4%  lr: 0.017207  loss: 0.001581  eta: 0h17m  tot: 0h31m39s  (65.3%)Epoch: 59.2%  lr: 0.013654  loss: 0.001556  eta: 0h14m  tot: 0h34m55s  (71.8%)26.5%  lr: 0.017197  loss: 0.001580  eta: 0h17m  tot: 0h31m39s  (65.3%)26.5%  lr: 0.017177  loss: 0.001581  eta: 0h17m  tot: 0h31m40s  (65.3%)26.6%  lr: 0.017177  loss: 0.001579  eta: 0h17m  tot: 0h31m40s  (65.3%)27.3%  lr: 0.017127  loss: 0.001578  eta: 0h17m  tot: 0h31m45s  (65.5%)27.4%  lr: 0.017107  loss: 0.001577  eta: 0h17m  tot: 0h31m45s  (65.5%)27.6%  lr: 0.017097  loss: 0.001577  eta: 0h17m  tot: 0h31m46s  (65.5%)28.1%  lr: 0.017027  loss: 0.001569  eta: 0h17m  tot: 0h31m49s  (65.6%)28.6%  lr: 0.016987  loss: 0.001566  eta: 0h17m  tot: 0h31m52s  (65.7%)29.0%  lr: 0.016907  loss: 0.001563  eta: 0h17m  tot: 0h31m55s  (65.8%)29.2%  lr: 0.016897  loss: 0.001563  eta: 0h17m  tot: 0h31m56s  (65.8%)29.6%  lr: 0.016827  loss: 0.001565  eta: 0h17m  tot: 0h31m58s  (65.9%)30.2%  lr: 0.016787  loss: 0.001563  eta: 0h16m  tot: 0h32m2s  (66.0%)30.4%  lr: 0.016787  loss: 0.001562  eta: 0h16m  tot: 0h32m3s  (66.1%)30.5%  lr: 0.016767  loss: 0.001559  eta: 0h16m  tot: 0h32m3s  (66.1%)30.5%  lr: 0.016737  loss: 0.001560  eta: 0h16m  tot: 0h32m4s  (66.1%)30.7%  lr: 0.016737  loss: 0.001561  eta: 0h16m  tot: 0h32m5s  (66.1%)30.8%  lr: 0.016717  loss: 0.001561  eta: 0h16m  tot: 0h32m5s  (66.2%)31.2%  lr: 0.016677  loss: 0.001562  eta: 0h16m  tot: 0h32m8s  (66.2%)31.4%  lr: 0.016637  loss: 0.001564  eta: 0h16m  tot: 0h32m9s  (66.3%)31.5%  lr: 0.016627  loss: 0.001564  eta: 0h16m  tot: 0h32m10s  (66.3%)31.7%  lr: 0.016607  loss: 0.001563  eta: 0h16m  tot: 0h32m11s  (66.3%)31.8%  lr: 0.016577  loss: 0.001562  eta: 0h16m  tot: 0h32m12s  (66.4%)31.9%  lr: 0.016567  loss: 0.001563  eta: 0h16m  tot: 0h32m12s  (66.4%)32.1%  lr: 0.016557  loss: 0.001561  eta: 0h16m  tot: 0h32m13s  (66.4%)32.7%  lr: 0.016517  loss: 0.001560  eta: 0h16m  tot: 0h32m17s  (66.5%)32.9%  lr: 0.016477  loss: 0.001558  eta: 0h16m  tot: 0h32m18s  (66.6%)33.1%  lr: 0.016457  loss: 0.001559  eta: 0h16m  tot: 0h32m19s  (66.6%)%  lr: 0.016457  loss: 0.001560  eta: 0h16m  tot: 0h32m19s  (66.6%)33.3%  lr: 0.016436  loss: 0.001564  eta: 0h16m  tot: 0h32m21s  (66.7%)33.4%  lr: 0.016436  loss: 0.001562  eta: 0h16m  tot: 0h32m21s  (66.7%)33.5%  lr: 0.016426  loss: 0.001563  eta: 0h16m  tot: 0h32m22s  (66.7%)33.6%  lr: 0.016426  loss: 0.001564  eta: 0h16m  tot: 0h32m22s  (66.7%)%  lr: 0.016406  loss: 0.001563  eta: 0h16m  tot: 0h32m24s  (66.8%)34.1%  lr: 0.016366  loss: 0.001562  eta: 0h16m  tot: 0h32m25s  (66.8%)34.7%  lr: 0.016276  loss: 0.001565  eta: 0h16m  tot: 0h32m29s  (66.9%)34.8%  lr: 0.016266  loss: 0.001564  eta: 0h16m  tot: 0h32m30s  (67.0%)35.1%  lr: 0.016256  loss: 0.001567  eta: 0h16m  tot: 0h32m31s  (67.0%)35.2%  lr: 0.016256  loss: 0.001569  eta: 0h16m  tot: 0h32m32s  (67.0%)35.4%  lr: 0.016246  loss: 0.001570  eta: 0h16m  tot: 0h32m33s  (67.1%)35.4%  lr: 0.016236  loss: 0.001569  eta: 0h16m  tot: 0h32m33s  (67.1%)35.6%  lr: 0.016216  loss: 0.001570  eta: 0h16m  tot: 0h32m34s  (67.1%)35.6%  lr: 0.016206  loss: 0.001572  eta: 0h16m  tot: 0h32m35s  (67.1%)36.1%  lr: 0.016166  loss: 0.001568  eta: 0h16m  tot: 0h32m37s  (67.2%)36.2%  lr: 0.016156  loss: 0.001568  eta: 0h16m  tot: 0h32m38s  (67.2%)36.5%  lr: 0.016156  loss: 0.001568  eta: 0h16m  tot: 0h32m40s  (67.3%)37.6%  lr: 0.016016  loss: 0.001569  eta: 0h16m  tot: 0h32m46s  (67.5%)38.6%  lr: 0.015896  loss: 0.001571  eta: 0h16m  tot: 0h32m51s  (67.7%)38.8%  lr: 0.015846  loss: 0.001570  eta: 0h16m  tot: 0h32m52s  (67.8%)39.3%  lr: 0.015826  loss: 0.001567  eta: 0h15m  tot: 0h32m55s  (67.9%)39.5%  lr: 0.015786  loss: 0.001565  eta: 0h15m  tot: 0h32m56s  (67.9%)39.7%  lr: 0.015776  loss: 0.001566  eta: 0h15m  tot: 0h32m57s  (67.9%)40.3%  lr: 0.015736  loss: 0.001566  eta: 0h15m  tot: 0h33m1s  (68.1%)40.9%  lr: 0.015646  loss: 0.001568  eta: 0h15m  tot: 0h33m5s  (68.2%)41.4%  lr: 0.015556  loss: 0.001564  eta: 0h15m  tot: 0h33m8s  (68.3%)41.6%  lr: 0.015536  loss: 0.001563  eta: 0h15m  tot: 0h33m9s  (68.3%)41.7%  lr: 0.015506  loss: 0.001561  eta: 0h15m  tot: 0h33m9s  (68.3%)42.9%  lr: 0.015425  loss: 0.001565  eta: 0h15m  tot: 0h33m16s  (68.6%)43.0%  lr: 0.015415  loss: 0.001563  eta: 0h15m  tot: 0h33m17s  (68.6%)43.1%  lr: 0.015405  loss: 0.001564  eta: 0h15m  tot: 0h33m18s  (68.6%)43.2%  lr: 0.015405  loss: 0.001563  eta: 0h15m  tot: 0h33m18s  (68.6%)43.5%  lr: 0.015365  loss: 0.001562  eta: 0h15m  tot: 0h33m20s  (68.7%)43.8%  lr: 0.015345  loss: 0.001561  eta: 0h15m  tot: 0h33m22s  (68.8%)44.4%  lr: 0.015275  loss: 0.001557  eta: 0h15m  tot: 0h33m26s  (68.9%)45.0%  lr: 0.015225  loss: 0.001555  eta: 0h15m  tot: 0h33m30s  (69.0%)45.2%  lr: 0.015205  loss: 0.001554  eta: 0h15m  tot: 0h33m30s  (69.0%)45.4%  lr: 0.015155  loss: 0.001552  eta: 0h15m  tot: 0h33m32s  (69.1%)45.5%  lr: 0.015135  loss: 0.001552  eta: 0h15m  tot: 0h33m32s  (69.1%)45.8%  lr: 0.015115  loss: 0.001552  eta: 0h15m  tot: 0h33m34s  (69.2%)%  lr: 0.015095  loss: 0.001551  eta: 0h15m  tot: 0h33m34s  (69.2%)46.1%  lr: 0.015075  loss: 0.001551  eta: 0h15m  tot: 0h33m36s  (69.2%)46.3%  lr: 0.015015  loss: 0.001550  eta: 0h15m  tot: 0h33m37s  (69.3%)46.5%  lr: 0.014975  loss: 0.001553  eta: 0h15m  tot: 0h33m39s  (69.3%)46.7%  lr: 0.014935  loss: 0.001555  eta: 0h15m  tot: 0h33m40s  (69.3%)46.8%  lr: 0.014925  loss: 0.001556  eta: 0h15m  tot: 0h33m40s  (69.4%)46.8%  lr: 0.014925  loss: 0.001556  eta: 0h15m  tot: 0h33m41s  (69.4%)46.9%  lr: 0.014925  loss: 0.001556  eta: 0h15m  tot: 0h33m41s  (69.4%)%  lr: 0.014925  loss: 0.001557  eta: 0h15m  tot: 0h33m42s  (69.4%)47.2%  lr: 0.014915  loss: 0.001557  eta: 0h15m  tot: 0h33m43s  (69.4%)48.0%  lr: 0.014795  loss: 0.001557  eta: 0h15m  tot: 0h33m48s  (69.6%)48.2%  lr: 0.014785  loss: 0.001558  eta: 0h15m  tot: 0h33m49s  (69.6%)48.7%  lr: 0.014705  loss: 0.001558  eta: 0h15m  tot: 0h33m52s  (69.7%)48.9%  lr: 0.014685  loss: 0.001557  eta: 0h15m  tot: 0h33m54s  (69.8%)49.1%  lr: 0.014685  loss: 0.001556  eta: 0h15m  tot: 0h33m54s  (69.8%)49.3%  lr: 0.014685  loss: 0.001556  eta: 0h15m  tot: 0h33m56s  (69.9%)49.6%  lr: 0.014685  loss: 0.001559  eta: 0h15m  tot: 0h33m57s  (69.9%)50.0%  lr: 0.014665  loss: 0.001555  eta: 0h14m  tot: 0h34m0s  (70.0%)50.7%  lr: 0.014525  loss: 0.001555  eta: 0h14m  tot: 0h34m4s  (70.1%)50.9%  lr: 0.014485  loss: 0.001555  eta: 0h14m  tot: 0h34m5s  (70.2%)51.3%  lr: 0.014475  loss: 0.001555  eta: 0h14m  tot: 0h34m8s  (70.3%)51.7%  lr: 0.014435  loss: 0.001555  eta: 0h14m  tot: 0h34m10s  (70.3%)51.8%  lr: 0.014435  loss: 0.001554  eta: 0h14m  tot: 0h34m11s  (70.4%)51.9%  lr: 0.014435  loss: 0.001553  eta: 0h14m  tot: 0h34m11s  (70.4%)52.4%  lr: 0.014374  loss: 0.001552  eta: 0h14m  tot: 0h34m14s  (70.5%)52.4%  lr: 0.014354  loss: 0.001551  eta: 0h14m  tot: 0h34m15s  (70.5%)52.5%  lr: 0.014324  loss: 0.001553  eta: 0h14m  tot: 0h34m15s  (70.5%)52.8%  lr: 0.014294  loss: 0.001554  eta: 0h14m  tot: 0h34m17s  (70.6%)53.7%  lr: 0.014194  loss: 0.001554  eta: 0h14m  tot: 0h34m22s  (70.7%)54.6%  lr: 0.014064  loss: 0.001556  eta: 0h14m  tot: 0h34m28s  (70.9%)54.6%  lr: 0.014064  loss: 0.001557  eta: 0h14m  tot: 0h34m28s  (70.9%)54.9%  lr: 0.014054  loss: 0.001557  eta: 0h14m  tot: 0h34m29s  (71.0%)55.2%  lr: 0.014044  loss: 0.001557  eta: 0h14m  tot: 0h34m31s  (71.0%)55.5%  lr: 0.014044  loss: 0.001556  eta: 0h14m  tot: 0h34m33s  (71.1%)55.6%  lr: 0.014044  loss: 0.001555  eta: 0h14m  tot: 0h34m34s  (71.1%)56.0%  lr: 0.014034  loss: 0.001554  eta: 0h14m  tot: 0h34m36s  (71.2%)56.1%  lr: 0.014024  loss: 0.001553  eta: 0h14m  tot: 0h34m37s  (71.2%)56.4%  lr: 0.013974  loss: 0.001555  eta: 0h14m  tot: 0h34m39s  (71.3%)56.6%  lr: 0.013964  loss: 0.001554  eta: 0h14m  tot: 0h34m40s  (71.3%)57.0%  lr: 0.013944  loss: 0.001555  eta: 0h14m  tot: 0h34m42s  (71.4%)%  lr: 0.013934  loss: 0.001555  eta: 0h14m  tot: 0h34m43s  (71.4%)57.6%  lr: 0.013874  loss: 0.001554  eta: 0h14m  tot: 0h34m46s  (71.5%)57.9%  lr: 0.013844  loss: 0.001553  eta: 0h14m  tot: 0h34m48s  (71.6%)58.0%  lr: 0.013824  loss: 0.001554  eta: 0h14m  tot: 0h34m48s  (71.6%)58.4%  lr: 0.013754  loss: 0.001554  eta: 0h14m  tot: 0h34m50s  (71.7%)58.9%  lr: 0.013674  loss: 0.001556  eta: 0h14m  tot: 0h34m53s  (71.8%)59.2%  lr: 0.013654  loss: 0.001556  eta: 0h14m  tot: 0h34m55s  (71.8%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 90.1%  lr: 0.010711  loss: 0.001574  eta: 0h10m  tot: 0h37m59s  (78.0%)59.3%  lr: 0.013654  loss: 0.001556  eta: 0h14m  tot: 0h34m56s  (71.9%)59.6%  lr: 0.013654  loss: 0.001556  eta: 0h14m  tot: 0h34m57s  (71.9%)59.8%  lr: 0.013654  loss: 0.001555  eta: 0h13m  tot: 0h34m58s  (72.0%)60.1%  lr: 0.013624  loss: 0.001555  eta: 0h13m  tot: 0h35m0s  (72.0%)60.1%  lr: 0.013614  loss: 0.001555  eta: 0h13m  tot: 0h35m1s  (72.0%)60.3%  lr: 0.013604  loss: 0.001554  eta: 0h13m  tot: 0h35m2s  (72.1%)60.4%  lr: 0.013604  loss: 0.001556  eta: 0h13m  tot: 0h35m2s  (72.1%)60.7%  lr: 0.013574  loss: 0.001555  eta: 0h13m  tot: 0h35m4s  (72.1%)61.0%  lr: 0.013524  loss: 0.001555  eta: 0h13m  tot: 0h35m6s  (72.2%)61.1%  lr: 0.013524  loss: 0.001555  eta: 0h13m  tot: 0h35m6s  (72.2%)61.4%  lr: 0.013504  loss: 0.001555  eta: 0h13m  tot: 0h35m8s  (72.3%)61.5%  lr: 0.013504  loss: 0.001555  eta: 0h13m  tot: 0h35m9s  (72.3%)62.0%  lr: 0.013464  loss: 0.001553  eta: 0h13m  tot: 0h35m12s  (72.4%)62.5%  lr: 0.013444  loss: 0.001553  eta: 0h13m  tot: 0h35m15s  (72.5%)62.8%  lr: 0.013363  loss: 0.001552  eta: 0h13m  tot: 0h35m17s  (72.6%)62.9%  lr: 0.013363  loss: 0.001552  eta: 0h13m  tot: 0h35m17s  (72.6%)63.2%  lr: 0.013333  loss: 0.001553  eta: 0h13m  tot: 0h35m19s  (72.6%)63.3%  lr: 0.013323  loss: 0.001552  eta: 0h13m  tot: 0h35m20s  (72.7%)63.3%  lr: 0.013323  loss: 0.001552  eta: 0h13m  tot: 0h35m20s  (72.7%)63.4%  lr: 0.013323  loss: 0.001553  eta: 0h13m  tot: 0h35m20s  (72.7%)63.5%  lr: 0.013313  loss: 0.001553  eta: 0h13m  tot: 0h35m21s  (72.7%)64.0%  lr: 0.013253  loss: 0.001554  eta: 0h13m  tot: 0h35m24s  (72.8%)64.1%  lr: 0.013253  loss: 0.001554  eta: 0h13m  tot: 0h35m24s  (72.8%)64.1%  lr: 0.013243  loss: 0.001554  eta: 0h13m  tot: 0h35m25s  (72.8%)64.2%  lr: 0.013223  loss: 0.001554  eta: 0h13m  tot: 0h35m25s  (72.8%)64.9%  lr: 0.013113  loss: 0.001559  eta: 0h13m  tot: 0h35m29s  (73.0%)65.0%  lr: 0.013113  loss: 0.001559  eta: 0h13m  tot: 0h35m30s  (73.0%)65.3%  lr: 0.013093  loss: 0.001561  eta: 0h13m  tot: 0h35m32s  (73.1%)65.5%  lr: 0.013093  loss: 0.001560  eta: 0h13m  tot: 0h35m33s  (73.1%)65.8%  lr: 0.013083  loss: 0.001561  eta: 0h13m  tot: 0h35m34s  (73.2%)66.1%  lr: 0.013063  loss: 0.001562  eta: 0h13m  tot: 0h35m36s  (73.2%)66.3%  lr: 0.013063  loss: 0.001562  eta: 0h13m  tot: 0h35m38s  (73.3%)66.5%  lr: 0.013003  loss: 0.001562  eta: 0h13m  tot: 0h35m39s  (73.3%)66.7%  lr: 0.012983  loss: 0.001564  eta: 0h13m  tot: 0h35m40s  (73.3%)66.9%  lr: 0.012983  loss: 0.001565  eta: 0h13m  tot: 0h35m41s  (73.4%)67.0%  lr: 0.012973  loss: 0.001564  eta: 0h13m  tot: 0h35m42s  (73.4%)67.4%  lr: 0.012963  loss: 0.001568  eta: 0h13m  tot: 0h35m45s  (73.5%)67.6%  lr: 0.012943  loss: 0.001569  eta: 0h13m  tot: 0h35m46s  (73.5%)67.7%  lr: 0.012943  loss: 0.001568  eta: 0h13m  tot: 0h35m47s  (73.5%)68.2%  lr: 0.012913  loss: 0.001569  eta: 0h13m  tot: 0h35m49s  (73.6%)68.5%  lr: 0.012903  loss: 0.001568  eta: 0h13m  tot: 0h35m51s  (73.7%)%  lr: 0.012883  loss: 0.001570  eta: 0h13m  tot: 0h35m52s  (73.7%)69.0%  lr: 0.012843  loss: 0.001569  eta: 0h13m  tot: 0h35m54s  (73.8%)69.3%  lr: 0.012823  loss: 0.001569  eta: 0h13m  tot: 0h35m56s  (73.9%)69.4%  lr: 0.012803  loss: 0.001569  eta: 0h13m  tot: 0h35m57s  (73.9%)70.2%  lr: 0.012723  loss: 0.001566  eta: 0h12m  tot: 0h36m2s  (74.0%)70.3%  lr: 0.012723  loss: 0.001566  eta: 0h12m  tot: 0h36m2s  (74.1%)71.1%  lr: 0.012653  loss: 0.001567  eta: 0h12m  tot: 0h36m7s  (74.2%)71.2%  lr: 0.012653  loss: 0.001567  eta: 0h12m  tot: 0h36m7s  (74.2%)71.8%  lr: 0.012613  loss: 0.001565  eta: 0h12m  tot: 0h36m11s  (74.4%)71.9%  lr: 0.012603  loss: 0.001565  eta: 0h12m  tot: 0h36m11s  (74.4%)72.4%  lr: 0.012543  loss: 0.001566  eta: 0h12m  tot: 0h36m14s  (74.5%)72.6%  lr: 0.012543  loss: 0.001566  eta: 0h12m  tot: 0h36m15s  (74.5%)%  lr: 0.012403  loss: 0.001567  eta: 0h12m  tot: 0h36m22s  (74.8%)74.3%  lr: 0.012342  loss: 0.001563  eta: 0h12m  tot: 0h36m25s  (74.9%)74.8%  lr: 0.012272  loss: 0.001563  eta: 0h12m  tot: 0h36m28s  (75.0%)75.0%  lr: 0.012232  loss: 0.001565  eta: 0h12m  tot: 0h36m29s  (75.0%)75.6%  lr: 0.012192  loss: 0.001564  eta: 0h12m  tot: 0h36m33s  (75.1%)75.7%  lr: 0.012182  loss: 0.001564  eta: 0h12m  tot: 0h36m34s  (75.1%)75.7%  lr: 0.012162  loss: 0.001565  eta: 0h12m  tot: 0h36m34s  (75.1%)75.9%  lr: 0.012112  loss: 0.001565  eta: 0h12m  tot: 0h36m35s  (75.2%)76.8%  lr: 0.011992  loss: 0.001567  eta: 0h12m  tot: 0h36m41s  (75.4%)%  lr: 0.011962  loss: 0.001566  eta: 0h12m  tot: 0h36m42s  (75.4%)77.2%  lr: 0.011952  loss: 0.001567  eta: 0h12m  tot: 0h36m43s  (75.4%)77.8%  lr: 0.011912  loss: 0.001568  eta: 0h12m  tot: 0h36m46s  (75.6%)78.1%  lr: 0.011882  loss: 0.001567  eta: 0h12m  tot: 0h36m48s  (75.6%)  lr: 0.011822  loss: 0.001567  eta: 0h12m  tot: 0h36m50s  (75.7%)78.8%  lr: 0.011772  loss: 0.001568  eta: 0h12m  tot: 0h36m52s  (75.8%)78.9%  lr: 0.011742  loss: 0.001567  eta: 0h12m  tot: 0h36m52s  (75.8%)79.0%  lr: 0.011702  loss: 0.001568  eta: 0h12m  tot: 0h36m53s  (75.8%)79.2%  lr: 0.011702  loss: 0.001568  eta: 0h12m  tot: 0h36m54s  (75.8%)79.7%  lr: 0.011652  loss: 0.001569  eta: 0h11m  tot: 0h36m58s  (75.9%)79.8%  lr: 0.011652  loss: 0.001568  eta: 0h11m  tot: 0h36m58s  (76.0%)79.9%  lr: 0.011642  loss: 0.001568  eta: 0h11m  tot: 0h36m59s  (76.0%)80.5%  lr: 0.011582  loss: 0.001568  eta: 0h11m  tot: 0h37m2s  (76.1%)80.6%  lr: 0.011582  loss: 0.001568  eta: 0h11m  tot: 0h37m3s  (76.1%)80.9%  lr: 0.011572  loss: 0.001567  eta: 0h11m  tot: 0h37m4s  (76.2%)81.2%  lr: 0.011532  loss: 0.001567  eta: 0h11m  tot: 0h37m6s  (76.2%)81.4%  lr: 0.011512  loss: 0.001566  eta: 0h11m  tot: 0h37m8s  (76.3%)81.9%  lr: 0.011472  loss: 0.001565  eta: 0h11m  tot: 0h37m11s  (76.4%)82.6%  lr: 0.011412  loss: 0.001564  eta: 0h11m  tot: 0h37m15s  (76.5%)82.8%  lr: 0.011402  loss: 0.001564  eta: 0h11m  tot: 0h37m16s  (76.6%)83.0%  lr: 0.011382  loss: 0.001567  eta: 0h11m  tot: 0h37m17s  (76.6%)83.2%  lr: 0.011361  loss: 0.001567  eta: 0h11m  tot: 0h37m18s  (76.6%)83.4%  lr: 0.011341  loss: 0.001568  eta: 0h11m  tot: 0h37m20s  (76.7%)83.9%  lr: 0.011271  loss: 0.001569  eta: 0h11m  tot: 0h37m22s  (76.8%)84.1%  lr: 0.011231  loss: 0.001570  eta: 0h11m  tot: 0h37m24s  (76.8%)84.8%  lr: 0.011171  loss: 0.001573  eta: 0h11m  tot: 0h37m27s  (77.0%)84.9%  lr: 0.011161  loss: 0.001572  eta: 0h11m  tot: 0h37m28s  (77.0%)85.1%  lr: 0.011151  loss: 0.001574  eta: 0h11m  tot: 0h37m29s  (77.0%)85.2%  lr: 0.011131  loss: 0.001573  eta: 0h11m  tot: 0h37m30s  (77.0%)85.3%  lr: 0.011131  loss: 0.001573  eta: 0h11m  tot: 0h37m30s  (77.1%)85.5%  lr: 0.011121  loss: 0.001575  eta: 0h11m  tot: 0h37m32s  (77.1%)85.6%  lr: 0.011121  loss: 0.001575  eta: 0h11m  tot: 0h37m32s  (77.1%)85.6%  lr: 0.011121  loss: 0.001575  eta: 0h11m  tot: 0h37m33s  (77.1%)86.1%  lr: 0.011091  loss: 0.001573  eta: 0h11m  tot: 0h37m35s  (77.2%)86.2%  lr: 0.011061  loss: 0.001573  eta: 0h11m  tot: 0h37m36s  (77.2%)86.5%  lr: 0.011031  loss: 0.001573  eta: 0h11m  tot: 0h37m37s  (77.3%)86.6%  lr: 0.011011  loss: 0.001573  eta: 0h11m  tot: 0h37m38s  (77.3%)86.8%  lr: 0.011001  loss: 0.001572  eta: 0h11m  tot: 0h37m39s  (77.4%)87.1%  lr: 0.010991  loss: 0.001572  eta: 0h11m  tot: 0h37m41s  (77.4%)87.3%  lr: 0.010951  loss: 0.001572  eta: 0h11m  tot: 0h37m42s  (77.5%)87.8%  lr: 0.010941  loss: 0.001572  eta: 0h11m  tot: 0h37m45s  (77.6%)88.0%  lr: 0.010941  loss: 0.001573  eta: 0h11m  tot: 0h37m46s  (77.6%)88.0%  lr: 0.010931  loss: 0.001573  eta: 0h11m  tot: 0h37m47s  (77.6%)88.1%  lr: 0.010931  loss: 0.001573  eta: 0h11m  tot: 0h37m47s  (77.6%)88.2%  lr: 0.010921  loss: 0.001573  eta: 0h11m  tot: 0h37m48s  (77.6%)88.7%  lr: 0.010851  loss: 0.001573  eta: 0h11m  tot: 0h37m51s  (77.7%)88.9%  lr: 0.010831  loss: 0.001573  eta: 0h11m  tot: 0h37m52s  (77.8%)89.0%  lr: 0.010821  loss: 0.001573  eta: 0h11m  tot: 0h37m53s  (77.8%)89.2%  lr: 0.010791  loss: 0.001572  eta: 0h11m  tot: 0h37m54s  (77.8%)89.3%  lr: 0.010781  loss: 0.001571  eta: 0h11m  tot: 0h37m54s  (77.9%)89.7%  lr: 0.010751  loss: 0.001572  eta: 0h10m  tot: 0h37m57s  (77.9%)89.9%  lr: 0.010741  loss: 0.001574  eta: 0h10m  tot: 0h37m58s  (78.0%)90.1%  lr: 0.010711  loss: 0.001574  eta: 0h10m  tot: 0h37m59s  (78.0%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100.0%  lr: 0.010000  loss: 0.001574  eta: 0h9m  tot: 0h38m49s  (80.0%)0.7%  lr: 0.010681  loss: 0.001574  eta: 0h10m  tot: 0h38m3s  (78.1%)90.8%  lr: 0.010661  loss: 0.001574  eta: 0h10m  tot: 0h38m4s  (78.2%)91.0%  lr: 0.010641  loss: 0.001574  eta: 0h10m  tot: 0h38m5s  (78.2%)91.0%  lr: 0.010641  loss: 0.001574  eta: 0h10m  tot: 0h38m5s  (78.2%)91.2%  lr: 0.010621  loss: 0.001574  eta: 0h10m  tot: 0h38m6s  (78.2%)91.8%  lr: 0.010591  loss: 0.001576  eta: 0h10m  tot: 0h38m10s  (78.4%)92.0%  lr: 0.010561  loss: 0.001576  eta: 0h10m  tot: 0h38m11s  (78.4%)92.1%  lr: 0.010561  loss: 0.001576  eta: 0h10m  tot: 0h38m11s  (78.4%)92.7%  lr: 0.010511  loss: 0.001574  eta: 0h10m  tot: 0h38m15s  (78.5%)92.8%  lr: 0.010511  loss: 0.001574  eta: 0h10m  tot: 0h38m15s  (78.6%)92.9%  lr: 0.010481  loss: 0.001573  eta: 0h10m  tot: 0h38m16s  (78.6%)93.0%  lr: 0.010481  loss: 0.001573  eta: 0h10m  tot: 0h38m16s  (78.6%)93.4%  lr: 0.010461  loss: 0.001574  eta: 0h10m  tot: 0h38m19s  (78.7%)94.0%  lr: 0.010431  loss: 0.001574  eta: 0h10m  tot: 0h38m23s  (78.8%)94.0%  lr: 0.010431  loss: 0.001574  eta: 0h10m  tot: 0h38m23s  (78.8%)94.4%  lr: 0.010411  loss: 0.001573  eta: 0h10m  tot: 0h38m25s  (78.9%)94.7%  lr: 0.010350  loss: 0.001572  eta: 0h10m  tot: 0h38m27s  (78.9%)95.1%  lr: 0.010300  loss: 0.001573  eta: 0h10m  tot: 0h38m29s  (79.0%)95.2%  lr: 0.010300  loss: 0.001573  eta: 0h10m  tot: 0h38m30s  (79.0%)95.2%  lr: 0.010290  loss: 0.001573  eta: 0h10m  tot: 0h38m30s  (79.0%)95.2%  lr: 0.010290  loss: 0.001573  eta: 0h10m  tot: 0h38m30s  (79.0%)95.4%  lr: 0.010270  loss: 0.001573  eta: 0h10m  tot: 0h38m31s  (79.1%)95.5%  lr: 0.010270  loss: 0.001573  eta: 0h10m  tot: 0h38m31s  (79.1%)95.5%  lr: 0.010260  loss: 0.001573  eta: 0h10m  tot: 0h38m32s  (79.1%)95.7%  lr: 0.010260  loss: 0.001573  eta: 0h10m  tot: 0h38m33s  (79.1%)%  lr: 0.010220  loss: 0.001573  eta: 0h10m  tot: 0h38m35s  (79.2%)96.2%  lr: 0.010210  loss: 0.001573  eta: 0h10m  tot: 0h38m36s  (79.2%)97.2%  lr: 0.010140  loss: 0.001575  eta: 0h10m  tot: 0h38m41s  (79.4%)0h10m  tot: 0h38m43s  (79.6%)\n",
      " ---+++                Epoch    3 Train error : 0.00155413 +++--- ���\n",
      "Training epoch 4: 0.01 0.01\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 31.1%  lr: 0.006647  loss: 0.001387  eta: 0h6m  tot: 0h41m52s  (86.2%).3%  lr: 0.009890  loss: 0.001346  eta: 0h9m  tot: 0h38m57s  (80.3%)1.8%  lr: 0.009770  loss: 0.001373  eta: 0h9m  tot: 0h39m0s  (80.4%)80.4%)2.2%  lr: 0.009740  loss: 0.001362  eta: 0h9m  tot: 0h39m1s  (80.4%)3.7%  lr: 0.009580  loss: 0.001331  eta: 0h9m  tot: 0h39m10s  (80.7%)3.9%  lr: 0.009580  loss: 0.001307  eta: 0h9m  tot: 0h39m11s  (80.8%)3.9%  lr: 0.009580  loss: 0.001317  eta: 0h9m  tot: 0h39m12s  (80.8%)4.1%  lr: 0.009570  loss: 0.001306  eta: 0h9m  tot: 0h39m13s  (80.8%)4.1%  lr: 0.009570  loss: 0.001306  eta: 0h9m  tot: 0h39m13s  (80.8%)4.7%  lr: 0.009520  loss: 0.001291  eta: 0h9m  tot: 0h39m16s  (80.9%)4.8%  lr: 0.009500  loss: 0.001302  eta: 0h9m  tot: 0h39m17s  (81.0%)5.1%  lr: 0.009459  loss: 0.001302  eta: 0h9m  tot: 0h39m19s  (81.0%)5.1%  lr: 0.009459  loss: 0.001327  eta: 0h9m  tot: 0h39m19s  (81.0%)5.3%  lr: 0.009449  loss: 0.001325  eta: 0h9m  tot: 0h39m20s  (81.1%)5.9%  lr: 0.009349  loss: 0.001325  eta: 0h9m  tot: 0h39m23s  (81.2%)6.9%  lr: 0.009189  loss: 0.001310  eta: 0h9m  tot: 0h39m29s  (81.4%)7.1%  lr: 0.009169  loss: 0.001310  eta: 0h8m  tot: 0h39m30s  (81.4%)7.2%  lr: 0.009149  loss: 0.001314  eta: 0h8m  tot: 0h39m31s  (81.4%)7.3%  lr: 0.009089  loss: 0.001322  eta: 0h8m  tot: 0h39m32s  (81.5%)7.4%  lr: 0.009079  loss: 0.001324  eta: 0h8m  tot: 0h39m32s  (81.5%)7.5%  lr: 0.009069  loss: 0.001327  eta: 0h8m  tot: 0h39m33s  (81.5%)7.6%  lr: 0.009069  loss: 0.001331  eta: 0h8m  tot: 0h39m33s  (81.5%)8.0%  lr: 0.009049  loss: 0.001344  eta: 0h8m  tot: 0h39m35s  (81.6%)8.3%  lr: 0.008999  loss: 0.001352  eta: 0h8m  tot: 0h39m38s  (81.7%)8.4%  lr: 0.008959  loss: 0.001352  eta: 0h8m  tot: 0h39m38s  (81.7%)8.5%  lr: 0.008959  loss: 0.001354  eta: 0h8m  tot: 0h39m39s  (81.7%)8.6%  lr: 0.008919  loss: 0.001352  eta: 0h8m  tot: 0h39m39s  (81.7%)8.7%  lr: 0.008909  loss: 0.001347  eta: 0h8m  tot: 0h39m40s  (81.7%)9.0%  lr: 0.008869  loss: 0.001355  eta: 0h8m  tot: 0h39m42s  (81.8%)9.2%  lr: 0.008849  loss: 0.001360  eta: 0h8m  tot: 0h39m43s  (81.8%)9.7%  lr: 0.008779  loss: 0.001365  eta: 0h8m  tot: 0h39m46s  (81.9%)9.8%  lr: 0.008779  loss: 0.001367  eta: 0h8m  tot: 0h39m46s  (82.0%)9.8%  lr: 0.008779  loss: 0.001368  eta: 0h8m  tot: 0h39m47s  (82.0%)10.4%  lr: 0.008709  loss: 0.001360  eta: 0h8m  tot: 0h39m50s  (82.1%)10.6%  lr: 0.008689  loss: 0.001366  eta: 0h8m  tot: 0h39m51s  (82.1%)10.7%  lr: 0.008669  loss: 0.001366  eta: 0h8m  tot: 0h39m51s  (82.1%)10.8%  lr: 0.008669  loss: 0.001367  eta: 0h8m  tot: 0h39m52s  (82.2%)11.0%  lr: 0.008639  loss: 0.001375  eta: 0h8m  tot: 0h39m53s  (82.2%)11.3%  lr: 0.008619  loss: 0.001370  eta: 0h8m  tot: 0h39m54s  (82.3%)12.0%  lr: 0.008559  loss: 0.001364  eta: 0h8m  tot: 0h39m58s  (82.4%)12.3%  lr: 0.008499  loss: 0.001359  eta: 0h8m  tot: 0h40m0s  (82.5%)12.4%  lr: 0.008499  loss: 0.001360  eta: 0h8m  tot: 0h40m0s  (82.5%)12.5%  lr: 0.008499  loss: 0.001363  eta: 0h8m  tot: 0h40m1s  (82.5%)12.6%  lr: 0.008499  loss: 0.001363  eta: 0h8m  tot: 0h40m1s  (82.5%)12.8%  lr: 0.008468  loss: 0.001355  eta: 0h8m  tot: 0h40m2s  (82.6%)13.1%  lr: 0.008428  loss: 0.001361  eta: 0h8m  tot: 0h40m4s  (82.6%)13.2%  lr: 0.008398  loss: 0.001359  eta: 0h8m  tot: 0h40m5s  (82.6%)13.4%  lr: 0.008398  loss: 0.001362  eta: 0h8m  tot: 0h40m6s  (82.7%)13.9%  lr: 0.008358  loss: 0.001365  eta: 0h8m  tot: 0h40m9s  (82.8%)14.0%  lr: 0.008358  loss: 0.001363  eta: 0h8m  tot: 0h40m9s  (82.8%)14.4%  lr: 0.008328  loss: 0.001370  eta: 0h8m  tot: 0h40m11s  (82.9%)14.5%  lr: 0.008328  loss: 0.001369  eta: 0h8m  tot: 0h40m12s  (82.9%)15.1%  lr: 0.008238  loss: 0.001376  eta: 0h8m  tot: 0h40m15s  (83.0%)15.5%  lr: 0.008218  loss: 0.001374  eta: 0h8m  tot: 0h40m17s  (83.1%)15.5%  lr: 0.008218  loss: 0.001373  eta: 0h8m  tot: 0h40m18s  (83.1%)15.9%  lr: 0.008158  loss: 0.001375  eta: 0h7m  tot: 0h40m20s  (83.2%)16.1%  lr: 0.008148  loss: 0.001381  eta: 0h7m  tot: 0h40m21s  (83.2%)16.4%  lr: 0.008108  loss: 0.001381  eta: 0h7m  tot: 0h40m23s  (83.3%)16.5%  lr: 0.008088  loss: 0.001379  eta: 0h7m  tot: 0h40m23s  (83.3%)16.9%  lr: 0.008058  loss: 0.001375  eta: 0h7m  tot: 0h40m25s  (83.4%)17.1%  lr: 0.008038  loss: 0.001377  eta: 0h7m  tot: 0h40m27s  (83.4%)17.3%  lr: 0.008018  loss: 0.001379  eta: 0h7m  tot: 0h40m28s  (83.5%)17.6%  lr: 0.008008  loss: 0.001377  eta: 0h7m  tot: 0h40m30s  (83.5%)18.2%  lr: 0.007888  loss: 0.001379  eta: 0h7m  tot: 0h40m34s  (83.6%)18.4%  lr: 0.007868  loss: 0.001377  eta: 0h7m  tot: 0h40m35s  (83.7%)19.2%  lr: 0.007808  loss: 0.001386  eta: 0h7m  tot: 0h40m40s  (83.8%)19.4%  lr: 0.007778  loss: 0.001386  eta: 0h7m  tot: 0h40m42s  (83.9%)19.7%  lr: 0.007768  loss: 0.001387  eta: 0h7m  tot: 0h40m43s  (83.9%)19.9%  lr: 0.007748  loss: 0.001387  eta: 0h7m  tot: 0h40m44s  (84.0%)20.2%  lr: 0.007708  loss: 0.001379  eta: 0h7m  tot: 0h40m46s  (84.0%)%  lr: 0.007658  loss: 0.001384  eta: 0h7m  tot: 0h40m49s  (84.1%)20.9%  lr: 0.007598  loss: 0.001386  eta: 0h7m  tot: 0h40m51s  (84.2%)21.0%  lr: 0.007598  loss: 0.001385  eta: 0h7m  tot: 0h40m51s  (84.2%)21.0%  lr: 0.007588  loss: 0.001385  eta: 0h7m  tot: 0h40m52s  (84.2%)21.2%  lr: 0.007588  loss: 0.001383  eta: 0h7m  tot: 0h40m53s  (84.2%)21.5%  lr: 0.007528  loss: 0.001383  eta: 0h7m  tot: 0h40m55s  (84.3%)21.7%  lr: 0.007518  loss: 0.001386  eta: 0h7m  tot: 0h40m56s  (84.3%)%  lr: 0.007508  loss: 0.001386  eta: 0h7m  tot: 0h40m57s  (84.4%)22.1%  lr: 0.007498  loss: 0.001395  eta: 0h7m  tot: 0h40m58s  (84.4%)22.3%  lr: 0.007468  loss: 0.001396  eta: 0h7m  tot: 0h41m0s  (84.5%)22.5%  lr: 0.007457  loss: 0.001397  eta: 0h7m  tot: 0h41m1s  (84.5%)%  lr: 0.007437  loss: 0.001397  eta: 0h7m  tot: 0h41m1s  (84.5%)%  lr: 0.007417  loss: 0.001403  eta: 0h7m  tot: 0h41m3s  (84.6%)22.9%  lr: 0.007417  loss: 0.001402  eta: 0h7m  tot: 0h41m4s  (84.6%)23.4%  lr: 0.007377  loss: 0.001399  eta: 0h7m  tot: 0h41m7s  (84.7%)23.6%  lr: 0.007337  loss: 0.001395  eta: 0h7m  tot: 0h41m8s  (84.7%)23.9%  lr: 0.007307  loss: 0.001401  eta: 0h7m  tot: 0h41m10s  (84.8%)24.2%  lr: 0.007267  loss: 0.001401  eta: 0h7m  tot: 0h41m11s  (84.8%)24.2%  lr: 0.007257  loss: 0.001400  eta: 0h7m  tot: 0h41m12s  (84.8%)24.3%  lr: 0.007247  loss: 0.001399  eta: 0h7m  tot: 0h41m12s  (84.9%)24.7%  lr: 0.007207  loss: 0.001398  eta: 0h7m  tot: 0h41m14s  (84.9%)25.4%  lr: 0.007137  loss: 0.001393  eta: 0h7m  tot: 0h41m19s  (85.1%)25.6%  lr: 0.007137  loss: 0.001390  eta: 0h7m  tot: 0h41m20s  (85.1%)25.9%  lr: 0.007107  loss: 0.001394  eta: 0h7m  tot: 0h41m21s  (85.2%)26.6%  lr: 0.007037  loss: 0.001391  eta: 0h7m  tot: 0h41m25s  (85.3%)26.8%  lr: 0.006987  loss: 0.001389  eta: 0h7m  tot: 0h41m27s  (85.4%)27.0%  lr: 0.006977  loss: 0.001387  eta: 0h7m  tot: 0h41m28s  (85.4%)27.4%  lr: 0.006907  loss: 0.001385  eta: 0h7m  tot: 0h41m31s  (85.5%)28.2%  lr: 0.006817  loss: 0.001381  eta: 0h7m  tot: 0h41m35s  (85.6%)28.3%  lr: 0.006797  loss: 0.001380  eta: 0h7m  tot: 0h41m36s  (85.7%)28.4%  lr: 0.006787  loss: 0.001381  eta: 0h7m  tot: 0h41m36s  (85.7%)28.4%  lr: 0.006787  loss: 0.001381  eta: 0h7m  tot: 0h41m36s  (85.7%)28.5%  lr: 0.006787  loss: 0.001381  eta: 0h7m  tot: 0h41m37s  (85.7%)29.0%  lr: 0.006767  loss: 0.001381  eta: 0h6m  tot: 0h41m40s  (85.8%)29.2%  lr: 0.006767  loss: 0.001381  eta: 0h6m  tot: 0h41m41s  (85.8%)29.2%  lr: 0.006767  loss: 0.001380  eta: 0h6m  tot: 0h41m41s  (85.8%)29.7%  lr: 0.006727  loss: 0.001386  eta: 0h6m  tot: 0h41m44s  (85.9%)29.8%  lr: 0.006717  loss: 0.001383  eta: 0h6m  tot: 0h41m44s  (86.0%)29.9%  lr: 0.006717  loss: 0.001382  eta: 0h6m  tot: 0h41m45s  (86.0%)29.9%  lr: 0.006697  loss: 0.001381  eta: 0h6m  tot: 0h41m45s  (86.0%)30.3%  lr: 0.006687  loss: 0.001384  eta: 0h6m  tot: 0h41m47s  (86.1%)30.3%  lr: 0.006687  loss: 0.001384  eta: 0h6m  tot: 0h41m48s  (86.1%)30.4%  lr: 0.006687  loss: 0.001386  eta: 0h6m  tot: 0h41m48s  (86.1%)30.6%  lr: 0.006667  loss: 0.001388  eta: 0h6m  tot: 0h41m49s  (86.1%)30.6%  lr: 0.006667  loss: 0.001387  eta: 0h6m  tot: 0h41m49s  (86.1%)30.8%  lr: 0.006667  loss: 0.001389  eta: 0h6m  tot: 0h41m51s  (86.2%)30.9%  lr: 0.006647  loss: 0.001387  eta: 0h6m  tot: 0h41m51s  (86.2%)%  lr: 0.006637  loss: 0.001387  eta: 0h6m  tot: 0h41m52s  (86.2%)Epoch: 58.2%  lr: 0.004164  loss: 0.001388  eta: 0h4m  tot: 0h44m35s  (91.6%)31.2%  lr: 0.006637  loss: 0.001386  eta: 0h6m  tot: 0h41m53s  (86.2%)31.9%  lr: 0.006597  loss: 0.001386  eta: 0h6m  tot: 0h41m57s  (86.4%)31.9%  lr: 0.006587  loss: 0.001387  eta: 0h6m  tot: 0h41m57s  (86.4%)32.0%  lr: 0.006587  loss: 0.001388  eta: 0h6m  tot: 0h41m57s  (86.4%)32.0%  lr: 0.006587  loss: 0.001388  eta: 0h6m  tot: 0h41m58s  (86.4%)32.1%  lr: 0.006587  loss: 0.001389  eta: 0h6m  tot: 0h41m58s  (86.4%)32.3%  lr: 0.006587  loss: 0.001388  eta: 0h6m  tot: 0h42m0s  (86.5%)32.3%  lr: 0.006587  loss: 0.001389  eta: 0h6m  tot: 0h42m0s  (86.5%)32.4%  lr: 0.006587  loss: 0.001389  eta: 0h6m  tot: 0h42m0s  (86.5%)32.8%  lr: 0.006517  loss: 0.001390  eta: 0h6m  tot: 0h42m3s  (86.6%)33.3%  lr: 0.006416  loss: 0.001395  eta: 0h6m  tot: 0h42m6s  (86.7%)33.5%  lr: 0.006386  loss: 0.001393  eta: 0h6m  tot: 0h42m7s  (86.7%)33.7%  lr: 0.006366  loss: 0.001393  eta: 0h6m  tot: 0h42m8s  (86.7%)33.8%  lr: 0.006346  loss: 0.001390  eta: 0h6m  tot: 0h42m9s  (86.8%)34.0%  lr: 0.006326  loss: 0.001391  eta: 0h6m  tot: 0h42m10s  (86.8%)34.3%  lr: 0.006316  loss: 0.001394  eta: 0h6m  tot: 0h42m11s  (86.9%)34.3%  lr: 0.006316  loss: 0.001395  eta: 0h6m  tot: 0h42m12s  (86.9%)34.5%  lr: 0.006306  loss: 0.001392  eta: 0h6m  tot: 0h42m13s  (86.9%)34.6%  lr: 0.006306  loss: 0.001392  eta: 0h6m  tot: 0h42m13s  (86.9%)34.7%  lr: 0.006286  loss: 0.001391  eta: 0h6m  tot: 0h42m14s  (86.9%)35.0%  lr: 0.006256  loss: 0.001394  eta: 0h6m  tot: 0h42m16s  (87.0%)35.4%  lr: 0.006206  loss: 0.001397  eta: 0h6m  tot: 0h42m18s  (87.1%)35.5%  lr: 0.006206  loss: 0.001398  eta: 0h6m  tot: 0h42m19s  (87.1%)35.8%  lr: 0.006206  loss: 0.001402  eta: 0h6m  tot: 0h42m21s  (87.2%)35.9%  lr: 0.006196  loss: 0.001404  eta: 0h6m  tot: 0h42m21s  (87.2%)36.2%  lr: 0.006156  loss: 0.001401  eta: 0h6m  tot: 0h42m23s  (87.2%)36.3%  lr: 0.006146  loss: 0.001403  eta: 0h6m  tot: 0h42m24s  (87.3%)37.2%  lr: 0.006106  loss: 0.001394  eta: 0h6m  tot: 0h42m29s  (87.4%)37.2%  lr: 0.006096  loss: 0.001396  eta: 0h6m  tot: 0h42m29s  (87.4%)37.4%  lr: 0.006076  loss: 0.001396  eta: 0h6m  tot: 0h42m30s  (87.5%)37.4%  lr: 0.006076  loss: 0.001396  eta: 0h6m  tot: 0h42m30s  (87.5%)37.5%  lr: 0.006066  loss: 0.001396  eta: 0h6m  tot: 0h42m31s  (87.5%)37.5%  lr: 0.006056  loss: 0.001396  eta: 0h6m  tot: 0h42m31s  (87.5%)37.8%  lr: 0.006016  loss: 0.001395  eta: 0h6m  tot: 0h42m32s  (87.6%)38.2%  lr: 0.006006  loss: 0.001399  eta: 0h6m  tot: 0h42m35s  (87.6%)38.3%  lr: 0.006006  loss: 0.001399  eta: 0h6m  tot: 0h42m36s  (87.7%)38.5%  lr: 0.005956  loss: 0.001396  eta: 0h6m  tot: 0h42m37s  (87.7%)38.6%  lr: 0.005936  loss: 0.001395  eta: 0h6m  tot: 0h42m37s  (87.7%)38.8%  lr: 0.005926  loss: 0.001396  eta: 0h6m  tot: 0h42m39s  (87.8%)39.0%  lr: 0.005906  loss: 0.001395  eta: 0h6m  tot: 0h42m40s  (87.8%)39.1%  lr: 0.005906  loss: 0.001395  eta: 0h6m  tot: 0h42m40s  (87.8%)39.2%  lr: 0.005896  loss: 0.001396  eta: 0h5m  tot: 0h42m41s  (87.8%)39.3%  lr: 0.005886  loss: 0.001394  eta: 0h5m  tot: 0h42m42s  (87.9%)39.5%  lr: 0.005866  loss: 0.001393  eta: 0h5m  tot: 0h42m42s  (87.9%)40.4%  lr: 0.005766  loss: 0.001389  eta: 0h5m  tot: 0h42m48s  (88.1%)40.6%  lr: 0.005766  loss: 0.001387  eta: 0h5m  tot: 0h42m49s  (88.1%)40.7%  lr: 0.005766  loss: 0.001386  eta: 0h5m  tot: 0h42m50s  (88.1%)40.9%  lr: 0.005766  loss: 0.001386  eta: 0h5m  tot: 0h42m51s  (88.2%)41.1%  lr: 0.005746  loss: 0.001386  eta: 0h5m  tot: 0h42m52s  (88.2%)41.3%  lr: 0.005726  loss: 0.001387  eta: 0h5m  tot: 0h42m53s  (88.3%)41.4%  lr: 0.005726  loss: 0.001387  eta: 0h5m  tot: 0h42m54s  (88.3%)41.5%  lr: 0.005716  loss: 0.001386  eta: 0h5m  tot: 0h42m55s  (88.3%)41.7%  lr: 0.005686  loss: 0.001388  eta: 0h5m  tot: 0h42m56s  (88.3%)41.8%  lr: 0.005686  loss: 0.001388  eta: 0h5m  tot: 0h42m57s  (88.4%)42.0%  lr: 0.005666  loss: 0.001386  eta: 0h5m  tot: 0h42m57s  (88.4%)42.2%  lr: 0.005636  loss: 0.001387  eta: 0h5m  tot: 0h42m59s  (88.4%)42.6%  lr: 0.005556  loss: 0.001388  eta: 0h5m  tot: 0h43m1s  (88.5%)42.7%  lr: 0.005556  loss: 0.001389  eta: 0h5m  tot: 0h43m2s  (88.5%)42.9%  lr: 0.005556  loss: 0.001391  eta: 0h5m  tot: 0h43m3s  (88.6%)43.0%  lr: 0.005556  loss: 0.001390  eta: 0h5m  tot: 0h43m4s  (88.6%)43.4%  lr: 0.005516  loss: 0.001389  eta: 0h5m  tot: 0h43m6s  (88.7%)43.6%  lr: 0.005506  loss: 0.001388  eta: 0h5m  tot: 0h43m7s  (88.7%)43.9%  lr: 0.005496  loss: 0.001388  eta: 0h5m  tot: 0h43m9s  (88.8%)44.2%  lr: 0.005466  loss: 0.001390  eta: 0h5m  tot: 0h43m11s  (88.8%)44.4%  lr: 0.005446  loss: 0.001388  eta: 0h5m  tot: 0h43m12s  (88.9%)44.4%  lr: 0.005436  loss: 0.001388  eta: 0h5m  tot: 0h43m12s  (88.9%)44.8%  lr: 0.005395  loss: 0.001386  eta: 0h5m  tot: 0h43m14s  (89.0%)45.3%  lr: 0.005345  loss: 0.001387  eta: 0h5m  tot: 0h43m17s  (89.1%)45.6%  lr: 0.005315  loss: 0.001386  eta: 0h5m  tot: 0h43m19s  (89.1%)45.9%  lr: 0.005265  loss: 0.001384  eta: 0h5m  tot: 0h43m21s  (89.2%)46.1%  lr: 0.005245  loss: 0.001384  eta: 0h5m  tot: 0h43m22s  (89.2%)46.3%  lr: 0.005225  loss: 0.001384  eta: 0h5m  tot: 0h43m23s  (89.3%)46.5%  lr: 0.005205  loss: 0.001385  eta: 0h5m  tot: 0h43m24s  (89.3%)46.6%  lr: 0.005185  loss: 0.001386  eta: 0h5m  tot: 0h43m25s  (89.3%)46.7%  lr: 0.005185  loss: 0.001385  eta: 0h5m  tot: 0h43m26s  (89.3%)46.9%  lr: 0.005175  loss: 0.001385  eta: 0h5m  tot: 0h43m27s  (89.4%)47.7%  lr: 0.005125  loss: 0.001383  eta: 0h5m  tot: 0h43m32s  (89.5%)47.8%  lr: 0.005115  loss: 0.001381  eta: 0h5m  tot: 0h43m32s  (89.6%)48.4%  lr: 0.005085  loss: 0.001381  eta: 0h5m  tot: 0h43m36s  (89.7%)48.6%  lr: 0.005065  loss: 0.001379  eta: 0h5m  tot: 0h43m37s  (89.7%)48.8%  lr: 0.005035  loss: 0.001378  eta: 0h5m  tot: 0h43m38s  (89.8%)48.9%  lr: 0.005015  loss: 0.001380  eta: 0h5m  tot: 0h43m39s  (89.8%)49.4%  lr: 0.004985  loss: 0.001379  eta: 0h4m  tot: 0h43m42s  (89.9%)49.6%  lr: 0.004955  loss: 0.001378  eta: 0h4m  tot: 0h43m43s  (89.9%)49.7%  lr: 0.004955  loss: 0.001378  eta: 0h4m  tot: 0h43m44s  (89.9%)49.8%  lr: 0.004955  loss: 0.001378  eta: 0h4m  tot: 0h43m44s  (90.0%)49.8%  lr: 0.004955  loss: 0.001378  eta: 0h4m  tot: 0h43m45s  (90.0%)50.8%  lr: 0.004885  loss: 0.001375  eta: 0h4m  tot: 0h43m50s  (90.2%)51.0%  lr: 0.004865  loss: 0.001376  eta: 0h4m  tot: 0h43m52s  (90.2%)51.2%  lr: 0.004865  loss: 0.001375  eta: 0h4m  tot: 0h43m53s  (90.2%)51.3%  lr: 0.004835  loss: 0.001374  eta: 0h4m  tot: 0h43m54s  (90.3%)51.5%  lr: 0.004835  loss: 0.001374  eta: 0h4m  tot: 0h43m54s  (90.3%)51.6%  lr: 0.004815  loss: 0.001374  eta: 0h4m  tot: 0h43m55s  (90.3%)51.6%  lr: 0.004815  loss: 0.001374  eta: 0h4m  tot: 0h43m55s  (90.3%)51.7%  lr: 0.004815  loss: 0.001374  eta: 0h4m  tot: 0h43m56s  (90.3%)51.8%  lr: 0.004815  loss: 0.001373  eta: 0h4m  tot: 0h43m56s  (90.4%)51.9%  lr: 0.004775  loss: 0.001373  eta: 0h4m  tot: 0h43m57s  (90.4%)52.2%  lr: 0.004765  loss: 0.001375  eta: 0h4m  tot: 0h43m59s  (90.4%)54.0%  lr: 0.004615  loss: 0.001379  eta: 0h4m  tot: 0h44m9s  (90.8%)54.1%  lr: 0.004545  loss: 0.001380  eta: 0h4m  tot: 0h44m10s  (90.8%)54.5%  lr: 0.004515  loss: 0.001386  eta: 0h4m  tot: 0h44m13s  (90.9%)54.6%  lr: 0.004495  loss: 0.001386  eta: 0h4m  tot: 0h44m13s  (90.9%)55.1%  lr: 0.004465  loss: 0.001384  eta: 0h4m  tot: 0h44m16s  (91.0%)55.4%  lr: 0.004415  loss: 0.001386  eta: 0h4m  tot: 0h44m18s  (91.1%)55.5%  lr: 0.004415  loss: 0.001386  eta: 0h4m  tot: 0h44m19s  (91.1%)55.7%  lr: 0.004384  loss: 0.001387  eta: 0h4m  tot: 0h44m20s  (91.1%)56.3%  lr: 0.004324  loss: 0.001387  eta: 0h4m  tot: 0h44m24s  (91.3%)%  lr: 0.004294  loss: 0.001386  eta: 0h4m  tot: 0h44m26s  (91.3%)56.8%  lr: 0.004294  loss: 0.001386  eta: 0h4m  tot: 0h44m27s  (91.4%)%  lr: 0.004294  loss: 0.001386  eta: 0h4m  tot: 0h44m27s  (91.4%)56.9%  lr: 0.004294  loss: 0.001386  eta: 0h4m  tot: 0h44m27s  (91.4%)57.2%  lr: 0.004264  loss: 0.001386  eta: 0h4m  tot: 0h44m29s  (91.4%)57.5%  lr: 0.004214  loss: 0.001388  eta: 0h4m  tot: 0h44m31s  (91.5%)57.6%  lr: 0.004214  loss: 0.001387  eta: 0h4m  tot: 0h44m31s  (91.5%)58.0%  lr: 0.004184  loss: 0.001388  eta: 0h4m  tot: 0h44m34s  (91.6%)58.1%  lr: 0.004164  loss: 0.001388  eta: 0h4m  tot: 0h44m34s  (91.6%)58.2%  lr: 0.004154  loss: 0.001388  eta: 0h4m  tot: 0h44m35s  (91.6%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 83.9%  lr: 0.001582  loss: 0.001383  eta: 0h1m  tot: 0h47m6s  (96.8%))58.4%  lr: 0.004134  loss: 0.001388  eta: 0h4m  tot: 0h44m36s  (91.7%)58.4%  lr: 0.004124  loss: 0.001389  eta: 0h4m  tot: 0h44m37s  (91.7%)58.6%  lr: 0.004124  loss: 0.001389  eta: 0h4m  tot: 0h44m37s  (91.7%)58.9%  lr: 0.004124  loss: 0.001390  eta: 0h4m  tot: 0h44m40s  (91.8%)59.4%  lr: 0.004104  loss: 0.001387  eta: 0h4m  tot: 0h44m42s  (91.9%)59.5%  lr: 0.004094  loss: 0.001386  eta: 0h4m  tot: 0h44m43s  (91.9%)59.9%  lr: 0.004054  loss: 0.001387  eta: 0h3m  tot: 0h44m45s  (92.0%)60.4%  lr: 0.004004  loss: 0.001388  eta: 0h3m  tot: 0h44m48s  (92.1%)60.6%  lr: 0.004004  loss: 0.001387  eta: 0h3m  tot: 0h44m49s  (92.1%)60.8%  lr: 0.003964  loss: 0.001387  eta: 0h3m  tot: 0h44m51s  (92.2%)60.9%  lr: 0.003964  loss: 0.001388  eta: 0h3m  tot: 0h44m51s  (92.2%)61.3%  lr: 0.003934  loss: 0.001386  eta: 0h3m  tot: 0h44m54s  (92.3%)61.6%  lr: 0.003904  loss: 0.001387  eta: 0h3m  tot: 0h44m56s  (92.3%)62.2%  lr: 0.003854  loss: 0.001385  eta: 0h3m  tot: 0h44m59s  (92.4%)62.3%  lr: 0.003844  loss: 0.001385  eta: 0h3m  tot: 0h45m0s  (92.5%)62.5%  lr: 0.003804  loss: 0.001386  eta: 0h3m  tot: 0h45m1s  (92.5%)62.8%  lr: 0.003794  loss: 0.001384  eta: 0h3m  tot: 0h45m3s  (92.6%)63.4%  lr: 0.003734  loss: 0.001385  eta: 0h3m  tot: 0h45m6s  (92.7%)63.5%  lr: 0.003724  loss: 0.001384  eta: 0h3m  tot: 0h45m7s  (92.7%)63.6%  lr: 0.003704  loss: 0.001384  eta: 0h3m  tot: 0h45m7s  (92.7%)64.0%  lr: 0.003644  loss: 0.001386  eta: 0h3m  tot: 0h45m10s  (92.8%)64.1%  lr: 0.003644  loss: 0.001386  eta: 0h3m  tot: 0h45m11s  (92.8%)64.1%  lr: 0.003634  loss: 0.001386  eta: 0h3m  tot: 0h45m11s  (92.8%)64.2%  lr: 0.003634  loss: 0.001387  eta: 0h3m  tot: 0h45m11s  (92.8%)64.3%  lr: 0.003624  loss: 0.001386  eta: 0h3m  tot: 0h45m12s  (92.9%)%  lr: 0.003594  loss: 0.001385  eta: 0h3m  tot: 0h45m14s  (92.9%)65.1%  lr: 0.003534  loss: 0.001386  eta: 0h3m  tot: 0h45m16s  (93.0%)65.7%  lr: 0.003464  loss: 0.001385  eta: 0h3m  tot: 0h45m19s  (93.1%)65.7%  lr: 0.003464  loss: 0.001385  eta: 0h3m  tot: 0h45m20s  (93.1%)66.1%  lr: 0.003393  loss: 0.001387  eta: 0h3m  tot: 0h45m22s  (93.2%)66.2%  lr: 0.003393  loss: 0.001388  eta: 0h3m  tot: 0h45m22s  (93.2%)66.3%  lr: 0.003383  loss: 0.001388  eta: 0h3m  tot: 0h45m23s  (93.3%)66.8%  lr: 0.003363  loss: 0.001388  eta: 0h3m  tot: 0h45m26s  (93.4%)67.1%  lr: 0.003283  loss: 0.001388  eta: 0h3m  tot: 0h45m28s  (93.4%)67.6%  lr: 0.003273  loss: 0.001387  eta: 0h3m  tot: 0h45m30s  (93.5%)67.7%  lr: 0.003263  loss: 0.001387  eta: 0h3m  tot: 0h45m31s  (93.5%)67.8%  lr: 0.003243  loss: 0.001386  eta: 0h3m  tot: 0h45m32s  (93.6%)%  lr: 0.003233  loss: 0.001388  eta: 0h3m  tot: 0h45m32s  (93.6%)67.9%  lr: 0.003233  loss: 0.001387  eta: 0h3m  tot: 0h45m33s  (93.6%)68.7%  lr: 0.003213  loss: 0.001387  eta: 0h3m  tot: 0h45m37s  (93.7%)68.7%  lr: 0.003213  loss: 0.001388  eta: 0h3m  tot: 0h45m38s  (93.7%)69.1%  lr: 0.003173  loss: 0.001387  eta: 0h3m  tot: 0h45m40s  (93.8%)69.1%  lr: 0.003173  loss: 0.001388  eta: 0h3m  tot: 0h45m40s  (93.8%)69.2%  lr: 0.003163  loss: 0.001388  eta: 0h3m  tot: 0h45m41s  (93.8%)69.3%  lr: 0.003163  loss: 0.001388  eta: 0h3m  tot: 0h45m41s  (93.9%)69.6%  lr: 0.003123  loss: 0.001386  eta: 0h3m  tot: 0h45m43s  (93.9%)69.7%  lr: 0.003103  loss: 0.001386  eta: 0h3m  tot: 0h45m44s  (93.9%)69.8%  lr: 0.003083  loss: 0.001387  eta: 0h2m  tot: 0h45m45s  (94.0%)69.9%  lr: 0.003083  loss: 0.001387  eta: 0h2m  tot: 0h45m46s  (94.0%)70.0%  lr: 0.003083  loss: 0.001387  eta: 0h2m  tot: 0h45m46s  (94.0%)70.1%  lr: 0.003063  loss: 0.001387  eta: 0h2m  tot: 0h45m47s  (94.0%)70.2%  lr: 0.003063  loss: 0.001386  eta: 0h2m  tot: 0h45m47s  (94.0%)70.5%  lr: 0.003033  loss: 0.001385  eta: 0h2m  tot: 0h45m49s  (94.1%)70.5%  lr: 0.003023  loss: 0.001385  eta: 0h2m  tot: 0h45m49s  (94.1%)70.8%  lr: 0.003003  loss: 0.001384  eta: 0h2m  tot: 0h45m51s  (94.2%)71.0%  lr: 0.002983  loss: 0.001384  eta: 0h2m  tot: 0h45m52s  (94.2%)71.5%  lr: 0.002933  loss: 0.001383  eta: 0h2m  tot: 0h45m55s  (94.3%)71.7%  lr: 0.002913  loss: 0.001384  eta: 0h2m  tot: 0h45m56s  (94.3%)72.0%  lr: 0.002863  loss: 0.001383  eta: 0h2m  tot: 0h45m57s  (94.4%)72.4%  lr: 0.002783  loss: 0.001385  eta: 0h2m  tot: 0h46m0s  (94.5%)72.5%  lr: 0.002763  loss: 0.001385  eta: 0h2m  tot: 0h46m0s  (94.5%)73.0%  lr: 0.002713  loss: 0.001384  eta: 0h2m  tot: 0h46m3s  (94.6%)73.1%  lr: 0.002713  loss: 0.001384  eta: 0h2m  tot: 0h46m3s  (94.6%)73.2%  lr: 0.002703  loss: 0.001384  eta: 0h2m  tot: 0h46m4s  (94.6%)73.7%  lr: 0.002653  loss: 0.001382  eta: 0h2m  tot: 0h46m7s  (94.7%)73.8%  lr: 0.002643  loss: 0.001382  eta: 0h2m  tot: 0h46m7s  (94.8%)74.5%  lr: 0.002543  loss: 0.001382  eta: 0h2m  tot: 0h46m11s  (94.9%)74.6%  lr: 0.002513  loss: 0.001383  eta: 0h2m  tot: 0h46m11s  (94.9%)74.8%  lr: 0.002503  loss: 0.001383  eta: 0h2m  tot: 0h46m12s  (95.0%)74.8%  lr: 0.002503  loss: 0.001383  eta: 0h2m  tot: 0h46m13s  (95.0%)74.9%  lr: 0.002493  loss: 0.001383  eta: 0h2m  tot: 0h46m13s  (95.0%)75.3%  lr: 0.002473  loss: 0.001382  eta: 0h2m  tot: 0h46m16s  (95.1%)75.4%  lr: 0.002463  loss: 0.001382  eta: 0h2m  tot: 0h46m16s  (95.1%)75.5%  lr: 0.002463  loss: 0.001382  eta: 0h2m  tot: 0h46m16s  (95.1%)75.5%  lr: 0.002453  loss: 0.001383  eta: 0h2m  tot: 0h46m17s  (95.1%)76.2%  lr: 0.002372  loss: 0.001380  eta: 0h2m  tot: 0h46m21s  (95.2%)76.4%  lr: 0.002322  loss: 0.001380  eta: 0h2m  tot: 0h46m22s  (95.3%)76.5%  lr: 0.002322  loss: 0.001380  eta: 0h2m  tot: 0h46m22s  (95.3%)76.7%  lr: 0.002292  loss: 0.001381  eta: 0h2m  tot: 0h46m24s  (95.3%)77.3%  lr: 0.002262  loss: 0.001382  eta: 0h2m  tot: 0h46m27s  (95.5%)77.6%  lr: 0.002232  loss: 0.001381  eta: 0h2m  tot: 0h46m29s  (95.5%)77.8%  lr: 0.002222  loss: 0.001382  eta: 0h2m  tot: 0h46m30s  (95.6%)77.8%  lr: 0.002212  loss: 0.001382  eta: 0h2m  tot: 0h46m30s  (95.6%)77.9%  lr: 0.002202  loss: 0.001382  eta: 0h2m  tot: 0h46m31s  (95.6%)78.0%  lr: 0.002192  loss: 0.001382  eta: 0h2m  tot: 0h46m31s  (95.6%)78.2%  lr: 0.002152  loss: 0.001382  eta: 0h2m  tot: 0h46m32s  (95.6%)78.2%  lr: 0.002142  loss: 0.001382  eta: 0h2m  tot: 0h46m33s  (95.6%)78.3%  lr: 0.002142  loss: 0.001382  eta: 0h2m  tot: 0h46m33s  (95.7%)%  lr: 0.002132  loss: 0.001382  eta: 0h2m  tot: 0h46m34s  (95.7%)78.5%  lr: 0.002132  loss: 0.001383  eta: 0h2m  tot: 0h46m35s  (95.7%)78.6%  lr: 0.002112  loss: 0.001383  eta: 0h2m  tot: 0h46m35s  (95.7%)78.8%  lr: 0.002112  loss: 0.001382  eta: 0h2m  tot: 0h46m36s  (95.8%)79.0%  lr: 0.002102  loss: 0.001381  eta: 0h2m  tot: 0h46m37s  (95.8%)79.2%  lr: 0.002072  loss: 0.001382  eta: 0h2m  tot: 0h46m39s  (95.8%)79.3%  lr: 0.002072  loss: 0.001381  eta: 0h2m  tot: 0h46m39s  (95.9%)79.4%  lr: 0.002042  loss: 0.001381  eta: 0h2m  tot: 0h46m40s  (95.9%)79.6%  lr: 0.002032  loss: 0.001382  eta: 0h2m  tot: 0h46m41s  (95.9%)79.8%  lr: 0.002022  loss: 0.001382  eta: 0h1m  tot: 0h46m42s  (96.0%)80.0%  lr: 0.002012  loss: 0.001383  eta: 0h1m  tot: 0h46m43s  (96.0%)80.0%  lr: 0.002012  loss: 0.001382  eta: 0h1m  tot: 0h46m44s  (96.0%)80.1%  lr: 0.002012  loss: 0.001382  eta: 0h1m  tot: 0h46m44s  (96.0%)80.3%  lr: 0.001992  loss: 0.001383  eta: 0h1m  tot: 0h46m45s  (96.1%)80.4%  lr: 0.001972  loss: 0.001384  eta: 0h1m  tot: 0h46m46s  (96.1%)80.5%  lr: 0.001952  loss: 0.001383  eta: 0h1m  tot: 0h46m46s  (96.1%)80.6%  lr: 0.001932  loss: 0.001382  eta: 0h1m  tot: 0h46m47s  (96.1%)81.0%  lr: 0.001862  loss: 0.001382  eta: 0h1m  tot: 0h46m49s  (96.2%)81.2%  lr: 0.001852  loss: 0.001382  eta: 0h1m  tot: 0h46m50s  (96.2%)81.3%  lr: 0.001832  loss: 0.001381  eta: 0h1m  tot: 0h46m51s  (96.3%)81.8%  lr: 0.001782  loss: 0.001380  eta: 0h1m  tot: 0h46m54s  (96.4%)82.4%  lr: 0.001682  loss: 0.001381  eta: 0h1m  tot: 0h46m58s  (96.5%)82.7%  lr: 0.001632  loss: 0.001382  eta: 0h1m  tot: 0h47m0s  (96.5%)83.2%  lr: 0.001622  loss: 0.001383  eta: 0h1m  tot: 0h47m2s  (96.6%)83.2%  lr: 0.001612  loss: 0.001383  eta: 0h1m  tot: 0h47m2s  (96.6%)83.5%  lr: 0.001602  loss: 0.001383  eta: 0h1m  tot: 0h47m4s  (96.7%)83.6%  lr: 0.001602  loss: 0.001383  eta: 0h1m  tot: 0h47m5s  (96.7%)83.8%  lr: 0.001592  loss: 0.001383  eta: 0h1m  tot: 0h47m6s  (96.8%)83.9%  lr: 0.001582  loss: 0.001383  eta: 0h1m  tot: 0h47m6s  (96.8%)"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 100.0%  lr: 0.000000  loss: 0.001373  eta: <1min   tot: 0h48m33s  (100.0%)  lr: 0.001582  loss: 0.001382  eta: 0h1m  tot: 0h47m7s  (96.8%)84.2%  lr: 0.001522  loss: 0.001382  eta: 0h1m  tot: 0h47m8s  (96.8%)84.4%  lr: 0.001492  loss: 0.001381  eta: 0h1m  tot: 0h47m10s  (96.9%)84.7%  lr: 0.001452  loss: 0.001381  eta: 0h1m  tot: 0h47m12s  (96.9%)85.5%  lr: 0.001381  loss: 0.001381  eta: 0h1m  tot: 0h47m16s  (97.1%)85.7%  lr: 0.001371  loss: 0.001380  eta: 0h1m  tot: 0h47m17s  (97.1%)85.9%  lr: 0.001361  loss: 0.001380  eta: 0h1m  tot: 0h47m18s  (97.2%)86.3%  lr: 0.001331  loss: 0.001379  eta: 0h1m  tot: 0h47m21s  (97.3%)86.4%  lr: 0.001331  loss: 0.001378  eta: 0h1m  tot: 0h47m21s  (97.3%)86.5%  lr: 0.001321  loss: 0.001378  eta: 0h1m  tot: 0h47m22s  (97.3%)86.5%  lr: 0.001291  loss: 0.001378  eta: 0h1m  tot: 0h47m22s  (97.3%)86.6%  lr: 0.001281  loss: 0.001377  eta: 0h1m  tot: 0h47m23s  (97.3%)87.2%  lr: 0.001151  loss: 0.001379  eta: 0h1m  tot: 0h47m26s  (97.4%)%  lr: 0.001141  loss: 0.001379  eta: 0h1m  tot: 0h47m28s  (97.5%)87.7%  lr: 0.001141  loss: 0.001379  eta: 0h1m  tot: 0h47m29s  (97.5%)87.8%  lr: 0.001141  loss: 0.001379  eta: 0h1m  tot: 0h47m30s  (97.6%)87.9%  lr: 0.001141  loss: 0.001380  eta: 0h1m  tot: 0h47m30s  (97.6%)88.0%  lr: 0.001111  loss: 0.001380  eta: 0h1m  tot: 0h47m31s  (97.6%)88.1%  lr: 0.001081  loss: 0.001380  eta: 0h1m  tot: 0h47m32s  (97.6%)88.2%  lr: 0.001081  loss: 0.001380  eta: 0h1m  tot: 0h47m32s  (97.6%)88.3%  lr: 0.001081  loss: 0.001381  eta: 0h1m  tot: 0h47m33s  (97.7%)88.9%  lr: 0.001011  loss: 0.001380  eta: 0h1m  tot: 0h47m36s  (97.8%)89.4%  lr: 0.000981  loss: 0.001380  eta: 0h1m  tot: 0h47m39s  (97.9%)89.5%  lr: 0.000961  loss: 0.001380  eta: 0h1m  tot: 0h47m40s  (97.9%)89.7%  lr: 0.000961  loss: 0.001382  eta: 0h1m  tot: 0h47m41s  (97.9%)%  lr: 0.000961  loss: 0.001382  eta: 0h1m  tot: 0h47m42s  (98.0%)90.2%  lr: 0.000891  loss: 0.001381  eta: <1min   tot: 0h47m44s  (98.0%)90.3%  lr: 0.000891  loss: 0.001381  eta: <1min   tot: 0h47m45s  (98.1%)90.7%  lr: 0.000841  loss: 0.001379  eta: <1min   tot: 0h47m47s  (98.1%)90.7%  lr: 0.000841  loss: 0.001379  eta: <1min   tot: 0h47m47s  (98.1%)90.8%  lr: 0.000811  loss: 0.001379  eta: <1min   tot: 0h47m48s  (98.2%)91.1%  lr: 0.000781  loss: 0.001379  eta: <1min   tot: 0h47m49s  (98.2%)91.6%  lr: 0.000701  loss: 0.001379  eta: <1min   tot: 0h47m52s  (98.3%)91.9%  lr: 0.000681  loss: 0.001379  eta: <1min   tot: 0h47m54s  (98.4%)91.9%  lr: 0.000681  loss: 0.001379  eta: <1min   tot: 0h47m54s  (98.4%)92.1%  lr: 0.000641  loss: 0.001378  eta: <1min   tot: 0h47m55s  (98.4%)92.3%  lr: 0.000611  loss: 0.001378  eta: <1min   tot: 0h47m56s  (98.5%)92.5%  lr: 0.000581  loss: 0.001378  eta: <1min   tot: 0h47m58s  (98.5%)92.9%  lr: 0.000561  loss: 0.001378  eta: <1min   tot: 0h48m0s  (98.6%)93.2%  lr: 0.000531  loss: 0.001377  eta: <1min   tot: 0h48m2s  (98.6%)93.3%  lr: 0.000531  loss: 0.001378  eta: <1min   tot: 0h48m2s  (98.7%)93.4%  lr: 0.000531  loss: 0.001378  eta: <1min   tot: 0h48m3s  (98.7%)93.7%  lr: 0.000501  loss: 0.001377  eta: <1min   tot: 0h48m5s  (98.7%)93.9%  lr: 0.000471  loss: 0.001376  eta: <1min   tot: 0h48m6s  (98.8%)94.0%  lr: 0.000471  loss: 0.001377  eta: <1min   tot: 0h48m6s  (98.8%)94.4%  lr: 0.000400  loss: 0.001376  eta: <1min   tot: 0h48m9s  (98.9%)94.4%  lr: 0.000400  loss: 0.001377  eta: <1min   tot: 0h48m9s  (98.9%)94.7%  lr: 0.000370  loss: 0.001377  eta: <1min   tot: 0h48m11s  (98.9%)95.0%  lr: 0.000310  loss: 0.001378  eta: <1min   tot: 0h48m12s  (99.0%)95.9%  lr: 0.000250  loss: 0.001376  eta: <1min   tot: 0h48m17s  (99.2%)96.3%  lr: 0.000250  loss: 0.001377  eta: <1min   tot: 0h48m18s  (99.3%)97.1%  lr: 0.000220  loss: 0.001377  eta: <1min   tot: 0h48m21s  (99.4%)97.1%  lr: 0.000220  loss: 0.001377  eta: <1min   tot: 0h48m21s  (99.4%)97.4%  lr: 0.000200  loss: 0.001377  eta: <1min   tot: 0h48m22s  (99.5%)  loss: 0.001375  eta: <1min   tot: 0h48m24s  (99.6%)98.0%  lr: 0.000170  loss: 0.001376  eta: <1min   tot: 0h48m25s  (99.6%)98.4%  lr: 0.000140  loss: 0.001376  eta: <1min   tot: 0h48m27s  (99.7%)\n",
      " ---+++                Epoch    4 Train error : 0.00137070 +++--- ���\n",
      "Saving model to file : starspace_embedding\n",
      "Saving model in tsv format : starspace_embedding.tsv\n"
     ]
    }
   ],
   "source": [
    "######### TRAINING HAPPENING HERE #############\n",
    "\n",
    "!starspace train -trainFile \"data/train_prepped.tsv\" \\\n",
    "    -model starspace_embedding \\\n",
    "    -trainMode 3 \\\n",
    "    -adagrad true \\\n",
    "    -ngrams 1 \\\n",
    "    -epoch 5 \\\n",
    "    -dim 100 \\\n",
    "    -similarity \"cosine\" \\\n",
    "    -minCount 2 \\\n",
    "    -verbose true \\\n",
    "    -fileFormat labelDoc \\\n",
    "    -negSearchLimit 10 \\\n",
    "    -lr 0.05 \\\n",
    "    -thread 4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "And now we can compare the new embeddings with the previous ones. You can find trained word vectors in the file *[model_file_name].tsv*. Upload the embeddings from StarSpace into a dict. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### YOUR CODE HERE #############\n",
    "starspace_embeddings = {}\n",
    "for line in open('starspace_embedding.tsv'):\n",
    "    line_elements = line.strip().split('\\t')\n",
    "    word = line_elements[0]\n",
    "    starspace_embeddings[word] = [float(x) for x in line_elements[1:]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss_prepared_ranking = []\n",
    "for line in prepared_validation:\n",
    "    q, *ex = line\n",
    "    ranks = rank_candidates(q, ex, starspace_embeddings, 100)\n",
    "    ss_prepared_ranking.append([r[0] for r in ranks].index(0) + 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in [1, 5, 10, 100, 500, 1000]:\n",
    "    print(\"DCG@%4d: %.3f | Hits@%4d: %.3f\" % (k, dcg_score(ss_prepared_ranking, k), \n",
    "                                               k, hits_count(ss_prepared_ranking, k)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to training for the particular task with the supervised data, you should expect to obtain a higher quality than for the previous approach. In additiion, despite the fact that StarSpace's trained vectors have a smaller dimension than word2vec's, it provides better results in this task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Task 5 (StarSpaceRanks).** For each question from prepared *test.tsv* submit the ranks of the candidates for trained representation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current answer for task StarSpaceRanks is: 88\t59\t75\t35\t17\t100\t98\t86\t94\t33\t25\t51\t20\t7\t99\t91\t8\t31\t47\t97\t80\t23\t4\t38\t87\t39\t76\t81\t90\t2\t40\t55\t48\t85\t7...\n"
     ]
    }
   ],
   "source": [
    "starspace_ranks_results = []\n",
    "prepared_test_data = 'data/test_prepped.tsv' ######### YOUR CODE HERE #############\n",
    "for line in open(prepared_test_data):\n",
    "    q, *ex = line.strip().split('\\t')\n",
    "    ranks = rank_candidates(q, ex, starspace_embeddings, 100)\n",
    "    ranked_candidates = [r[0] for r in ranks]\n",
    "    starspace_ranks_results.append([ranked_candidates.index(i) + 1 for i in range(len(ranked_candidates))])\n",
    "    \n",
    "grader.submit_tag('StarSpaceRanks', matrix_to_string(starspace_ranks_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Authorization & Submission\n",
    "To submit assignment parts to Cousera platform, please, enter your e-mail and token into variables below. You can generate token on this programming assignment page. <b>Note:</b> Token expires 30 minutes after generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "You want to submit these parts:\n",
      "Task Question2Vec: 0.019293891059\n",
      "-0.0287272135417\n",
      "0.0460561116536\n",
      "0.0852593315972\n",
      "0.0243055555556\n",
      "-0.0729031032986\n",
      "0.0...\n",
      "Task HitsCount: 1.0\n",
      "0.5\n",
      "1.0\n",
      "0.5\n",
      "1.0\n",
      "0.3333333333333333\n",
      "0.6666666666666666\n",
      "1.0\n",
      "0.1\n",
      "0.2\n",
      "0.3\n",
      "0.4\n",
      "0.5\n",
      "0.6\n",
      "0.7\n",
      "0.8\n",
      "0.9\n",
      "1....\n",
      "Task DCGScore: 1.0\n",
      "0.5\n",
      "0.815464876786\n",
      "0.5\n",
      "0.815464876786\n",
      "0.333333333333\n",
      "0.54364325119\n",
      "0.710309917857\n",
      "0.1\n",
      "0.16309297...\n",
      "Task W2VTokenizedRanks: 95\t94\t7\t9\t64\t36\t31\t93\t23\t100\t99\t20\t60\t6\t97\t48\t70\t37\t41\t96\t29\t56\t2\t65\t68\t44\t27\t25\t57\t62\t11\t87\t50\t66\t7...\n",
      "Task StarSpaceRanks: 88\t59\t75\t35\t17\t100\t98\t86\t94\t33\t25\t51\t20\t7\t99\t91\t8\t31\t47\t97\t80\t23\t4\t38\t87\t39\t76\t81\t90\t2\t40\t55\t48\t85\t7...\n"
     ]
    }
   ],
   "source": [
    "STUDENT_EMAIL = 'prateek1592@gmail.com'\n",
    "STUDENT_TOKEN = 'HJ5SPADE8oELfDzU'\n",
    "grader.status()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you want to submit these answers, run cell below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "grader.submit(STUDENT_EMAIL, STUDENT_TOKEN)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
